%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\rawhtml
<a name="production_code_program_synthesis"></a>
\endrawhtml
\subsectional{Generation: Automated Code Synthesis}

%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Gulwani~\etal{}~\cite{GulwanietalFaTiPL-17} provide an up-to-date survey of challenges and technologies in automated program synthesis. Machine learning is devoted 10 out of the more than 100 pages in the review with neural network methods singled out as a separate section of 6 additional pages. My experience is that most advocates are largely ignorant concerning the relevant history including the many successful applications for handling interesting special cases. I won't attempt to remedy that state of affairs here except to recommend that readers interested in program synthesis spend the time to familiarize themselves with the relevant work including both successes and notable failures. 

For those of you primarily interested in neural-network methods, understanding this background is likely to prove useful in developing hybrid systems that combine connectionist models and more conventional symbolic methods. Already, the power of high-dimensional vector-space representations, context-sensitive embedding spaces and fully-differentiable models trained with backpropagation is winning converts among devotees of more traditional methods, even as the latest generation of neural-network experts working on neural-network code synthesis are rediscovering some of the same special cases that have been exploited in deductive and constraint-based approaches to automated code synthesis.

%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Given the title, you might have expected that this document would be all about automatic programming, but it's really about human augmentation and human-computer collaboration. Programming is all about representing procedural knowledge in an interpretable form, i.e., executable on some computational substrate. Teaching someone to program or, for that matter, teaching someone to do most anything nontrivial, is also about representing and communicating procedural knowledge in an interpretable form \emdash{} the clearer and more precise the communication the simpler and less knowledgeable the computational substrate.

In this section, we attempt to identify special cases in which it is relatively easy for a human programmer to instruct an AI system how to facilitate the conversion of thoughts conveyed in natural language into working programs \emdash{} see Graham Neubig's CS379C calendar {\urlh{https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/05/01/index.html}{page}} for a sample of his NLP work on code generation and learning dialog systems. We are not anticipating that we will be able to read minds so much as exploit shared knowledge in order to translate succinct descriptions of desired computations \emdash{} along with an implicit understanding of what constitutes a suitable computational solution \emdash{} into working software possibly with guarantees of its correctness and performance.

How does this perspective inform the discussion in this section? Prior to any training the apprentice comes equipped with a very basic language facility and an innate ability to work with computer programs, but the former is practically useless since the meta-learning controller hasn't been trained and the latter only produces results in the same way that a baby has virtually no control over its limbs and torso. It learns to communicate by reinforcement when it successfully carries out a command from the expert programmer. A built-in training system expedites this process and relieves some of the burden from the programmer by generating synthetic commands that serve to initialize the meta-learning controller allowing the assistant to achieve a basic facility for directly translating natural language commands exercising the integrated development environment.

The apprentice also comes pre-trained with a (semantic) {\urlh{https://en.wikipedia.org/wiki/Language_model}{language model}} trained on a corpus that includes a large vocabulary of practical and technical terms used by programmers in talking about programs and programming. The system has also ingested a large corpus of programs and program fragments written in the language that it will use for writing new programs, resulting in an embedding space that encodes these programs and an encoder decoder translation facility that allows it to read and write programs represented as abstract syntax trees. Were there more computer- / natural-language {\urlh{https://en.wikipedia.org/wiki/Parallel_text#Parallel_corpora}{parallel corpora}}, supervised training of systems that depend on natural-language specification as input would be tempting. As it is, we have to rely on more sophisticated strategies.

%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Perhaps it is not surprising that many current neural-network approaches take advantage of the fact of neural-network technology originally designed for machine translation, question answering and related natural-language processing applications. Programs are linguistic objects with relatively simple syntax. Their syntax is well understood since linguistically adept computer scientists designed them. Parsing programs is easy. Their semantics is revealed by running them, and not just their input-output behavior \emdash{} execution traces can be used to reveal meaning of every function and fragment. 

Programming languages are syntactically unforgiving \emdash{} a source of aggravation for beginning programmers, but we have sophisticated editors and syntax checkers that avoid most problems and there is no reason not to build them into the integrated development environment used by the programmer's assistant and shared with the programmer. Internally, the assistant can work with equivalent abstract syntax trees making it easy to ingest, embed, manipulate and generate proposals for performing program transformations on such representations. Human readable code can be recovered for the programmer's convenience.

Successful code synthesis \emdash{} for different flavors of success \emdash{} can verified by running the program and comparing with the provided input-output examples. Modulo the intractability of the halting problem, failure for relatively simple programs can be be relatively easily determined. Program {\urlh{https://en.wikipedia.org/wiki/Correctness_(computer_science)}{correctness}} is generally specified with respect to a specification and hence is more difficult to pin down, though the term generally implies the existence of a mathematical proof and, hence, one formal-methods approach to code synthesis involves generating a {\urlh{https://en.wikipedia.org/wiki/Constructive_proof}{constructive proof}} of correctness. 

Semantic embeddings are increasingly common~\cite{DevlinetalICLR-18,ChistyakovetalICLR-17,WangetalCoRR-17,XuetalCoRR-17,PiechetalICML-15} based on {\urlh{https://en.wikipedia.org/wiki/Software_diagnosis#Characteristics}{execution traces}}, {\urlh{https://en.wikipedia.org/wiki/Log_file#Event_logs}{event logs}}, or {\urlh{https://en.wikipedia.org/wiki/Invariant_(computer_science)}{program invariants}}. 
See this discussion log {\urlh{https://web.stanford.edu/class/cs379c/class_messages_listing/index.html#program_embedding_core_technology}{entry}}
and Rishabh Singh's CS379C calendar {\urlh{https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/05/24/index.html}{page}} plus 
this discussion log {\urlh{https://web.stanford.edu/class/cs379c/class_messages_listing/index.html#execution_logs_program_traces}{entry}}
and Dawn Song's CS379C calendar {\urlh{https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/05/31/index.html}{page}} for more on semantic embeddings. I'm not going into detail here for the simple reason that it is still early days and your best approach is to learn more is to read the papers, check out the slides and watch the videos mentioned in this paragraph \emdash{} you might also take a look at Danny Tarlow's automatic programming list {\urlh{./content/Selected_Program_Synthesis_Papers_Tarlow.pdf}{here}}.

%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\setcounter{figure}{2}

%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%% Figure~{\urlh{#fig_CS379C_Final_Project_Gomezetal_Figure_03}{3}}
\rawhtml
<a name="fig_CS379C_Final_Project_Gomezetal_Figure_03"></a>
\endrawhtml
\begin{figure}
%
  \hrule{}
%
  \begin{center}
    \includegraphics[width=11.0in]{./figures/CS379C_Final_Project_Gomezetal_Figure_03.png}
  \end{center}
%
  \caption{Summary of the proposed LSTM-based state-embedding architecture for $C_{f}$ described in Gomez~\etal{}~\cite{CS379C_Final_Project_Gomezetal-18}. The code representation, $C_{f}$, is by default variable in size since the abstract syntax trees that comprise the individual helper functions are variable size. The authors solve this problem by training an autoencoder penalized on reconstruction loss such that the decoded output is the binary tree representation of the original AST.}
%
  \hrule{}
%
\end{figure}

%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In {\urlh{https://web.stanford.edu/class/cs379c/}{CS379C}} this year, 30 students, organized in 12 teams proposed and carried out projects relating to the programmer's apprentice. As an example, the team consisting of Marcus Gomez, Nate Gruver, Michelle Lam, Rohun Saxena and Lucy Wang decided based on their coding habits that the most helpful assistant would be one that could be trained to understand design through the structure of an application programming interface ({\urlh{https://en.wikipedia.org/wiki/Application_programming_interface}{API}}) and assist in the completion of the code through a divide-and-conquer approach {\urlh{./content/CS379C_Final_Project_Gomezetal-18.pdf}{PDF}}.

The system they envision would be designed to integrate seamlessly into programmer's workflow, minimize interaction and start from a header file and dependency graph. They took pains to standardize the format of the input in order to simplify learning a compressed fixed-size state vector as an ordered list of GLoVe vectors~\cite{PenningtonetalEMNLP-14} \emdash{} see Figure~{\urlh{#fig_CS379C_Final_Project_Gomezetal_Figure_03}{3}}.

They use the method of generative adversarial imitation learning (GAIL) developed by Ho and Ermon~\cite{HoandErmonCoRR-16} for extracting a policy from data as if it were obtained by reinforcement learning following inverse reinforcement learning. This enables them to derive a model-free imitation learning algorithm that obtains significant performance gains over existing model-free methods in imitating complex behaviors in large, high-dimensional environments.

The details are less important than the diversity and scalabilty of the architectural components now available that allow for the creative manipulation of the ungainly objects that comprise the inputs and outputs of software engineering practice, e.g., natural language specifications of arbitrary format, programs of arbitrary size and computed artifacts such as execution traces that defy explicit encoding due to their size and format variability.

%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% 

%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsectional{Resources}

Daniel Abolafia's {\urlh{https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/24/slides/Daniel_Abolafia_CS379C_04-24-18.pdf}{presentation}} on iterative optimization for program synthesis in the presence of a reward function over the output of programs, where the goal is to find programs with maximal rewards~\cite{AbolafiaetalCoRR-18}\footnote{%
%
  The abstract for Abolafia~\etal{}~\cite{AbolafiaetalCoRR-18}:
%
  \begin{quotation}
%
    We consider the task of program synthesis in the presence of a reward function over the output of programs, where the goal is to find programs with maximal rewards. We employ an iterative optimization scheme, where we train an RNN on a dataset of K best programs from a priority queue of the generated programs so far. Then, we synthesize new programs and add them to the priority queue by sampling from the RNN. We benchmark our algorithm, called priority queue training (or PQT), against genetic algorithm and reinforcement learning baselines on a simple but expressive Turing complete programming language called BF. Our experimental results show that our simple PQT algorithm significantly outperforms the baselines. By adding a program length penalty to the reward function, we are able to synthesize short, human readable programs.
%
  \end{quotation}}.

Graham Neubig's {\urlh{https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/05/01/slides/Graham_Neubig_CS379C_05-01-18.pdf}{presentation}} on a novel neural architecture for parsing natural language descriptions into source code powered by a grammar model to explicitly capture the target syntax as prior knowledge~\cite{YinandNeubigACL-17}\footnote{%
%
  The abstract for Yin and Neubig~\cite{YinandNeubigACL-17}:
%
  \begin{quotation}
%
    We consider the problem of parsing natural language descriptions into source code written in a general-purpose programming language like Python. Existing data-driven methods treat this problem as a language generation task without considering the underlying syntax of the target programming language. Informed by previous work in semantic parsing, in this paper we propose a novel neural architecture powered by a grammar model to explicitly capture the target syntax as prior knowledge. Experiments find this an effective way to scale up to generation of complex programs from natural language descriptions, achieving state-of-the-art results that well outperform previous code generation and semantic parsing approaches.
%
  \end{quotation}}.

Rishabh Singh's {\urlh{https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/05/24/videos/Rishabh_Singh_CS379C_05-24-18.mp4}{presentation}} on using a strong statistical model for semantic code repair to predict bug locations and exact fixes without access to information about the intended correct behavior of the program.~\cite{DevlinetalICLR-18}\footnote{%
%
  The abstract for Devlin~\etal{}~\cite{DevlinetalICLR-18}:
%
  \begin{quotation}
%
    We study the problem of semantic code repair, which can be broadly defined as automatically fixing non-syntactic bugs in source code. The majority of past work in semantic code repair assumed access to unit tests against which candidate repairs could be validated. In contrast, the goal here is to develop a strong statistical model to accurately predict both bug locations and exact fixes without access to information about the intended correct behavior of the program. Achieving such a goal requires a robust contextual repair model, which we train on a large corpus of real-world source code that has been augmented with synthetically injected bugs. Our framework adopts a two-stage approach where first a large set of repair candidates are generated by rule-based processors, and then these candidates are scored by a statistical model using a novel neural network architecture which we refer to as Share, Specialize, and Compete. Specifically, the architecture (1) generates a  shared encoding of the source code using an RNN over the abstract syntax tree, (2) scores each candidate repair using specialized network modules, and (3) then normalizes these scores together so they can compete against one another in comparable probability space. We evaluate our model on a real-world test set gathered from GitHub containing four common categories of bugs. Our model is able to predict the exact correct repair 41\% of the time with a single guess, compared to 13\% accuracy for an attentional sequence-to-sequence model.
%
  \end{quotation}}.

Dawn Song and Xinyun Chen's {\urlh{https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/05/31/videos/Dawn_Song_CS379C_05-31-18.mp4}{presentation}} on program synthesis from input-output examples, tree-to-tree neural networks for program translation, and attention for program synthesis from natural language descriptions~\cite{ChenetalICLR-18b}\footnote{%
%
  The abstract for Chen~\etal{}~\cite{ChenetalICLR-18b}:
%
  \begin{quotation}
%
    Program translation is an important tool to migrate legacy code in one language into an ecosystem built in a different language. In this work, we are the first to consider employing deep neural networks toward tackling this problem. We observe that program translation is a modular procedure, in which a sub-tree of the source tree is translated into the corresponding target sub-tree at each step. To capture this intuition, we design a tree-to-tree neural network as an encoder-decoder architecture to translate a source tree into a target one. Meanwhile, we develop an attention mechanism for the tree-to-tree model, so that when the decoder expands one non-terminal in the target tree, the attention mechanism locates the corresponding sub-tree in the source tree to guide the expansion of the decoder. We evaluate the program translation capability of our tree-to-tree model against several state-of-the-art approaches. Compared against other neural translation models, we observe that our approach is consistently better than the baselines with a margin of up to 15 points. Further, our approach can improve the previous state-of-the-art program translation approaches by a margin of 20 points on the translation of real-world projects.
%
  \end{quotation}}.

%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


