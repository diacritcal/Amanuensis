<!DOCTYPE html>
<html>
<!--
Generated from index.tex by tex2page, v 20150301
(running on Racket 6.6, :unix), 
(c) Dorai Sitaram, 
http://www.ccs.neu.edu/~dorai/tex2page/index.html
-->
<head>
<meta charset="utf-8">
<title>
Amanuensis: The Programmer's Apprentice
</title>
<link rel="stylesheet" href="index.css" title=default />
<meta name=robots content="index,follow">
</head>
<body>
<div id=slidetitle>
<div align=right class=navigation></div>
<p>

</p>
<p>


</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>


</p>
<p>
</p>
<p>
</p>
<p>

</p>
<p>

</p>
<p>


</p>
<p>
</p>
<p>

</p>
<p>











</p>
<p>











</p>
<p>
</p>
<p>












</p>
<p>






</p>
<p>
















































</p>
<p>















































</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>

</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>

</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<h1 class=title>Amanuensis: The Programmer's Apprentice</h1>
<p></p>
<div align=center>
Thomas Dean<sup><strong>1,2</strong></sup>
<br>Maurice Chiang<sup><strong>2</strong></sup> 
<br>Marcus Gomez<sup><strong>2</strong></sup> 
<br>Nate Gruver<sup><strong>2</strong></sup> 
<br>Yousef Hindy<sup><strong>2</strong></sup> 
<br>Michelle Lam<sup><strong>2</strong></sup> 
<br>Peter Lu<sup><strong>2</strong></sup> 
<br>Sophia Sanchez<sup><strong>2</strong></sup> 
<br>Rohun Saxena<sup><strong>2</strong></sup> 
<br>Michael Smith<sup><strong>2</strong></sup> 
<br>Lucy Wang<sup><strong>2</strong></sup> 
<br>Catherine Wong<sup><strong>2</strong></sup><br><div class=smallskip></div>
<p style="margin-top: 0pt; margin-bottom: 0pt">
<br><strong>1</strong> Google Research, <strong>2</strong> Stanford University</p>
<p></p>
</div>
<p></p>
<p>
</p>
<blockquote><div align=center>&nbsp;<strong>Abstract</strong>&nbsp;</div>
<p>
This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators &#8212; effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.
</p>
</blockquote><p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<a name="node_sec_Temp_1"></a>
<h1 class=section>Contents</h1>
<p><a name="node_toc_start"></a></p>

<p class=noindent></p>
<p></p>

<p class=noindent><b>
&nbsp; &nbsp; <a name="node_toc_node_sec_1"></a><a href="#node_sec_1">1&nbsp;&nbsp;Introduction: Programmer's Apprentice</a></b><br>
&nbsp; &nbsp; &nbsp; &nbsp; <a name="node_toc_node_sec_1.1"></a><a href="#node_sec_1.1">1.1&nbsp;&nbsp;Resources</a><br>
</p>
<p></p>

<p class=noindent><b>
&nbsp; &nbsp; <a name="node_toc_node_sec_2"></a><a href="#node_sec_2">2&nbsp;&nbsp;Foundation: The Cognitive Neurosciences</a></b><br>
&nbsp; &nbsp; &nbsp; &nbsp; <a name="node_toc_node_sec_2.1"></a><a href="#node_sec_2.1">2.1&nbsp;&nbsp;Memory</a><br>
&nbsp; &nbsp; &nbsp; &nbsp; <a name="node_toc_node_sec_2.2"></a><a href="#node_sec_2.2">2.2&nbsp;&nbsp;Actions</a><br>
&nbsp; &nbsp; &nbsp; &nbsp; <a name="node_toc_node_sec_2.3"></a><a href="#node_sec_2.3">2.3&nbsp;&nbsp;Resources</a><br>
</p>
<p></p>

<p class=noindent><b>
&nbsp; &nbsp; <a name="node_toc_node_sec_3"></a><a href="#node_sec_3">3&nbsp;&nbsp;Interaction: Natural Language Processing</a></b><br>
&nbsp; &nbsp; &nbsp; &nbsp; <a name="node_toc_node_sec_3.1"></a><a href="#node_sec_3.1">3.1&nbsp;&nbsp;Planning</a><br>
&nbsp; &nbsp; &nbsp; &nbsp; <a name="node_toc_node_sec_3.2"></a><a href="#node_sec_3.2">3.2&nbsp;&nbsp;Hybrids</a><br>
&nbsp; &nbsp; &nbsp; &nbsp; <a name="node_toc_node_sec_3.3"></a><a href="#node_sec_3.3">3.3&nbsp;&nbsp;Resources</a><br>
</p>
<p></p>

<p class=noindent><b>
&nbsp; &nbsp; <a name="node_toc_node_sec_4"></a><a href="#node_sec_4">4&nbsp;&nbsp;Generation: Automated Code Synthesis</a></b><br>
&nbsp; &nbsp; &nbsp; &nbsp; <a name="node_toc_node_sec_4.1"></a><a href="#node_sec_4.1">4.1&nbsp;&nbsp;Teaching</a><br>
&nbsp; &nbsp; &nbsp; &nbsp; <a name="node_toc_node_sec_4.2"></a><a href="#node_sec_4.2">4.2&nbsp;&nbsp;Projects</a><br>
&nbsp; &nbsp; &nbsp; &nbsp; <a name="node_toc_node_sec_4.3"></a><a href="#node_sec_4.3">4.3&nbsp;&nbsp;Resources</a><br>
</p>
<p></p>

<p class=noindent><b>
&nbsp; &nbsp; <a name="node_toc_node_sec_A"></a><a href="#node_sec_A">A&nbsp;&nbsp;Human-Like Cognitive Architectures</a></b><br>
</p>
<p></p>

<p class=noindent><b>
&nbsp; &nbsp; <a name="node_toc_node_sec_B"></a><a href="#node_sec_B">B&nbsp;&nbsp;Bootstrapped Linguistic Competence</a></b><br>
<a name="node_toc_end"></a></p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
<a name="introduction_and_high_level_content"></a>
</p>
<a name="node_sec_1"></a>
<h1 class=section><a href="#node_toc_node_sec_1">1&nbsp;&nbsp;Introduction: Programmer's Apprentice</a></h1>
<p></p>
<p>
</p>
<p>
Suppose you could merely imagine a computation, and a digital prostheses, an extension of your biological brain, would turn it into code that instantly realizes what you had in mind. Imagine looking at an image, dataset or set of equations and wanting to analyze and explore its meaning as an artistic whim or part of a scientific investigation. I don't mean you would use an existing software suite to produce a standard visualization, but rather you would make use of an extensive repository of existing code to assemble a new program analogous to how a composer draws upon a repertoire of musical motifs, themes and styles to construct new works, and tantamount to having a talented musical amanuensis who, in addition to copying your scores, takes liberties with your prior work, making small alterations here and there and occasionally adding new works of its own invention, novel but consistent with your taste and sensibilities.</p>
<p>
Perhaps the interaction would be wordless and you would express your objective by simply focusing your attention and guiding your imagination, the prostheses operating directly on patterns of activation arising in your primary sensory, proprioceptive and associative cortex that have become part of an extensive vocabulary that you now share with your personal digital amanuensis. Or perhaps it would involve a conversation conducted in subvocal, unarticulated speech in which you specify what it is you want to compute and your assistant asks questions to clarify your intention and the two of you share examples of input and output to ground your internal conversation in concrete terms. </p>
<p>
More than thirty years ago, Charles Rich and Richard Waters published an MIT AI Lab technical report&nbsp;[<a href="#node_bib_80">80</a>] entitled <i>The Programmer's Apprentice: A Research Overview</i>. Whether they intended it or not, it would have been easy in those days for someone to misremember the title and inadvertently refer to it as &quot;The Sorcerer's Apprentice&quot; since computer programmers at the time were often characterized as wizards and most children were familiar with the Walt Disney movie <i>Fantasia</i>, featuring music written by Paul Dukas inspired by Goethe's poem of the same name<a name="node_call_footnote_Temp_2"></a><sup><small><a href="#node_footnote_Temp_2">1</a></small></sup>.
The Rich and Waters conception of an apprentice was certainly more prosaic than the idea described above<a name="node_call_footnote_Temp_3"></a><sup><small><a href="#node_footnote_Temp_3">2</a></small></sup>, but they might have had trouble imagining the amount of code available in open-source repositories and the considerable computational power we carry about on our persons or can access through the cloud.<p>
In any case, you might find it easier to imagine describing programs in natural language and supplementing your descriptions with input-output pairs. The programs could be as simple as regular expressions or SQL queries or as complicated as designing powerful simulators and visualization algorithms. The point is that there is a set of use cases that are within our reach now and that set will grow as we improve our natural language understanding and machine learning tools. I simply maintain that the scope of applications within reach today is probably larger than you think and that our growing understanding of human cognition is helping to substantially broaden that scope and significantly improve the means by which we interact with computers in general and a new generation of digital prostheses in particular. Here are just a few of the implications that might follow from pursuing a very practical and actionable modern version of The Programmer's Apprentice:</p>
<p>
</p>
<p>
<strong>Develop systems that enable human-machine collaboration on challenging design problems including software engineering:</strong></p>
<p>
The objective of this effort is to develop digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators &#8212; effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources. </p>
<p>
</p>
<p>
<strong>Leverage and extend the current state of the art in machine learning by integrating human and machine intelligence:</strong></p>
<p>
Current methods for training neural networks typically require substantial amounts of carefully labeled and curated data. Moreover the environments in which many learning systems are expected to perform are partially observable and non-stationary. The distributions that govern the presentation of examples change over time requiring constant effort to collect new data and retrain. The ability to solicit and incorporate knowledge gleaned from new experience to modify subsequent expectations and adapt behavior is particularly important for systems such as digital assistants with whom we interact and routinely share experience. Effective planning and decision making rely on counterfactual reasoning in which we imagine future states in which propositions not currently true are accommodated or steps taken to make them true&nbsp;[<a href="#node_bib_47">47</a>]. The ability for digital assistants to construct predictive models of other agents &#8212; so-called theory-of-mind modeling &#8212; is critically important for collaboration&nbsp;[<a href="#node_bib_78">78</a>].</p>
<p>
</p>
<p>
<strong>Draw insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems:</strong></p>
<p>
Many state-of-the-art machine learning systems now combine differentiable and non-differentiable computational models. The former consist of fully-differentiable connectionist artificial neural networks. They achieve their competence by leveraging a combination of distributed representations facilitating context-sensitive, noise-tolerant pattern-recognition and end-to-end training via backpropagation. The latter, non-differentiable models, excel at manipulating representations that exhibit combinatorial syntax and semantics, are said to be full systematic and compositional, and can directly and efficiently exploit the advantages of traditional von Neumann computing architectures. The differences between the two models are at the heart of the connectionist versus symbolic systems debate that dominated cognitive science in 80's and continues to this day&nbsp;[<a href="#node_bib_71">71</a>,&nbsp;<a href="#node_bib_32">32</a>]. Rather than simulate symbolic reasoning within connectionist models or vice a versa, we simply acknowledge their strengths and build systems that enable efficient integration of both types of reasoning.</p>
<p>
</p>
<p>
<strong>Take advantage of advances in natural language processing to implement systems capable of continuous focused dialog:</strong></p>
<p>
Language is arguably the most important technical innovation in the history of humanity. Not only does it make possible our advanced social skills, but it allows us to pass knowledge from one generation to the next and provides the foundation for mathematical and logical reasoning. Natural language is our native programming language. It is the way we communicate plans and coordinate their execution. In terms of expressiveness, it surpasses modern computer programming languages, but its capability for communicating imprecisely and even incoherently, and our tendency for utilizing that capability makes it a poor tool for programming conventional computers. That said it serves us well in training scientists and engineers to develop and apply more precise languages, and its expressiveness along with our facility using it make it an ideal means for humans and AI systems to collaborate. The consolidation and subsequent recall and management of episodic memory is a key part of what makes us human and enables our diverse social behaviors. Episodic memory makes it possible to create and maintain long-term relationships and collaborations&nbsp;[<a href="#node_bib_76">76</a>,&nbsp;<a href="#node_bib_62">62</a>,&nbsp;<a href="#node_bib_70">70</a>].</p>
<p>
</p>
<p>
<strong>Think seriously about how such technology might ultimately be employed to build brain-computer-interfaced prostheses:</strong></p>
<p>
This exercise primarily relies on the use of natural language to facilitate communication between the expert programmer and apprentice AI system. The AI system learns to use natural language in much the same way as a human apprentice would &#8212; as a flexible and expressive tool to capture and convey understanding and recognize and resolve misunderstanding and ambiguity. The AI system interacts with computing hardware through a highly instrumented integrated development environment. Essentially, the AI system can read, write, execute and debug code by simply thinking &#8212; reading and writing to a differentiable neural computing interface&nbsp;[<a href="#node_bib_40">40</a>]. It can also directly sense code running by reading from <tt>STDERR</tt> and <tt>STDIO</tt>, parsing output from the debugger and collecting and analyzing program traces. The same principles could be applied to develop digital prostheses employed for a wide range of intelligence-enhancing human-computer interfaces.</p>
<p>
</p>
<p>
</p>
<a name="node_sec_1.1"></a>
<h2 class=section><a href="#node_toc_node_sec_1.1">1.1&nbsp;&nbsp;Resources</a></h2>
<p></p>
<p>
</p>
<p>
This document attempts to optimize for the student or software engineer knowledgeable about neural networks and interested primarily in understanding how one might go about building a system along the lines of the programmer's apprentice. It is my experience that this audience has relatively little appetite for details about relevant work in cognitive and systems neuroscience that has informed the design sketched in these pages. The course website for the class I taught at Stanford in the 2018 Spring quarter serves as an extensive resource for those reading this document. It includes all of the <a href="https://web.stanford.edu/class/cs379c/calendar.html">lectures</a> and <a href="https://web.stanford.edu/class/cs379c/class_messages_listing/index.html">discussion notes</a> for the class and I refer to it often in this document as a source of supplementary information.</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
<a name="foundation_cognitive_neuroscience"></a>
</p>
<a name="node_sec_2"></a>
<h1 class=section><a href="#node_toc_node_sec_2">2&nbsp;&nbsp;Foundation: The Cognitive Neurosciences</a></h1>
<p></p>
<p>
</p>
<p>
This document is not intended to provide the reader with a short course in cognitive science, artificial intelligence, natural language processing, machine learning, artificial neural networks, or automated code synthesis / automatic inductive programming, and is certainly not intended to cover all these disciplines in any but the most cursory of detail. The primary goal is to explore the possibility of building digital assistants that considerably extend our ability to solve complex engineering problems with a emphasis here on software engineering. A secondary goal is to explain how the field of neuroscience is helping to achieve our primary goal<a name="node_call_footnote_Temp_4"></a><sup><small><a href="#node_footnote_Temp_4">3</a></small></sup>.</p>
<p>
The fields of cognitive and systems neuroscience are playing an important role in directing and accelerating research on artificial neural network systems. Much of this work predates and helped give rise to the especially exciting work on connectionist models in the 1980s. However, in the nearly 40 intervening years, a great deal of progress has been made, much of it due to improved methods for studying the behavior of awake behaving animal subjects and human beings in particular. Indeed, this work is undergoing a renaissance fueled by even more powerful methods for observing brain activity in human beings in the midst of solving complex cognitive tasks.</p>
<p>
The field of automatic programming, after decades of steady, often quite practical research on using symbolic methods &#8212; much of it originating in labs outside the United States, is seeing a renewed interest in artificial neural networks. It remains to be seen whether artificial neural networks will have a significant impact on code synthesis, however there appear to be opportunities to leverage what we know about both natural and artificial neural networks to make progress, and hybrid systems that combine both connectionist and traditional symbolic methods may have the best chance of pushing the state-of-the-art significantly beyond its present level.</p>
<p>
</p>
<p>
</p>
<a name="node_sec_2.1"></a>
<h2 class=section><a href="#node_toc_node_sec_2.1">2.1&nbsp;&nbsp;Memory</a></h2>
<p></p>
<p>
</p>
<p>
We begin with the problem of how to represent information in memory. In the case of the programmer's apprentice, relevant information includes the type of items that software engineers routinely think about in plying their trade such as algorithms, data structures, interfaces, programs, subroutines and tools such as assemblers, compilers, debuggers, interpreters, parsers and syntax checkers. Then there are the things that programmers generally do not think about explicitly but that concern how they solve problems and organize their thoughts, including, for example, the design strategies we learn in computer science courses such as divide-and-conquer, dynamic-programming and recursion. Finally, there is strategic organizational information of a sort that plays a role in any complex individual or collaborative effort including plans, tasks, subtasks, specifications and requirements.</p>
<p>
All of this information has to be encoded in memory and made accessible when required to perform cognitive tasks. Information, whether in a computer or a brain, tends to move around depending on what is to be done with it, and, at least in biological brains, it is constantly changing<a name="node_call_footnote_Temp_7"></a><sup><small><a href="#node_footnote_Temp_7">6</a></small></sup>.
In biological brains, it is difficult if not impossible to think about something without changing it. In building systems inspired by biological brains we have somewhat more control over such changes, but control comes at a cost. We make no distinction between concrete and abstract thoughts &#8212; all thoughts are abstract whether they represent atoms or bits. We will on occasion refer to memories as being short- or long-term but the distinction doesn't begin to address real issues. When we talk about episodic memory, it may seem that we are referring to some sort of permanent or archival memory, but that's not the case.</p>
<p>
Since this document is more condensed precis than unabridged thesis, we need some way of navigating the huge space of ideas relating to biological and artificial brains as they pertain to building digital assistants and automatic programming. I'll begin by pointing out that language, programs and plans are all usefully thought of as having hierarchical, recursive structure. It also makes sense to think of brains as being organized as such&nbsp;[<a href="#node_bib_4">4</a>,&nbsp;<a href="#node_bib_55">55</a>,&nbsp;<a href="#node_bib_23">23</a>,&nbsp;<a href="#node_bib_36">36</a>,&nbsp;<a href="#node_bib_22">22</a>,&nbsp;<a href="#node_bib_48">48</a>], and the human brain apparently employs hierarchical models to make sense of the world in which it evolved. </p>
<p>
To the untutored mind, the world is essentially flat. We impose hierarchical structure to make understanding it more tractable. We ingest sequences of observations as input and execute sequences of actions as output. What goes on between is complicated. Rather than immediately focusing on how biological and artificial brains learn and apply hierarchical models, we start by considering the simpler problem of how we might represent a <i>subroutine</i>, the smallest fungible unit of activity for our purposes. Subroutines can be used to kick a soccer ball or implement simple program transformations in a neural-network architecture.</p>
<p>
</p>
<p>
<a name="convention_and_abbreviation_index"></a>
The following assumes familiarity with artificial neural networks<a name="node_call_footnote_Temp_8"></a><sup><small><a href="#node_footnote_Temp_8">7</a></small></sup>. 
We begin with the simplifying assumption that subroutines can be represented as tuples consisting of a set of operands represented as high-dimensional embedding vectors, a weight matrix representing the transformation and a product vector space in which to embed the result. In applying this idea to program transformations, assume that each operand corresponds to the embedding of an abstract-syntax-tree representation of a code fragment, w.l.o.g., any non-terminal node in the AST of a syntactically well-formed program. In the remainder of this section and the next, we use the following abstractions and abbreviations:
</p>
<ul>
<li><p><i>prefrontal cortex</i> (PFC) including attention, conscious access, reward-based-learning and executive control&nbsp;[<a href="#node_bib_98">98</a>,&nbsp;<a href="#node_bib_54">54</a>];
</p>
<li><p><i>entorhinal-hippocampal complex</i> (EHC) in its role as primary interface between the hippocampus and neocortex&nbsp;[<a href="#node_bib_70">70</a>,&nbsp;<a href="#node_bib_67">67</a>];
</p>
<li><p><i>global workspace</i> (GW) broadly distributed cortical circuits connected through long-range excitatory axons<a name="node_call_footnote_Temp_9"></a><sup><small><a href="#node_footnote_Temp_9">8</a></small></sup>&nbsp;[<a href="#node_bib_26">26</a>,&nbsp;<a href="#node_bib_3">3</a>];
</p>
<li><p><i>basal ganglia</i> (BG) for its role in action selection and dynamic gating to direct input to the prefrontal cortex[<a href="#node_bib_69">69</a>,&nbsp;<a href="#node_bib_54">54</a>];
</p>
<li><p><i>semantic memory system</i> (SMS) including areas of the brain responsible for mathematical and abstract thought&nbsp;[<a href="#node_bib_94">94</a>,&nbsp;<a href="#node_bib_8">8</a>];
</p>
<li><p><i>episodic memory system</i> (EMS) including episodic memory management and memory-based parameter adaptation&nbsp;[<a href="#node_bib_88">88</a>,&nbsp;<a href="#node_bib_76">76</a>];
</p>
<li><p><i>differentiable neural computer</i> (DNC) as the interface to the integrated development environment prostheses&nbsp;[<a href="#node_bib_40">40</a>,&nbsp;<a href="#node_bib_39">39</a>];
</p>
<li><p><i>abstract syntax-tree</i> (AST) is a representation of the abstract syntactic structure of a source-code program<a name="node_call_footnote_Temp_10"></a><sup><small><a href="#node_footnote_Temp_10">9</a></small></sup>&nbsp;[<a href="#node_bib_28">28</a>,&nbsp;<a href="#node_bib_99">99</a>];
</ul><p></p>
<p>
The second introductory lecture (<a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/05/slides/index.html">HTML</a>) for the Stanford <a href="https://web.stanford.edu/class/cs379c/">course</a> associated with this document provides a high-level overview of the relevant research in cognitive and systems neuroscience. Annotations of the form &quot;Slide #&quot; link to relevant slides in the introductory lecture. For example <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/05/slides/index.html#CS379C_INTRODUCTORY_LECTURE_2_SLIDE_02">Slide&nbsp;2</a> covers the key anatomical landmarks in the human brain mentioned in this document. While the material in the remainder of this section refers to work in cognitive and systems neuroscience, the discussion here emphasizes applications of what we've learned from neuroscience, and so the interested reader is encouraged to at least skim the above-linked lecture notes.</p>
<p>
</p>
<p>
Referring to the abstractions and abbreviations introduced in the previous section, reading a program from <tt>STDIO</tt> &#8212; the analog of a human programmer reading a program displayed on a monitor &#8212; will result in &#8212; at least &#8212; two different internal representations of the resulting AST: an embedding vector in the SMS and a key-value representation in the DNC. The former allows us manipulate programs and program fragments as fully-differentiable representations within distributed models. The latter allows us to modify, execute and share code in a human-accessible format, fully compatible with our software-development toolchain.</p>
<p>
Following&nbsp;[<a href="#node_bib_76">76</a>], we assume EMS consists of initial-state-action-reward-next-state tuples of the form (<em>s</em><sub><em>t</em></sub>,<span style="margin-left: .27778em">&zwnj;</span><em>a</em><sub><em>t</em></sub>,<span style="margin-left: .27778em">&zwnj;</span><em>r</em><sub><em>t</em></sub>,<span style="margin-left: .27778em">&zwnj;</span><em>s</em><sub><em>t</em>+1</sub>). State representations <em>s</em><sub><em>t</em></sub> have to be detailed enough to reconstruct the context in which the action is performed and yet concise enough to be practical. Suppose the PFC directs the activation of selected circuits in the SMS via the global workspace (GW) &#8212; see Slides&nbsp;<a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/05/slides/index.html#CS379C_INTRODUCTORY_LECTURE_2_SLIDE_03">3</a> and&nbsp;<a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/05/slides/index.html#CS379C_INTRODUCTORY_LECTURE_2_SLIDE_05">5</a> &#8212; in accord with Dehaene&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_27">27</a>,&nbsp;<a href="#node_bib_25">25</a>] assuming a prior that generates low-dimensional thought vectors&nbsp;[<a href="#node_bib_5">5</a>]. The state representation <em>s</em><sub><em>t</em></sub> encodes the attentional state that served to identify representations in SMS relevant to <em>a</em><sub><em>t</em></sub> allowing the EHC to produce the resulting state <em>s</em><sub><em>t</em>+1</sub>. Given <em>s</em><sub><em>t</em></sub> we can reproduce the activity recorded in the EMS, and, in principle, incorporate multiple steps and contingencies in a policy constituting a specialized program-synthesis or program-repair subroutine.</p>
<p>
Such subroutines would include repairing a program in which a variable is introduced but not initialized, or when it is initialized but ambiguously typed or scoped. As another example, a variable is initialized as <tt>VOID</tt> and subsequently assigned an integer value in some but not all branches of a conditional statement. Other examples of repair routines include problems with the use of comparison operators, e.g., conditional branches both with &le;, the <tt>is</tt> operator is used instead of <tt>is not</tt>, or vice versa, confusion involving <tt>A is not None</tt>, <tt>A not None</tt> and <tt>A != None</tt>, and problems involving class methods, e.g., when <tt>self</tt> accessor is missing from a variable, e.g., <tt>mode = 'manual'</tt> instead of <tt>self.mode = 'manual'</tt>&nbsp;[<a href="#node_bib_85">85</a>,&nbsp;<a href="#node_bib_28">28</a>,&nbsp;<a href="#node_bib_99">99</a>].</p>
<p>
Attentional machinery in the prefrontal cortex (PFC) populates the (GW) by activating circuits relevant to the current input and internal state, including that of the DNC and any ongoing activity in (SMS) circuits produced by previous top-down attention and bottom-up sensory processing. The PFC in its role as executive arbiter identifies operators in the form of policy subroutines and then enlists the EHC to &#8212; using terminology adapted from Von Neumann machines &#8212; to load registers in short-term memory and perform operations by using fast weights to transform the contents of the loaded registers into product representations that can either be fed to associative embeddings, temporarily stored in other registers or used to modify the contents of the DNC thereby altering the AST representation of the target code and updating the display to provide feedback to the human programmer.</p>
<p>
The primate cortex appears to be tiled with columnar structures referred to as <i>cortical columns</i>. Some neuroscientists believe that all of these columns compute the same basic function. However, there is considerable variation in cell type, thickness of the cortical layers, and the size of the dendritic arbors to question this hypothesis. The prefrontal cortex is populated with a type of neuron, called a <i>spindle neuron</i>, similar in some respects to the <i>pyramidal cells</i> found throughout the cortex, that allow rapid communication across the large brains of great apes, elephants, and cetaceans. Although rare in comparison to other neurons, spindle neurons are abundant and quite large in humans and apparently play an important role in consciousness and attentional networks &#8212; see <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/05/slides/index.html#CS379C_INTRODUCTORY_LECTURE_2_SLIDE_04">Slide&nbsp;4</a>.</p>
<p>
The corresponding artificial neural network architecture for the programmer's apprentice application consists of a hierarchy of specialized networks with a relatively dense collection of feedforward and feedback connections that enable recurrent state, attentional focus and the management of specialized memory systems that persists across different temporal scales &#8212; see <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/05/slides/index.html#CS379C_INTRODUCTORY_LECTURE_2_SLIDE_06">Slide&nbsp;6</a>. Individual networks are specialized to serve different types of representation, employing convolutional networks, gated-feedback recurrent networks and specialized embedding models. All of these networks are distributed representations that encode information in high-dimensional vector spaces such that different dimensions can be trained to represent different features allowing attentional mechanisms to emphasize or modify encodings so as to alter their meaning.</p>
<p>
These attentional networks are connected to regions throughout the cortex and are trained via reinforcement learning to recognize events worth attending to according to the learned value function. Using extensive networks of connections &#8212; both incoming and outgoing, attentional networks are able to create a composite representation of the current situation that can serve a wide range of executive cognitive functions, including decision making and imagining possible futures. The basic idea of a neural network trained to attend to relevant parts of the input is key to a number of the systems that we'll be looking at.</p>
<p>
To understand attentional networks, think about an encoder-decoder network for machine translation. As the encoder digests each word in the sequence of words that constitute the input sentence, it produces a representation &#8212; Geoff Hinton refers to these as <i>thought clouds</i> in analogy to the iconic clouds that you see in comic strips &#8212; of the sentence fragment or <i>prefix</i> that it has seen so far. Because the sentence is ingested one word at a time &#8212; generally proceeding from left to right &#8212; the resulting thought cloud will tend to emphasize the meaning of the most recently ingested words in each prefix. You could encode the entire input sentence and then pass the resulting representation on to the decoder, but earlier words in the sentence will receive less attention that later words. Alternatively, you could introduce a new network layer that takes as input encodings of all the sentence prefixes seen so far and trains the new layer &#8212; thereby taking advantage of the power of gradient descent &#8212; to produce a composite representation that emphasizes those parts of the input that are most relevant in decoding / generating the next word in the output.</p>
<p>
The programmer's apprentice is implemented as an instance of an hierarchical neural network architecture. It has a variety of conventional inputs that include speech and vision, as well as output modalities including speech and text. In these respects, it operates like most existing commercial personal assistants &#8212; see <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/05/slides/index.html#CS379C_INTRODUCTORY_LECTURE_2_SLIDE_07">Slide&nbsp;7</a>. It differs substantially, however, in terms of the way in which the apprentice interacts with the programmer. It is useful to think of the programmer and apprentice as pair programming, with the caveat that the programmer is in charge, knows more than the apprentice does &#8212; at least initially, and is invested in training the apprentice to become a competent software engineer. One aspect of their joint attention is manifest in the fact that they share a browser window. The programmer interacts with the browser in a conventional manner while the apprentice interacts with it as though it is part of its body directly reading and manipulating the HTML using the browser API. The browser serves both programmer and apprentice as an encyclopedic source of useful knowledge as well as another mode of interaction and teaching.</p>
<p>
The spatial relationships among the ganglion cells in the retina are preserved in the activity of neurons found in the primary visual &#8212; or <i>striate</i> &#8212; cortex. Most sensory and motor areas maintain similar modality-specific topographic relationships. Shown <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/05/slides/index.html#CS379C_INTRODUCTORY_LECTURE_2_SLIDE_10">here</a>, for example, are Wilder Penfield's famous motor and somatosensory <a href="https://en.wikipedia.org/wiki/Cortical_homunculus">homunculi</a> depicting the areas and proportions of the human brain dedicated to processing motor and sensory functions. Scientists have observed that the area devoted to the hands tend to be larger among pianists, while the relevant areas in the brains of amputees typically become significantly smaller &#8212; see <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/05/slides/index.html#CS379C_INTRODUCTORY_LECTURE_2_SLIDE_10">Slide&nbsp;10</a>.</p>
<p>
We imagine the programmer's apprentice with a body part consisting of an instrumented <i>integrated development environment</i> (IDE). Alternatively you might think of it as a prosthetic device. It is not, however, something that you can simply remove or replace with an alternative device outfitted with a different interface or supporting different functions and expect it to immediately respond to your attempts to control it &#8212; it is not a plug-and-play device. Like the legs you were born with or the prosthesis replacing an amputee's severed arm, you have to learn how to use these devices. Architecturally, the apprentice's prosthetic IDE is an instance of a <i>differentiable neural computer</i> (DNC) introduced by Alex Graves and his colleagues at DeepMind. The assistant combined with its prosthetic IDE is neural network that can read from and write to an external memory matrix, combining the characteristics of a random-access memory and set of memory-mapped device drivers and programmable interrupt controllers. The interface supports a fixed number of commands and channels that provide feedback. You can think of it as roughly similar to an Atari game console &#8212; see <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/05/slides/index.html#CS379C_INTRODUCTORY_LECTURE_2_SLIDE_11">Slide&nbsp;11</a>.</p>
<p>
What is left out of this account so far includes how we might take advantage of semantics in the form of executing code and examining traces in order to better understand the consequences of the changes just made. Presumably, wrapping a code fragment in a function and executing the function with different input to examine changes in the state variables could be used as a distal reinforcement signal providing intermediate rewards useful in debugging subroutines. As pointed out earlier, subroutines designed to modify code are likely to involve many conditional choices and so it is important for subroutine policies to be highly conditioned on the status of specific state variables. Indeed a technique such as model-based parameter adaptation may be perfectly suited to providing such context-sensitive adaptations.</p>
<p>
Perhaps this next observation seems obvious, but it is worth keeping in mind that the human brain does a great deal of (parallel) processing that never rises to the level of conscious attention. The executive control systems in the prefrontal cortex don't have micromanage everything. Every thought corresponds to a pattern of activity in one or more neural circuits in the brain or beyond in the peripheral nervous system. One pattern of activity inevitably leads to another in the same or another set of neurons. For example, patterns of activity that begin in the sensory cortex can lead to patterns of activity in the motor cortex and can have consequences elsewhere in the brain, e.g., in the cerebellar cortex resulting in speech, or external to the central nervous system as in the case of neurons that propagate through the peripheral nervous system causing muscles to contract and extend thereby making your limbs and torso move. </p>
<p>
Every new observation, every act of creating a new thought or revisiting an old one produces even more activity in the brain resulting in new thoughts some of which are ignored as their reverberations weaken and die and others that spawn new thoughts and proliferate under the influence of reentrant production of activity and the active encouragement of conscious attention in a perpetually self reinforcing, reimagining and self-analyzing cycle of recurrent activity. Meta-reinforcement learning supports the sort of diverse activity one might expect from a system that selects activity to attend to and then makes available in the global workspace for ready access by other systems. Sustaining a collection of such activated circuits would help to provide a context, serve to maintain a stack of policies, guide switching between them, support caching partial results for later use, reconstructing necessary state as needed when restoring policy after a recursive descent.</p>
<p>
When you think of building systems that can develop new algorithms it is instructive the think about the simple case of learning to sort lists from input-output pairs. The bubble sort algorithm is generally regarded as the easiest to come up with, but even then it is easier if you start with simple I/O pairs like [<em>A</em>,<span style="margin-left: .27778em">&zwnj;</span><em>B</em>] &rarr; [<em>A</em>,<span style="margin-left: .27778em">&zwnj;</span><em>B</em>], [<em>B</em>,<span style="margin-left: .27778em">&zwnj;</span><em>A</em>] &rarr; [<em>A</em>,<span style="margin-left: .27778em">&zwnj;</span><em>B</em>] and work up to longer lists &#8212; referred to as curriculum learning&nbsp;[<a href="#node_bib_6">6</a>]. As Dan Abolafia pointed out in his class <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/24/index.html">presentation</a>, it is relative easy to learn to sort lists of length no more than <em>n</em>, but substantially more difficult to learn an algorithm that works for lists of arbitrary length, without the ability to construct a simple inductive proof of correctness. Logic and basic theorem proving are certainly important in learning to write programs. You might want to look at the Coq proof assistant<a name="node_call_footnote_Temp_11"></a><sup><small><a href="#node_footnote_Temp_11">10</a></small></sup> for a glimpse at the future of algorithm development.</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
<a name="fig_Integrated_Architecture_Integrated_Figure"></a>
</p>
<a name="node_fig_Temp_12"></a>
<div class=:figure align=center><table width=100%><tr><td align=center><hr>
<p>
</p>
<div align=center><table><tr><td>

<img width=722 src="./figures/Integrated_Architecture_Integrated_Figure.jpg"></td></tr></table></div>

</td></tr>
<tr><td align=left><b>Figure 1:</b>&nbsp;&nbsp;This figure highlights the primary architectural components mentioned in the main text superimposed over an anatomical rendering of the human brain identifying related cortical and sub-cortical landmarks. The triangle and three ovals and match the shape and color conventions employed in O'Reilly&nbsp;[<a href="#node_bib_67">67</a>] where you will find a substantially more detailed explanation of the underlying biological model. The three gold square shapes denote abstract architectural structures and not anatomical features. The acronyms are expanded and explained <a href="#convention_and_abbreviation_index">here</a>.</td></tr>
<tr><td>
<hr>
<p>
</p>
</td></tr></table></div><p></p>
<p>
</p>
<p>
Figure&nbsp;<a href="#fig_Integrated_Architecture_Integrated_Figure">1</a> shows a diagram of the human brain overlaid with a simplified architectural drawing. The box shapes represent abstract systems and the oval and triangular shapes represent anatomical features for which we can supply computational models. For example, the box labeled GW represents the global workspace which performs a particular function in the architecture, but actually spans a good portion of the neocortex. Whereas the triangle labeled BG represents a group of subcortical nuclei called the basal ganglia situated at the base of the forebrain.</p>
<p>
The box labeled AST represents a form of sensory input corresponding to the ingestion of abstract syntax trees representing code fragments. The oval labeled SMS represents semantic memory and the box labeled DNC corresponds to a differentiable neural computer. When the system ingests a new program fragment the resulting AST is encoded in the SMS as an embedding vector and simultaneously as a set of key-value pairs in the DNC. Here we think of the DNC as a body part or external prosthesis with corresponding maps in the somatosensory and motor cortex that enable reading and writing respectively &#8212; see Slides&nbsp;<a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/05/slides/index.html#CS379C_INTRODUCTORY_LECTURE_2_SLIDE_10">10</a> and&nbsp;<a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/05/slides/index.html#CS379C_INTRODUCTORY_LECTURE_2_SLIDE_11">11</a> mentioned earlier.</p>
<p>
Our explanation of the architecture proceeds top down, as it were, with a discussion of executive function in the prefrontal cortex. The GW provides two-way connection between structures in the prefrontal cortex and homologous structures of a roughly semantic character throughout the rest of neocortex thereby enabling the PFC to listen in on diverse circuits in the neocortex and select a subset of such circuits for attention. Stanislas Dehaene describes this process as one of the primary functions of consciousness, but we need not commit ourselves to such interpretation here.</p>
<p>
Not only does the PFC selectively activate circuits but it can also maintain the activity such circuits indefinitely as constituents of working memory. Since this capability is limited by the capacity of the PFC, the content of working memory is limited and adding new constituents may curtail the activation of existing constituents. In practice, we intend to model this capability using meta-reinforcement learning&nbsp;[<a href="#node_bib_98">98</a>] (MRL) in which the MRL system relies on the GW network to sample, evaluate and select constitutuent circuits guided by a suitable prior&nbsp;[<a href="#node_bib_5">5</a>] and past experience and then maintain their activity by a combination of memory networks&nbsp;[<a href="#node_bib_102">102</a>] and fast weights&nbsp;[<a href="#node_bib_2">2</a>]. </p>
<p>
</p>
<p>
Meta-reinforcement learning serves a second complementary role in the PFC related to executive function. We will refer to the first role as MRL-A for &quot;attention&quot; and the second as MRL-P for &quot;planning&quot;. MRL-A is trained to focus attention on relevant new sensory input and new interpretations of and associations among prior perceptions and thoughts. MRL-P is trained to capitalize on and respond to opportunities made available by new and existing constituents in working memory. Essentially MRL-P is responsible for the scheduling and deployment of plans relevant to recognized opportunities to act. These plans are realized as policies trained by reinforcement learning from traces of past experience or constructed on the fly in response to unexpected / unfamiliar contingencies by recovering and reimagining past activities recovered from episodic memory &#8212; see&nbsp;<a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/05/slides/index.html#CS379C_INTRODUCTORY_LECTURE_2_SLIDE_13">Slide&nbsp;13</a>.</p>
<p>
MRL-A and MRL-P could be implemented as a single policy, but it is simpler to think of them as two coupled systems, one responsible for focusing attention by constantly assessing changes in (neural) activity throughout the global workspace, and a second responsible for overseeing the execution of plans in responding to new opportunities to solve problems. MRL-A is as a relatively straightforward reinforcement learning system independently performing its task largely a function of whatever neural activity is going on in the GW, its attentional network and the prior baked into its reward function. MRL-P could be implemented along the lines of the Imagination-Augmented Agent (I2A) architecture&nbsp;[<a href="#node_bib_101">101</a>] or the related Imagination-Based Optimization&nbsp;[<a href="#node_bib_46">46</a>] and Imagination-Based Planning&nbsp;[<a href="#node_bib_72">72</a>] systems.</p>
<p>
</p>
<p>
The remaining parts of the architecture involve the interplay between the PFC and the semantic and episodic memory systems as facilitated by the basal ganglia and hippocampus. If we had a policy pre-trained for every possible contingency, we would be nearly done &#8212; let MRL-A draw attention to relevant internal and external activity and then design a simple just-in-time greedy scheduler that picks the policy with the highest reward given the state vector corresponding to the current content of working memory. Unfortunately, the life of an apprentice programmer is not nearly so simple. The apprentice might listen to advice from a human programmer or watch someone solve a novel coding problem or repair a buggy program. Alternatively, it may be relatively simple to adapt an existing policy to work in the present circumstances. However, making progress on harder problems will depend on expert feedback or having an existing reward function that generalizes to the problem at hand. </p>
<p>
The hippocampus is perhaps best known for its role in supporting spatial reasoning. A type of pyramidal neuron called a <i>place cell</i> has been shown to become active when an experimental animal enters an area of a maze that it has visited before. However, the hippocampus plays a much larger role in memory by representing not just the &quot;where&quot; of experience but also the &quot;when&quot;. The manner in which we employ short- and long-term memory is very different. We might construct a representation of our current situation in short-term memory, drawing upon our long-term memory to provide detail. </p>
<p>
The two memory systems are said to be complementary in that they serve different purposes, one provides an archival record of the past while the other serves as a scratchpad for planning purposes. In retrieving a memory there is a danger that we corrupt the long-term memory in the process of subsequent planning. This isn't simply an academic question, it is at the heart of how we learn from the past and employ what we've learned to think about the future. Our subtle memory systems enable us to imagine solutions to problems that humans have never faced, and account for a good deal of our incredible adaptivity. In several lectures, we will explore architectures that support such flexibility &#8212; see <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/05/slides/index.html#CS379C_INTRODUCTORY_LECTURE_2_SLIDE_14">Slide&nbsp;14</a>.</p>
<p>
</p>
<p>
</p>
<a name="node_sec_2.2"></a>
<h2 class=section><a href="#node_toc_node_sec_2.2">2.2&nbsp;&nbsp;Actions</a></h2>
<p></p>
<p>
</p>
<p>
The basal ganglia in cognitive models such as the one described by Randall O'Reilly's in his <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/12/index.html">presentation</a> in class, play a central role in action selection. This seems like a good opportunity to review how actions are represented in deep-neural-network implementations of reinforcement learning. Returning to our default representation for the simplest sort of episodic memory, (<em>s</em><sub><em>t</em></sub>,<span style="margin-left: .27778em">&zwnj;</span><em>a</em><sub><em>t</em></sub>,<span style="margin-left: .27778em">&zwnj;</span><em>r</em><sub><em>t</em></sub>,<span style="margin-left: .27778em">&zwnj;</span><em>s</em><sub><em>t</em>+1</sub>), it’s easy to think of a state <em>s</em> as a vector <em>s</em> &isin; &reals;<sup><em>n</em></sup> and a reward <em>r</em> as a scalar value, <em>r</em> &isin; &reals;, but how are actions represented?</p>
<p>
Most approaches to deep reinforcement learning employ a tabular model of the policy implying a finite &#8212; and generally rather small &#8212; repertoire of actions. For example, most of the experiments described in Wayne&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_100">100</a>] (MERLIN) six-dimensional one-hot binary vector that maps a set of six actions: move forward, move backward, rotate left with rotation rate of 30, rotate right with rotation rate of 30, move forward and turn left, move forward and turn right. The action space for the grid-world problems described in Rabinowitz&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_78">78</a>] (ToMnets) consists of four movement actions: up, down, left, right and stay &#8212; see <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/05/slides/index.html#CS379C_INTRODUCTORY_LECTURE_2_SLIDE_15">Slide&nbsp;15</a>.</p>
<p>
The programmer's apprentice (PA) operates on programs represented as trees, where the set of actions includes basic operations for traversing and editing trees &#8212; or more generally directed-graphs with cycles if you assume edges in abstract syntax trees corresponding to loops, recursion and nested procedure calls, i.e., features common to nearly all the programs we actually care about. We still have a finite number of actions since for any given project we can represent the code base as a directed-acyclic graph with annotations to accommodate procedure calls and recursion, and use attention to direct and contextualize a finite set of edit operations<a name="node_call_footnote_Temp_13"></a><sup><small><a href="#node_footnote_Temp_13">11</a></small></sup>.</p>
<p>
Pritzel&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_77">77</a>] employ a semi-tabular representation of an agent's experience of the environment possessing features of episodic memory including long-term memory, sequentiality and context-based lookups. The representation called a <i>differential neural dictionary</i> (DND) is related to Graves&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_40">40</a>] DNC. The programmer's apprentice is better suited to Vinyals&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_95">95</a>] related idea of a <i>pointer-network</i> designed to learn the conditional probability of an output sequence with elements that are discrete tokens corresponding to positions in an input sequence &#8212; see related work in natural language processing by Merity&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_59">59</a>] on <i>pointer sentinels</i>.</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
<a name="fig_SeeetalACL-17_Figure_03"></a>
</p>
<a name="node_fig_Temp_14"></a>
<div class=:figure align=center><table width=100%><tr><td align=center><hr>
<p>
</p>
<div align=center><table><tr><td>

<img width=722 src="./figures/SeeetalACL-17_Figure_03.png"></td></tr></table></div>

</td></tr>
<tr><td align=left><b>Figure 2:</b>&nbsp;&nbsp;The sequence-to-sequence encoder-decoder attentional model shown here uses a specialized memory called a <i>pointer network</i> to construct a short summary of a source document by flexibly combining phrases from the source document with words from its existing vocabulary. For each decoder timestep a generation probability <em>P</em>gen &isin; [0, 1] is calculated, which weights the probability of <i>generating</i> words from the vocabulary, versus <i>copying</i> words from the source text. The vocabulary distribution and the attention distribution are weighted and summed to obtain the final distribution, from which we make our prediction. Note that out-of-vocabulary article words such as &quot;2-0&quot; are included in the final distribution. &#8212; adapted from See&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_84">84</a>].</td></tr>
<tr><td>
<hr>
<p>
</p>
</td></tr></table></div><p></p>
<p>
</p>
<p>
<a name="automated_programming_code_repair"></a>
One approach involves representing a program as an abstract syntax tree and performing a series of repairs that involve replacing complete subtrees in the AST. It might be feasible to use some variant of the pointer-network concept, e.g., [<a href="#node_bib_7">7</a>], [<a href="#node_bib_84">84</a>] and  [<a href="#node_bib_97">97</a>] or neural programmer framework [<a href="#node_bib_65">65</a>], but there are limitations with all of the alternatives I've run across so far, requiring additional innovation to deal with the dynamic character of editing AST representations, but at least the parsing problem is solved for us &#8212; all we have to do is make sure that our edits maintain syntactic well-formedness.</p>
<p>
Most of the existing pointer-network applications analyze / operate on a fixed structure such as a road map, e.g., examples include the planar graphs that Oriol Vinyals addresses in his paper&nbsp;[<a href="#node_bib_95">95</a>], recognizing long-range dependencies in code repositories&nbsp;[<a href="#node_bib_7">7</a>], and annotating text to support summarization&nbsp;[<a href="#node_bib_84">84</a>]. Student projects focusing on program-repair might try ingesting programs using an LSTM, creating a pointer-network / DNC-like representation of the AST and then altering selected programs by using fragments from other programs, but be advised this approach will likely require inventing extensions to existing pointer-network techniques.</p>
<p>
One possibility for training data is to use the ETH / SRI Python <a href="https://www.sri.inf.ethz.ch/py150">dataset</a> that was developed by Veselin Raychev as part of his <a href="https://www.sri.inf.ethz.ch/raychev_thesis.pdf">thesis</a> on automated code synthesis<a name="node_call_footnote_Temp_15"></a><sup><small><a href="#node_footnote_Temp_15">12</a></small></sup>.
Possible projects include designing a rewrite system for code synthesis based on NLP work from Chris Manning's lab led by Abigail See focusing on text summarization leveraging pointer networks &#8212; see Figure&nbsp;<a href="#fig_SeeetalACL-17_Figure_03">2</a> for a schematic description of the model from their paper&nbsp;[<a href="#node_bib_84">84</a>]. Further afield are program synthesis papers that work starting from specifications like Shin&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_85">85</a>] out of Dawn Song's lab or recent work from Rishabh Singh and his colleagues&nbsp;[<a href="#node_bib_99">99</a>].</p>
<p>
Another possibility is to use RL to learn repair rules that operate directly on the AST using various strategies. It's not necessary in this case to represent the AST as a pointer network, but, rather, take the expedient of simply creating a new embedding edited AST after each repair. We can generate synthetic data by taking correct programs from the ETH / SRI dataset and introducing bugs and then use these to generate a reward signal, with harder problems requiring two or three separate repairs. </p>
<p>
It might also be worth exploring the idea of working with program embedding vectors in a manner similar to performing arithmetic operations on word vectors in order to recover analogies &#8212; see the analysis of Levy and Goldberg&nbsp;[<a href="#node_bib_57">57</a>] in which they demonstrate that analogy recovery is not restricted to simple neural word embeddings. For example, given the AST for a program <tt>P</tt> with subtree <tt>Q</tt> and two possible repairs that correspond to replacing <tt>Q</tt> with either <tt>R</tt> or <tt>R'</tt>, can we determine which is the better outcome <tt>A = P - Q + R</tt> or <tt>A' = P - Q + R'</tt> and might it serve as a distal reward signal to expedite training?</p>
<p>
I also recommend Reed and de Freitas&nbsp;[<a href="#node_bib_79">79</a>] for its application of the idea of using dynamically programmable networks in which the activations of one network become the weights (program) of another network.  The authors note that this approach was mentioned in Sigma-Pi units section of Rumelhart&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_83">83</a>], appeared in Sutskever and Hinton&nbsp;[<a href="#node_bib_90">90</a>] in the context of learning higher order symbolic relations and in Donnarumma&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_29">29</a>] as the key ingredient of an architecture for prefrontal cognitive control.</p>
<p>
</p>
<p>
</p>
<a name="node_sec_2.3"></a>
<h2 class=section><a href="#node_toc_node_sec_2.3">2.3&nbsp;&nbsp;Resources</a></h2>
<p></p>
<p>
</p>
<p>
Michael Graziano's <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/10/index.html">presentation</a> on machines that incorporate an internal model of what consciousness is and attribute that model to themselves and others to make predictions about human behavior&nbsp;[<a href="#node_bib_41">41</a>]<a name="node_call_footnote_Temp_16"></a><sup><small><a href="#node_footnote_Temp_16">13</a></small></sup>.<p>
Randall O'Reilly's <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/12/index.html">presentation</a> on learning mechanisms that rely on a computational model of the prefrontal cortex to control both itself and other brain areas in a strategic, task-appropriate manner&nbsp;[<a href="#node_bib_68">68</a>]<a name="node_call_footnote_Temp_17"></a><sup><small><a href="#node_footnote_Temp_17">14</a></small></sup>.<p>
Jay McClelland's <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/19/index.html">presentation</a> on complementary learning systems that avoid catastrophic forgetting and support the stable learning of new knowledge and learning with imbalanced class labels&nbsp;[<a href="#node_bib_88">88</a>]<a name="node_call_footnote_Temp_18"></a><sup><small><a href="#node_footnote_Temp_18">15</a></small></sup>.<p>
Matt Botvinick's <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/26/index.html">presentation</a> describing a new model of reward-based learning in which a traditional dopamine system trains the prefrontal cortex to operate as its own free-standing learning system&nbsp;[<a href="#node_bib_98">98</a>]<a name="node_call_footnote_Temp_19"></a><sup><small><a href="#node_footnote_Temp_19">16</a></small></sup>.<p>
</p>
<p>
</p>
<p>
</p>
<p>
<a name="collabration_communication_value"></a>
</p>
<a name="node_sec_3"></a>
<h1 class=section><a href="#node_toc_node_sec_3">3&nbsp;&nbsp;Interaction: Natural Language Processing</a></h1>
<p></p>
<p>
</p>
<p>
The brain didn't evolve to accommodate language, rather, language evolved to accommodate the brain&nbsp;[<a href="#node_bib_15">15</a>]. Biological and cognitive constraints determine what types of linguistic structure are learned, processed and transmitted from person to person and generation to generation. Language acquisition has comparatively little to do with linguistics and is probably best viewed as a form of skill acquisition. Indeed, we are constantly processing streams of sensory information into successively more abstract representations while simultaneously learning to recode the compressed information into hierarchies of skills that serve our diverse purposes&nbsp;[<a href="#node_bib_16">16</a>,&nbsp;<a href="#node_bib_17">17</a>].</p>
<p>
Contrary to what some textbook authors might think, students learn to code by writing programs, a process that can be considerably accelerated by timely communication with peers and invested collaborators. In the case of unequal skill levels, communication tends to be on the terms of the more capable interlocutor, and the onus of understanding on the less capable partner in the collaboration. To sustain the collaboration, we need to bootstrap the apprentice to achieve a reasonble threshold level of competence in both language and in working with computers so as to compensate for expert programmer's investment in effort. From a value-proposition perspective, the apprentice has to provide net positive benefit to the programmer from day one.</p>
<p>
It is important to keep in mind that any program specification whether in the form of input/output pairs or natural language descriptions when communicated between individuals of differing expertise is just the beginning of a conversation. Experts are often careless in specifying computations and assume too much of the student. Students, on the other hand, can surprise experts with their logical thinking while frustrate and disappoint with their difficulty in handling ambiguity and analogy, particularly of the esoteric sort familiar to professional programmers. Input from an expert will typically consist of a stream of facts, suggestions, heuristics, shortcuts, etc., peppered with clarifications, interruptions and other miscellany.</p>
<p>
We propose a hybrid system for achieving competence in communicating programming knowledge and collaboratively generating software by creating a non-differentiable conventional dialogue management system that works in tandem with a differentiable neural-network dialogue system (NDS) that will become more competent as it gains experience coding and collaborating with its expert partner. The deployment of these two language systems will be controlled on a sentence-by-sentence basis by a meta-reinforcement learning (MRL) system that will depend less and less on the more conventional system but likely never entirely eclipse its utility. The MRL system subsumes the role of a beam search or softmax layer in an encoder-decoder dialogue model. </p>
<p>
</p>
<p>
The conventional system will be built as a hierarchical planner<a name="node_call_footnote_Temp_20"></a><sup><small><a href="#node_footnote_Temp_20">17</a></small></sup>
following in the footsteps of the CMU Ravenclaw Dialogue System&nbsp;[<a href="#node_bib_10">10</a>] and will come equipped with a relatively sophisticated suite of hierarchical dialogue plans for dealing with communication problems arising due to ambiguity and misunderstanding. While clumsy compared to how humans handle ambiguity and misunderstanding, these dialogue plans are designed to resolve the ambiguity and mitigate the consequences of misunderstanding quickly and get the conversation back on track by attempting various repairs involving requests for definition, clarification, repetition and restatement in as inconspicuous manner as possible&nbsp;[<a href="#node_bib_9">9</a>].</p>
<p>
The conventional dialogue system will also include a collection of hierarchical plans for interpreting requests made by the expert programmer to alter programs in the shared editor space, execute programs on specified inputs and perform analyses on the output generated by the program, debugger and other tools provided in the integrated development environment (IDE) accessible through a set of commands implemented as either primitive tasks in the non-differentiable hierarchical planner or through a differentiable neural computer (DNC) interface using the NDS system that will ultimately replace most of the functions of the hierarchical-planner-based dialogue management system.</p>
<p>
This dual mode dialogue system and its MRL controller allows the apprentice to practice on its own and rewards it for learning to emulate the less-flexible hierarchical-planner implementation. Indeed there is quite a bit that we can do to preload the apprentice’s basic language competence and facility using the instrumented IDE and related compiler chain. A parallel dialogue system implemented using the same hierarchical planner can be designed to carry out the programmer’s side of the conversation so as to train the NDS system and the meta-reinforcement learning system that controls its deployment utterance by utterance. We can also train domain-specific language models using <em>n</em>-gram corpora gleaned from discussions between pair programmers engaged in writing code for projects requiring the same programming language and working on similar programming tasks.</p>
<p>
</p>
<p>
</p>
<a name="node_sec_3.1"></a>
<h2 class=section><a href="#node_toc_node_sec_3.1">3.1&nbsp;&nbsp;Planning</a></h2>
<p></p>
<p>
</p>
<p>
In a collaboration, figuring out what to say requires planning and a certain degree of imagination. Suppose you are the apprentice and you want to tell the programmer with whom you're collaborating that you don't understand what a particular expression does. You want to understand what role it plays in the program you are jointly working on. How do you convey this message? What do you need to say explicitly and what can be assumed common knowledge? What does the programmer know and what does she need to be told in order to provide you with assistance?</p>
<p>
Somehow you need to model what the programmer knows. In planning what to say, you might turn this around and imagine that you're the programmer and ask how you would respond to an apprentice's effort to solicit help, but in imagining this role reversal you have be careful that you don't assume the programmer knows everything that you do. You need a model of what you know as well as a model of what the programmer knows. This is called Theory of Mind (ToM) reasoning and learning how to carry out such reasoning occurs in a critical stage of child development.</p>
<p>
Shared knowledge includes general knowledge about programming, knowledge about the current state of a particular program you are working on, as well as specific details concerning what you are attending to at the moment, including program fragments and variable names that have been mentioned recently in the discussion or can be inferred from context. This sort of reasoning can be applied recursively if, for example, the apprentice wants to know what the programmer thinks it knows about what the apprentice knows. To a large extent we can finesse the problem of reasoning about other minds by practicing transparency, redundancy and simplicity so that both parties can depend on not having to work hard to figure out what the other means. However, there are some opportunities in the programmer's apprentice problem for applying ToM reasoning to parts of the problem that cannot be so easily finessed.</p>
<p>
Suppose that the apprentice has started a new program using an existing program <em>P</em> following a suggestion by the expert programmer. Realizing that the body of a loop in <em>P</em> is irrelevant to the task at hand, the apprentice replaces the useless body <em>B</em> with a fragment from another program that does more or less what is required and then makes local changes to the fragment to create a new body <em>B</em>&prime; so that it works with the extant loop variables, e.g., loop counter, termination flag, etc. When the assistant has completed these local changes, the programmer intervenes and changes the name of a variable in <em>B</em>&prime;. What induced the programmer to make this change?</p>
<p>
The programmer noticed that the variable in <em>B</em>&prime; was not initialized or referenced in <em>P</em> but that another variable that was initialized in <em>P</em> and is no longer referenced &#8212; it only appeared in the original loop body <em>B</em>, is perfectly suited for the purposes of the new program. Assume for the sake of this discussion, that the programmer does not explain her action. How might the assistant learn from this intervention or, at the very least, understand why it was made? A reasonable theory of mind might assume that agents perform actions for reasons and those reasons often have to do with preconditions for acting in the world, and, moreover, that determining if action-enabling preconditions are true often requires effort. A useful ToM also depends on having a model allowing an agent to infer how preconditions enable actions by working backward from actions to enabling preconditions. </p>
<p>
</p>
<p>
Imagine the following scene, there's a man holding the reins of a donkey harnessed to a two-wheeled cart &#8212; often called a <i>dray</i> and its owner referred to as a <i>drayman</i> &#8212; carrying a load of rocks. He makes the donkey rear up and by so doing the surface of the cart tilts, dumping the rocks onto the road which was clearly his intention given the appreciative nods from the onlooking pedestrians. This short <a href="https://web.stanford.edu/class/cs379c/resources/amanuensis/content/Donkey_Cart_Draymans_Quick_Unloading_Trick.mp4">video</a> illustrates that, while this might seem an unusual way of delivering a load of rocks, most people think they understand exactly how it was done. Not so!</p>
<p>
The fact is that, as with so many other perceptual and conceptual tasks, people feel strongly that they perceived or understood much more than in fact they did. For example, most people would be hard-pressed to induce a donkey to rear up and, if you asked them to draw the donkey harnessed to the cart with its load of stone, they would very likely misrepresent the geometric relationships involving the height of the donkey, how the harness is attached, how far off the ground the axle is located, the diameter of the wheels and the level of the cart surface and center of gravity of the load with respect to the axle's frame of reference. In other words, they would not have &#8212; and possibly never could have &#8212; designed a working version of the system used by the drayman.</p>
<p>
Now imagine that the drayman has a new apprentice who was watching the entire scene with some concentration, anticipating that he might want to do the very same thing before the first week of his apprenticeship is complete. Sure enough, the next day the drayman tells the apprentice to take a load of bricks to a building site in town where they are constructing a chimney on a new house. He stacks the bricks in a pile that looks something like how he remembers the rocks were arranged on the dray the day before. Unfortunately the load isn't balanced over the axle and almost lifts the donkey off its feet. After some experimentation he discovers how to balance the weight so the donkey can pull the load of bricks without too much effort.</p>
<p>
When he finally gets to the building site, he nearly gets trampled by the donkey in the process of repeatedly trying to induce the distressed animal to rear up on its hind legs. Finally, one of the brick masons intervenes and demonstrates the trick. Unfortunately, the bricks don’t slide neatly off the dray as the rocks did for the experienced drayman the day before, but instead the bricks on the top of the stack tumble to the pavement and several break into pieces. The helpful brick mason suggests that in the future the assistant should prepare the dray by sprinkling a layer of sand on the surface of cart so that the bricks will slide more freely and that he should also dump the bricks on a softer surface to mitigate possible breakage. He then helps the assistant to unload the rest of the bricks but refuses to pay for the broken ones, telling the assistant he will probably have to pay the drayman to make up for the difference.</p>
<p>
An interesting challenge is to develop a model based on what is known about the human brain explaining how memories of the events depicted in the video and extended in the above story might be formed, consolidated, and, subsequently, retrieved, altered, applied and finally assigned a value taking into account the possible negative implications of damaged goods and destroyed property. In the story above, the assistant initially uses his innate &quot;physics engine&quot; to convince himself that he understands the lesson from the master drayman, he then uses a combination of his physical intuitions and trial-and-error to load the cart, but runs up against a wall due to his unfamiliarity with handling reluctant beasts of burden. Finally, he gets into trouble with laws of friction and the quite-reasonable expectations of consumers unwilling to pay for damaged goods. </p>
<p>
</p>
<p>
We don't propose to solve the general problems of theory-of-mind and physics-based reasoning in developing a programmer's apprentice, though the application provides an interesting opportunity to address particular special cases. As mentioned earlier, the stream of conversation between the assistant an expert programmer will inevitably relate to many different topics and specialized areas of expertise. It will include specific and general advice, reasons for acting, suggestions for what to attend to and a wide range of comments and criticisms. Several recent approaches for combining planning and prediction, especially in the case of partially observable Markov decision processes, are particularly promising for this application&nbsp;[<a href="#node_bib_42">42</a>,&nbsp;<a href="#node_bib_31">31</a>,&nbsp;<a href="#node_bib_33">33</a>,&nbsp;<a href="#node_bib_100">100</a>,&nbsp;<a href="#node_bib_86">86</a>].</p>
<p>
The apprentice will want to separate this information into different categories to construct solutions to problems that arise at multiple levels of abstraction and complexity during code synthesis. Or will it? We like to think of knowledge neatly packaged into modules that result in textbooks, courses, monographs, tutorials, etc. The apparent order in which activities appear in a stream of activities is largely a consequence of the context in which those activities are carried out. They may seem to arise in accord with some plan, as if assembled and orchestrated with a particular purpose in mind, but, even if there was plan at the outset, we tend to make up things on the fly to accommodate the sort of unpredictable circumstances that characterize most of our evolutionary history. </p>
<p>
In some cases that context or purpose is used to assign a name, but that name or contextual handle is seldom used to initiate or identify the activity except in academic circumstances where divisions and boundaries are highly prized and made much of. The point of this is that in a diverse stream of activities &#8212; or utterances intended to instigate activities &#8212; credit assignment can be difficult. Proximity in terms of the length of time or number of intervening activities between a action and a reward is not necessarily a good measure of its value. We suggest it is possible to build a programer's apprentice or other sort of digital assistant that performs its essential services primarily by learning to predict actions, their consequences and their value from observing such a diverse stream of dialog intermixed with actions and observations. </p>
<p>
</p>
<p>
</p>
<a name="node_sec_3.2"></a>
<h2 class=section><a href="#node_toc_node_sec_3.2">3.2&nbsp;&nbsp;Hybrids</a></h2>
<p></p>
<p>
When the programmer tells the assistant to replace the name of a variable in one location in a program with the name of a variable in another location, the process starts with a contextually rich representation in the programmer’s brain corresponding to the activation of millions or billions of neurons in circuits distributed broadly throughout the cortex. This pattern of activation is compressed into a more compact representation used to generate a sequence of words uttered one at a time as if condensing out of a cloud of commingled thoughts in droplets or phrasal showers uttered in sudden bursts of words that are &#8212; ignoring the intervening stages of speech production in the programmer and auditory processing in the assistant &#8212; subsequently converted into activations in peripheral subnetworks of the assistant and quickly propagate to other subnetworks throughout the assistant’s neural-network architecture. </p>
<p>
The resulting activations insinuate fractal patterns of meaning into broadly distributed subnetworks of the apprentice subtly altering activity in some and substantially altering activity in others, contributing to the formation of another contextually rich representation in the apprentice’s brain. The imperative conveyed by the programmer’s tone of voice produces a quick response. The apprentice performs a sequence of well rehearsed steps that involve activating a sequence of patterns in the non-differentiable interface connecting the assistant to the integrated development environment. This sequence is produced by recurrent networks operating much like the programmer’s speech production circuits. The resulting patterns produce a sequence of unambiguous words &#8212; requiring no additional context to interpret, that immediately produce the desired change and are displayed on the screen shared by the programmer and the apprentice.</p>
<p>
What does this combination of expert-human biological computing, differentiable connectionist models and non-differentiable symbolic systems buy us? The human expert provides heuristic advice and technical guidance. The connectionist components enable natural language communication between human and machine and enable the system to discover and exploit structure in computer programs to facilitate code synthesis and reduce brute search. Finally, the symbolic components allow the connectionist components &#8212; and, by extension, the human expert &#8212; to directly engage with computers as prosthetic extensions in which compiling and running code is as natural as playing video games.</p>
<p>
</p>
<p>
</p>
<a name="node_sec_3.3"></a>
<h2 class=section><a href="#node_toc_node_sec_3.3">3.3&nbsp;&nbsp;Resources</a></h2>
<p></p>
<p>
Neil Rabinowitz's <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/17/index.html">presentation</a> on learning a machine theory-of-mind model that relies on meta-learning to build mental models of the agents that it encounters from observations of their behaviour alone&nbsp;[<a href="#node_bib_78">78</a>]<a name="node_call_footnote_Temp_21"></a><sup><small><a href="#node_footnote_Temp_21">18</a></small></sup>.<p>
Greg Wayne's <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/05/03/index.html">presentation</a> on <tt>MERLIN</tt> a method for prediction in environments corresponding to partially observable Markov decision processes in which memory formation is guided by predictive modeling&nbsp;[<a href="#node_bib_100">100</a>]<a name="node_call_footnote_Temp_22"></a><sup><small><a href="#node_footnote_Temp_22">19</a></small></sup>.<p>
Oriol Vinyals' <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/05/10/index.html">presentation</a> on an approach for model-based plan construction, evaluation and execution applied to sequential decision making problems relying on a method of imagination-based forecasting&nbsp;[<a href="#node_bib_72">72</a>]<a name="node_call_footnote_Temp_23"></a><sup><small><a href="#node_footnote_Temp_23">20</a></small></sup>.<p>
Devi Parikh's <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/05/22/index.html">public lectures</a> on learning to conduct meaningful dialog with humans in natural, conversational language by grounding the conversation in shared visual experience, inferring its context from history&nbsp;[<a href="#node_bib_20">20</a>]<a name="node_call_footnote_Temp_24"></a><sup><small><a href="#node_footnote_Temp_24">21</a></small></sup>.<p>
</p>
<p>
</p>
<p>
</p>
<p>
<a name="production_code_program_synthesis"></a>
</p>
<a name="node_sec_4"></a>
<h1 class=section><a href="#node_toc_node_sec_4">4&nbsp;&nbsp;Generation: Automated Code Synthesis</a></h1>
<p></p>
<p>
</p>
<p>
Gulwani&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_44">44</a>] provide an up-to-date survey of challenges and technologies in automated program synthesis. Machine learning is allocated only 10 of the more than 100 pages in the review with neural network-methods singled out as a separate section of 6 additional pages. My experience is that many current devotees are largely ignorant concerning the relevant history including the many successful applications for handling interesting special cases. I won't attempt to remedy that state of affairs here except to recommend that readers interested in program synthesis spend the time to familiarize themselves with the relevant work including both successes and notable failures. </p>
<p>
For those of you primarily interested in neural-network methods, understanding this background is likely to prove useful in developing hybrid systems that combine connectionist models and more conventional symbolic methods. Already, the power of high-dimensional vector-space representations, context-sensitive embedding spaces and fully-differentiable models trained with backpropagation is winning converts among advocates of more traditional methods, even as the latest generation of neural-network experts working on what is popularly called neural program synthesis are rediscovering some of the same special cases that have been exploited in deductive and constraint-based approaches to automated code synthesis.</p>
<p>
</p>
<p>
</p>
<a name="node_sec_4.1"></a>
<h2 class=section><a href="#node_toc_node_sec_4.1">4.1&nbsp;&nbsp;Teaching</a></h2>
<p></p>
<p>
</p>
<p>
Given the title, you might have expected that this document would be all about automatic programming, but it's really about human augmentation and human-computer collaboration. Programming is all about representing procedural knowledge in an interpretable form, i.e., executable on some computational substrate. Teaching someone to program or, for that matter, teaching someone to do most anything nontrivial, is also about representing and communicating procedural knowledge in an interpretable form &#8212; the clearer and more precise the communication, the simpler and less knowledgeable the required substrate.</p>
<p>
In this section, we attempt to identify special cases in which it is relatively easy for a human programmer to instruct an AI system how to facilitate the conversion of thoughts conveyed in natural language into working programs &#8212; see Graham Neubig's CS379C calendar <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/05/01/index.html">page</a> for a sample of his NLP work on code generation and learning dialog systems. We are not anticipating that we will be able to read minds so much as exploit shared knowledge in order to translate succinct descriptions of desired computations &#8212; along with an implicit understanding of what constitutes a suitable computational solution &#8212; into working software possibly with guarantees of its correctness and performance.</p>
<p>
How does this perspective inform the discussion in this section? Prior to any training the apprentice comes equipped with a very basic language facility and an innate ability to work with computer programs, but the former is practically useless since the meta-learning controller hasn't been trained and the latter only produces results in the same way that a baby has virtually no control over its limbs and torso. It learns to communicate by reinforcement when it successfully carries out a command from the expert programmer. A built-in training system expedites this process and relieves some of the burden from the programmer by generating synthetic commands that serve to initialize the meta-learning controller allowing the assistant to achieve a basic facility for directly translating natural language commands exercising the integrated development environment.</p>
<p>
The apprentice also comes pre-trained with a (semantic) <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> trained on a corpus that includes a large vocabulary of practical and technical terms used by programmers in talking about programs and programming. The apprentice ingests a large corpus of programs and program fragments written in the language that it will use for writing new programs, resulting in an embedding space that encodes these programs and an encoder-decoder translation facility that allows it to read and write programs represented as abstract syntax trees. Were there more computer- / natural-language <a href="https://en.wikipedia.org/wiki/Parallel_text#Parallel_corpora">parallel corpora</a>, supervised training of systems that depend on natural-language specification as input would be tempting. As it is, we have to rely on more subtle strategies.</p>
<p>
</p>
<p>
Perhaps it is not surprising that many current neural-network approaches take advantage of neural-network technology originally designed for machine translation, question answering and related natural-language processing applications. Programs are linguistic objects with relatively simple syntax. Their syntax is well understood since linguistically adept computer scientists designed them. Parsing programs is trivial using standard compiler tools. Their semantics is revealed by running them, and not just their input-output behavior &#8212; execution traces can be used to reveal the meaning of every function and fragment. </p>
<p>
Programming languages are syntactically unforgiving &#8212; a source of aggravation for beginning programmers, but we have sophisticated editors and syntax checkers that avoid most problems and there is no reason not to build them into the integrated development environment used by the programmer's assistant and shared with the programmer. Internally, the assistant can work with equivalent abstract syntax trees making it easy to ingest, embed, manipulate and generate proposals for performing program transformations on such representations. Human readable code can be recovered for the programmer's convenience.</p>
<p>
Successful code synthesis can be verified by running the program and comparing with the provided input-output examples. Modulo the intractability of the halting problem, failure for relatively simple programs can be easily determined. Program <a href="https://en.wikipedia.org/wiki/Correctness_(computer_science)">correctness</a> is generally specified with respect to a specification and hence is more difficult to pin down, though the term generally implies the existence of a mathematical proof and, hence, one formal-methods approach to code synthesis involves generating a <a href="https://en.wikipedia.org/wiki/Constructive_proof">constructive proof</a> of correctness. </p>
<p>
Semantic embeddings are increasingly common&nbsp;[<a href="#node_bib_28">28</a>,&nbsp;<a href="#node_bib_19">19</a>,&nbsp;<a href="#node_bib_99">99</a>,&nbsp;<a href="#node_bib_104">104</a>,&nbsp;<a href="#node_bib_75">75</a>] based on <a href="https://en.wikipedia.org/wiki/Software_diagnosis#Characteristics">execution traces</a>, <a href="https://en.wikipedia.org/wiki/Log_file#Event_logs">event logs</a>, or <a href="https://en.wikipedia.org/wiki/Invariant_(computer_science)">program invariants</a>. See this discussion log <a href="https://web.stanford.edu/class/cs379c/class_messages_listing/index.html#program_embedding_core_technology">entry</a> and Rishabh Singh's CS379C calendar <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/05/24/index.html">page</a> plus this discussion log <a href="https://web.stanford.edu/class/cs379c/class_messages_listing/index.html#execution_logs_program_traces">entry</a> and Dawn Song's CS379C calendar <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/05/31/index.html">page</a> for more on semantic embeddings. I'm not going into detail here for the simple reason that it is still early days and your best approach to learn more is to read the papers, check out the slides and watch the videos mentioned in this paragraph and at the end of this section &#8212; you might also take a look at Danny Tarlow's list of selected program synthesis papers <a href="./content/Selected_Program_Synthesis_Papers_Tarlow.pdf">here</a>.</p>
<p>
</p>
<p>
</p>
<a name="node_sec_4.2"></a>
<h2 class=section><a href="#node_toc_node_sec_4.2">4.2&nbsp;&nbsp;Projects</a></h2>
<p></p>
<p>
</p>
<p>
In the Spring 2018 instance of Stanford <a href="https://web.stanford.edu/class/cs379c/">CS379C</a>, 30 students, organized in 12 teams proposed and carried out projects relating to the programmer's apprentice. As an example, the team consisting of Marcus Gomez, Nate Gruver, Michelle Lam, Rohun Saxena and Lucy Wang&nbsp;[<a href="#node_bib_38">38</a>] decided based on their coding habits that the most helpful assistant would be one that could be trained to understand design through the structure of an application programming interface (<a href="https://en.wikipedia.org/wiki/Application_programming_interface">API</a>) and assist in the completion of the code through a divide-and-conquer approach <a href="./content/CS379C_Final_Project_Gomezetal-18.pdf">PDF</a>.</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
<a name="fig_CS379C_Final_Project_Gomezetal_Figure_03"></a>
</p>
<a name="node_fig_Temp_25"></a>
<div class=:figure align=center><table width=100%><tr><td align=center><hr>
<p>
</p>
<div align=center><table><tr><td>

<img width=722 src="./figures/CS379C_Final_Project_Gomezetal_Figure_03.png"></td></tr></table></div>

</td></tr>
<tr><td align=left><b>Figure 3:</b>&nbsp;&nbsp;Summary of the proposed LSTM-based state-embedding architecture for <em>C</em><sub><em>f</em></sub> described in Gomez&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_38">38</a>]. The code representation, <em>C</em><sub><em>f</em></sub>, is by default variable in size since the abstract syntax trees that comprise the individual helper functions are variable size. The authors solve this problem by training an autoencoder penalized on reconstruction loss such that the decoded output is the binary tree representation of the original AST.</td></tr>
<tr><td>
<hr>
<p>
</p>
</td></tr></table></div><p></p>
<p>
</p>
<p>
The system they envision would be designed to integrate seamlessly into programmer's workflow, minimize interaction and start from a simple header file and dependency graph. They took pains to standardize the format of the input in order to simplify learning a compressed fixed-size state vector as an ordered list of GLoVe vectors&nbsp;[<a href="#node_bib_74">74</a>] &#8212; see Figure&nbsp;<a href="#fig_CS379C_Final_Project_Gomezetal_Figure_03">3</a>. They employ the method of <i>generative adversarial imitation learning</i> (GAIL) developed by Ho and Ermon&nbsp;[<a href="#node_bib_49">49</a>] to extract a policy from data as if it were obtained by reinforcement learning following inverse reinforcement learning. GAIL should enable them to derive a model-free imitation-learning algorithm that obtains significant performance gains over existing model-free methods in imitating complex behaviors in large, high-dimensional environments.</p>
<p>
</p>
<p>
Episodic memory is an important component of the programmer's apprentice. In order to exploit what you've learned through experience and previously consolidated in episodic memory, it is often necessary to reconstruct memories in enough detail that you can compare the past with current experience, determine if activities applied to resolve problems in the past apply in the present, and, if necessary, adapt those early responses to fit the present circumstances. Catherine Wong, in her final project report&nbsp;[<a href="#node_bib_103">103</a>] for CS379C, developed a new neural-network model for content-based and selectively-reconstructive memory inspired by research on <i>hippocampal indexing theory</i>&nbsp;[<a href="#node_bib_93">93</a>] and <i>adaptive deconvolutional networks</i>&nbsp;[<a href="#node_bib_107">107</a>,&nbsp;<a href="#node_bib_106">106</a>] <a href="./content/CS379C_Final_Project_Wong-18.pdf">PDF</a>. </p>
<p>
In designing her model she built upon the Kavukcuoglu&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_52">52</a>] work on <a href="http://koray.kavukcuoglu.org/research.html">convolutional predictive sparse decomposition</a> and Kingma and Welling&nbsp;[<a href="#node_bib_53">53</a>] on <a href="https://www.ibm.com/blogs/research/2018/05/disentanglement-deep-learning/">explicit feature disentanglement using variational autoencoders</a>. While previous work has focused on deciding <i>how</i> to remember&nbsp;[<a href="#node_bib_100">100</a>], Catherine's model emphasizes deciding <i>what</i> to remember, focusing on the problem of leveraging compressive coding to balance the demands of efficient and effective content-based lookup with domain specificity. Her work is also closely related to and consistent with recent research&nbsp;[<a href="#node_bib_56">56</a>,&nbsp;<a href="#node_bib_30">30</a>,&nbsp;<a href="#node_bib_66">66</a>] on the role of high-frequency <a href="https://en.wikipedia.org/wiki/Sleep_spindle">thalamic sleep spindles</a> during sleep-dependent memory consolidation<a name="node_call_footnote_Temp_26"></a><sup><small><a href="#node_footnote_Temp_26">22</a></small></sup>.</p>
<p>
</p>
<p>
Technology for automatic software repair is becoming an important component of software maintenance and automatic code synthesis&nbsp;[<a href="#node_bib_61">61</a>]. Maurice Chiang, Yousef Hindy, Peter Lu, Sophia Sanchez and Michael Smith&nbsp;[<a href="#node_bib_58">58</a>] developed a neural network architecture to support error correction in abstract syntax trees that can be used as a code repair module in a more general neural code synthesis system <a href="./content/CS379C_Final_Project_Luetal-18.pdf">PDF</a>. Their approach is novel in its use of multiple strategies realized as separate submodules, coordinated by a master controller, so that the whole system is trained end-to-end after training each of the submodules independently. </p>
<p>
The Lu&nbsp;<em>et al</em> work&nbsp;[<a href="#node_bib_58">58</a>] takes advantage of a number of recent innovations in neural code synthesis. Specifically they leverage the Cai&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_14">14</a>] work on using recursion to generalize programs to handle novel inputs. They employ a version of Pascanu&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_72">72</a>] model-based planning (IBP) that accepts partially complete or incorrect ASTs, extending the IBP controller to coordinate the separate submodules. They also propose a strategy for handling intermediate reward signals to compensate for the relative sparsity of ground truth data and a clever approach to comparing programs that relies on normalizing and comparing stack traces computed from input-output pairs&nbsp;[<a href="#node_bib_13">13</a>,&nbsp;<a href="#node_bib_45">45</a>,&nbsp;<a href="#node_bib_87">87</a>]. </p>
<p>
These three projects illustrate how ideas from such seemingly disjoint disciplines as cognitive neuroscience and theoretical computer science can come together to create sophisticated new technologies<a name="node_call_footnote_Temp_27"></a><sup><small><a href="#node_footnote_Temp_27">23</a></small></sup>. 
Unfortunately, competition between disciplines has resulted in convenient lapses in memory exacerbated by strategic internal rebranding of ideas. The current period of increased collaboration illustrates the advantages of creating and maintaining cross-disciplinary ties. This generation of students is being exposed to ideas from a broad range of ideas relating to synthetic and biological computing and will hopefully pass on their interests to their students and more narrowly focused colleagues.</p>
<p>
</p>
<p>
These innovative student projects target important problems that we face in designing complex collaborative AI systems such as the programmer's apprentice. Their proposed solutions highlight the variety and scalabilty of the architectural components now available that allow for the creative manipulation of the ungainly objects that comprise the inputs and outputs of software engineering practice, e.g., natural language specifications of arbitrary format, the encoding, analysis and procedural extraction of programming knowledge from dialog, and dealing with computer programs of arbitrary size and complexity and computed artifacts such as execution traces that defy explicit encoding due to their size and format variability.</p>
<p>
</p>
<p>
The Programmer's Apprentice is <a href="https://en.wikipedia.org/wiki/AI-complete">AI complete</a> in the sense that it is equivalent to that of making computers at least as intelligent as human beings. It isn't necessarily the part relating to code synthesis &#8212; though, depending on how you define fully automatic code synthesis starting from a natural language description, that too could be said to be AI complete. Assuming we are satisfied to build a system capable of <i>assisting</i> rather than <i>replacing</i> a programmer, then the hard problem is in the ability to interact easily with humans.</p>
<p>
This is not to say that we can't build highly capable assistants in the near term. We simply have to constrain the problem appropriately, and I believe we can do much better than the current breed of personal assistants in designing a programmer's assistant that can considerably increase the productivity of professional software engineers and enable reasonably competent programmers to become much more effective. The speakers contributing to class discussions and students working on related projects demonstrate that many of the crucial features required of a programmer's assistant are within our grasp.</p>
<p>
Such features include speaker- and task-dependent management of episodic memory including memory consolidation, procedural abstraction and control-policy / strategy integration, meta-level control of reinforcement learning and policy application integrating multiple sources of knowledge pertaining to programming and maintaining continuous, problem-focused dialog, and basic programming capabilities including program repair and simplification, identifying and repurposing existing program fragments to generate new programs, and translating natural language program specifications into working programs.</p>
<p>
If you are serious about wanting to build some variant of digital amanuensis to assist in writing programs, the good news is that there are a lot of tools you can leverage. There is also some excitement and optimism derived from the scattered successes in applying modern connectionist models to the problem of automatic code synthesis. For those with the perspective to see beyond the new advances, there is the distinct possibility of combining the deep learning methods that have recently shown such promise with the considerable body of work on deductive and statistical methods applied to automatic program synthesis&nbsp;[<a href="#node_bib_44">44</a>]. </p>
<p>
</p>
<p>
</p>
<a name="node_sec_4.3"></a>
<h2 class=section><a href="#node_toc_node_sec_4.3">4.3&nbsp;&nbsp;Resources</a></h2>
<p></p>
<p>
Daniel Abolafia's <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/04/24/index.html">presentation</a> on iterative optimization for program synthesis in the presence of a reward function over the output of programs, where the goal is to find programs with maximal rewards&nbsp;[<a href="#node_bib_1">1</a>]<a name="node_call_footnote_Temp_28"></a><sup><small><a href="#node_footnote_Temp_28">24</a></small></sup>.<p>
Graham Neubig's <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/05/01/index.html">presentation</a> on a novel neural architecture for parsing natural language descriptions into source code powered by a grammar model to explicitly capture the target syntax as prior knowledge&nbsp;[<a href="#node_bib_105">105</a>]<a name="node_call_footnote_Temp_29"></a><sup><small><a href="#node_footnote_Temp_29">25</a></small></sup>.<p>
Rishabh Singh's <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/05/24/index.html">presentation</a> on using a strong statistical model for semantic code repair to predict bug locations and exact fixes without access to information about the intended correct behavior of the program.&nbsp;[<a href="#node_bib_28">28</a>]<a name="node_call_footnote_Temp_30"></a><sup><small><a href="#node_footnote_Temp_30">26</a></small></sup>.<p>
Dawn Song and Xinyun Chen's <a href="https://web.stanford.edu/class/cs379c/calendar_invited_talks/lectures/05/31/index.html">presentation</a> on program synthesis from input-output examples, tree-to-tree neural networks for program translation, and attention for program synthesis from natural language descriptions&nbsp;[<a href="#node_bib_18">18</a>]<a name="node_call_footnote_Temp_31"></a><sup><small><a href="#node_footnote_Temp_31">27</a></small></sup>.<p>
</p>
<p>
</p>
<p>
</p>
<p>

</p>
<a name="node_sec_Temp_32"></a>
<h1 class=section><a href="#node_toc_node_sec_Temp_32">References</a></h1>
<p></p>
<table>
<p>
</p>
<tr><td align=right valign=top><a name="node_bib_1"></a>[1]&nbsp;&nbsp;</td><td>
Daniel&nbsp;A. Abolafia, Mohammad Norouzi, and Quoc&nbsp;V. Le.
 Neural program synthesis with priority queue training.
 <i>CoRR</i>, arXiv:1801.03526, 2018.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_2"></a>[2]&nbsp;&nbsp;</td><td>
Jimmy Ba, Geoffrey Hinton, Volodymyr Mnih, Joel&nbsp;Z. Leibo, and Catalin Ionescu.
 Using fast weights to attend to the recent past.
 <i>CoRR</i>, arXiv:1610.06258, 2016.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_3"></a>[3]&nbsp;&nbsp;</td><td>
B.&nbsp;J. Baars.
 <i>A cognitive theory of consciousness</i>.
 Cambridge University Press, New York, NY, 1988.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_4"></a>[4]&nbsp;&nbsp;</td><td>
Dana&nbsp;H. Ballard.
 <i>Brain Computation as Hierarchical Abstraction</i>.
 Computational Neuroscience Series. MIT Press, 2015.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_5"></a>[5]&nbsp;&nbsp;</td><td>
Yoshua Bengio.
 The consciousness prior.
 <i>CoRR</i>, arXiv:1709.08568, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_6"></a>[6]&nbsp;&nbsp;</td><td>
Yoshua Bengio, Je&#x301;ro&#x302;me Louradour, Ronan Collobert, and Jason Weston.
 Curriculum learning.
 In <i>Proceedings of the 26th Annual International Conference on
Machine Learning</i>, pages 41--48, New York, NY, USA, 2009. ACM.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_7"></a>[7]&nbsp;&nbsp;</td><td>
Avishkar Bhoopchand, Tim Rockta&#x308;schel, Earl&nbsp;T. Barr, and Sebastian Riedel.
 Learning python code suggestion with a sparse pointer network.
 In <i>International Conference on Learning Representations</i>, volume
arXiv:/1611.08307, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_8"></a>[8]&nbsp;&nbsp;</td><td>
Jeffrey&nbsp;R. Binder and Rutvik&nbsp;H. Desai.
 The neurobiology of semantic memory.
 <i>Trends in Cognitive Science</i>, 15:527--536, 2011.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_9"></a>[9]&nbsp;&nbsp;</td><td>
Dan Bohus.
 <i>Error Awareness and Recovery in Conversational Spoken Language
Interfaces</i>.
 PhD thesis, Carnegie Mellon University, 2007.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_10"></a>[10]&nbsp;&nbsp;</td><td>
Dan Bohus and Alexander&nbsp;I. Rudnicky.
 The RavenClaw dialogue management framework: architecture and
systems.
 <i>Computer Speech &amp; Language</i>, 23:332--361, 2009.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_11"></a>[11]&nbsp;&nbsp;</td><td>
Dan Bohus and Alexander&nbsp;I. Rudnicky.
 The RavenClaw Dialogue Management Framework: Architecture and
Systems.
 <i>Computer Speech and Language</i>, 23:332--361, 2009.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_12"></a>[12]&nbsp;&nbsp;</td><td>
Ronald Brachman and Hector Levesque.
 <i>Knowledge Representation and Reasoning</i>.
 The Morgan Kaufmann Series in Artificial Intelligence. Elsevier
Science, 2004.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_13"></a>[13]&nbsp;&nbsp;</td><td>
M.&nbsp;Brodie, Sheng Ma, G.&nbsp;Lohman, L.&nbsp;Mignet, N.&nbsp;Modani, M.&nbsp;Wilding, J.&nbsp;Champlin,
and P.&nbsp;Sohn.
 Quickly finding known software problems via automated symptom
matching.
 In <i>Proceedings of the Second International Conference on
Autonomic Computing</i>. ACM, New York, NY, USA, 2005.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_14"></a>[14]&nbsp;&nbsp;</td><td>
Jonathon Cai, Richard Shin, and Dawn Song.
 Making neural programming architectures generalize via recursion.
 <i>CoRR</i>, arXiv:1704.06611, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_15"></a>[15]&nbsp;&nbsp;</td><td>
Nick Chater and Morten&nbsp;H. Christiansen.
 A solution to the logical problem of language evolution: language as
an adaptation to the human brain.
 In Kathleen&nbsp;R. Gibson and Maggie Tallerman, editors, <i>The Oxford
Handbook of Language Evolution</i>. Oxford University Press, 2011.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_16"></a>[16]&nbsp;&nbsp;</td><td>
Nick Chater and Morten&nbsp;H. Christiansen.
 Language acquisition as skill learning.
 <i>Current Opinion in Behavioral Sciences</i>, 2018.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_17"></a>[17]&nbsp;&nbsp;</td><td>
Nick Chater, Stewart&nbsp;M. McCauley, and Morten&nbsp;H. Christiansen.
 Language as skill: Intertwining comprehension and production.
 <i>Journal of Memory and Language</i>, 89:244--254, 2016.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_18"></a>[18]&nbsp;&nbsp;</td><td>
Xinyun Chen, Chang Liu, and Dawn Song.
 Tree-to-tree neural networks for program translation.
 <i>CoRR</i>, arXiv:1802.03691, 2018.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_19"></a>[19]&nbsp;&nbsp;</td><td>
Alexander Chistyakov, Ekaterina Lobacheva, Arseny Kuznetsov, and Alexey
Romanenko.
 Semantic embeddings for program behaviour patterns.
 In <i>ICLR Workshop</i>, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_20"></a>[20]&nbsp;&nbsp;</td><td>
Abhishek Das, Satwik Kottur, Khushi Gupta, Avi Singh, Deshraj Yadav,
Jose&#x301;&nbsp;M.F. Moura, Devi Parikh, and Dhruv Batra.
 Visual Dialog.
 In <i>Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition (CVPR)</i>, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_21"></a>[21]&nbsp;&nbsp;</td><td>
Terrence&nbsp;W. Deacon.
 <i>The Symbolic Species: The Co-evolution of Language and the
Brain</i>.
 W. W. Norton, 1998.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_22"></a>[22]&nbsp;&nbsp;</td><td>
Thomas Dean.
 A computational model of the cerebral cortex.
 In <i>Proceedings of AAAI-05</i>, pages 938--943, Cambridge,
Massachusetts, 2005. MIT Press.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_23"></a>[23]&nbsp;&nbsp;</td><td>
Thomas Dean.
 Learning invariant features using inertial priors.
 <i>Annals of Mathematics and Artificial Intelligence</i>, 47:223--250,
2006.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_24"></a>[24]&nbsp;&nbsp;</td><td>
Thomas Dean.
 Interaction and negotiation in learning and understanding dialog.
 <tt>https://web.stanford.edu/class/cs379c/resources/dialogical/zanax_DOC.dir/index.html</tt>,
2014.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_25"></a>[25]&nbsp;&nbsp;</td><td>
Stanislas Dehaene.
 <i>Consciousness and the Brain: Deciphering How the Brain Codes Our
Thoughts</i>.
 Viking Press, 2014.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_26"></a>[26]&nbsp;&nbsp;</td><td>
Stanislas Dehaene, Michel Kerszberg, and Jean-Pierre Changeux.
 A neuronal model of a global workspace in effortful cognitive tasks.
 <i>Proceedings of the National Academy of Sciences</i>,
95:14529--14534, 1998.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_27"></a>[27]&nbsp;&nbsp;</td><td>
Stanislas Dehaene, Hakwan Lau, and Sid Kouider.
 What is consciousness, and could machines have it?
 <i>Science</i>, 358(6362):486--492, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_28"></a>[28]&nbsp;&nbsp;</td><td>
Jacob Devlin, Jonathan Uesato, Rishabh Singh, and Pushmeet Kohli.
 Semantic code repair using neuro-symbolic transformation networks.
 In <i>International Conference on Learning Representations</i>, 2018.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_29"></a>[29]&nbsp;&nbsp;</td><td>
F.&nbsp;Donnarumma, R.&nbsp;Prevete, F.&nbsp;Chersi, and G.&nbsp;Pezzulo.
 A programmer-interpreter neural network architecture for prefrontal
cognitive control.
 <i>International Journal Neural Systems</i>, 25(6):1550017, 2015.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_30"></a>[30]&nbsp;&nbsp;</td><td>
D.&nbsp;Fan, Q.&nbsp;Wang, J.&nbsp;Su, and H.&nbsp;Xi.
 Stimulus-induced transitions between spike-wave discharges and
spindles with the modulation of thalamic reticular nucleus.
 <i>Journal of Computational Neuroscience</i>, 43(3):203--225, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_31"></a>[31]&nbsp;&nbsp;</td><td>
Chelsea Finn, Pieter Abbeel, and Sergey Levine.
 Model-agnostic meta-learning for fast adaptation of deep networks.
 <i>CoRR</i>, arXiv:1703.03400, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_32"></a>[32]&nbsp;&nbsp;</td><td>
Jerry&nbsp;A. Fodor and Zenon&nbsp;W. Pylyshyn.
 Connectionism and cognitive architecture.
 <i>Cognition</i>, 28(1-2):3--71, 1988.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_33"></a>[33]&nbsp;&nbsp;</td><td>
Jakob&nbsp;N. Foerster, Richard&nbsp;Y. Chen, Maruan Al-Shedivat, Shimon Whiteson,
Pieter Abbeel, and Igor Mordatch.
 Learning with opponent-learning awareness.
 <i>CoRR</i>, abs/1709.04326, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_34"></a>[34]&nbsp;&nbsp;</td><td>
C.R. Gallistel and A.P. King.
 <i>Memory and the Computational Brain: Why Cognitive Science will
Transform Neuroscience</i>.
 Wiley, 2009.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_35"></a>[35]&nbsp;&nbsp;</td><td>
Michael&nbsp;S. Gazzaniga.
 <i>The Cognitive Neurosciences (Third Edition)</i>.
 Bradford Books. MIT Press, Cambridge, MA, 2009.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_36"></a>[36]&nbsp;&nbsp;</td><td>
Dileep George and Jeff Hawkins.
 A hierarchical Bayesian model of invariant pattern recognition in
the visual cortex.
 In <i>Proceedings of the International Joint Conference on Neural
Networks</i>, volume&nbsp;3, pages 1812--1817. IEEE, 2005.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_37"></a>[37]&nbsp;&nbsp;</td><td>
James&nbsp;J. Gibson.
 <i>The Ecological Approach to Visual Perception</i>.
 Houghton Mifflin, Boston, 1979.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_38"></a>[38]&nbsp;&nbsp;</td><td>
Marcus Gomez, Nate Gruver, Michelle Lam, Rohun Saxena, and Lucy Wang.
 Imitation learning for code generation via recurrent state space
embeddings.
 Representative Final Project Archive for Stanford CS379C in Spring
2018, 2018.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_39"></a>[39]&nbsp;&nbsp;</td><td>
Alex Graves, Greg Wayne, and Ivo Danihelka.
 Neural Turing machines.
 <i>CoRR</i>, arXiv:1410.5401, 2014.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_40"></a>[40]&nbsp;&nbsp;</td><td>
Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka
Grabska-Barwin&#x301;ska, Sergio&nbsp;Go&#x301;mez Colmenarejo, Edward Grefenstette,
Tiago Ramalho, John Agapiou, Adria&#x300;&nbsp;Puigdome&#x301;nech Badia, Karl&nbsp;Moritz
Hermann, Yori Zwols, Georg Ostrovski, Adam Cain, Helen King, Christopher
Summerfield, Phil Blunsom, Koray Kavukcuoglu, and Demis Hassabis.
 Hybrid computing using a neural network with dynamic external memory.
 <i>Nature</i>, 538:471--476, 2016.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_41"></a>[41]&nbsp;&nbsp;</td><td>
Michael S.&nbsp;A. Graziano.
 The attention schema theory: A foundation for engineering artificial
consciousness.
 <i>Frontiers in Robotics and AI</i>, 4:60, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_42"></a>[42]&nbsp;&nbsp;</td><td>
Edward Groshev, Aviv Tamar, Siddharth Srivastava, and Pieter Abbeel.
 Learning generalized reactive policies using deep neural networks.
 <i>CoRR</i>, arXiv:1708.07280, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_43"></a>[43]&nbsp;&nbsp;</td><td>
Arthur Guez, The&#x301;ophane Weber, Ioannis Antonoglou, Karen Simonyan, Oriol
Vinyals, Daan Wierstra, Re&#x301;mi Munos, and David Silver.
 Learning to search with MCTSnets.
 <i>CoRR</i>, arXiv:1802.04697, 2018.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_44"></a>[44]&nbsp;&nbsp;</td><td>
Sumit Gulwani, Oleksandr Polozov, and Rishabh Singh.
 Program synthesis.
 <i>Foundations and Trends in Programming Languages</i>, 4(1-2):1--119,
2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_45"></a>[45]&nbsp;&nbsp;</td><td>
Rajeev Gupta, Guy&nbsp;Maring Lohman, Tanveer&nbsp;Fathima Mahmood, Laurent&nbsp;Sebastien
Mignet, Natwar Modani, and Mark&nbsp;Francis Wilding.
 System and method for matching a plurality of ordered sequences with
applications to call stack analysis to identify known software problems.
 https://patents.google.com/patent/US7840946, 2006.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_46"></a>[46]&nbsp;&nbsp;</td><td>
Jessica&nbsp;B. Hamrick, Andrew&nbsp;J. Ballard, Razvan Pascanu, Oriol Vinyals, Nicolas
Heess, and Peter&nbsp;W. Battaglia.
 Metacontrol for adaptive imagination-based optimization.
 <i>CoRR</i>, arXiv:1705.02670, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_47"></a>[47]&nbsp;&nbsp;</td><td>
Demis Hassabis and Eleanor&nbsp;A. Maguire.
 Deconstructing episodic memory with construction.
 <i>Trends in Cognitive Science</i>, 11:299--306, 2007.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_48"></a>[48]&nbsp;&nbsp;</td><td>
Jeff Hawkins and Sandra Blakeslee.
 <i>On Intelligence</i>.
 Henry Holt and Company, New York, 2004.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_49"></a>[49]&nbsp;&nbsp;</td><td>
Jonathan Ho and Stefano Ermon.
 Generative adversarial imitation learning.
 <i>CoRR</i>, arXiv:1606.03476, 2016.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_50"></a>[50]&nbsp;&nbsp;</td><td>
D.&nbsp;H. Hubel and T.&nbsp;N Wiesel.
 Receptive fields, binocular interaction and functional architecture
in the cat's visual cortex.
 <i>Journal of Physiology</i>, 160:106--154, 1962.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_51"></a>[51]&nbsp;&nbsp;</td><td>
D.&nbsp;H. Hubel and T.&nbsp;N Wiesel.
 Receptive fields and functional architecture of monkey striate
cortex.
 <i>Journal of Physiology</i>, 195:215--243, 1968.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_52"></a>[52]&nbsp;&nbsp;</td><td>
Koray Kavukcuoglu, Pierre Sermanet, Y-Lan Boureau, Karol Gregor, Michae&#x308;l
Mathieu, and Yann LeCun.
 Learning convolutional feature hierarchies for visual recognition.
 In <i>Proceedings of the 23rd International Conference on Neural
Information Processing Systems - Volume 1</i>, pages 1090--1098. Curran
Associates Inc., 2010.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_53"></a>[53]&nbsp;&nbsp;</td><td>
Diederik&nbsp;P. Kingma and Max Welling.
 Auto-encoding variational Bayes.
 <i>CoRR</i>, arXiv:1312.6114, 2013.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_54"></a>[54]&nbsp;&nbsp;</td><td>
Trenton Kriete, David&nbsp;C. Noelle, Jonathan&nbsp;D. Cohen, and Randall&nbsp;C. O'Reilly.
 Indirection and symbol-like processing in the prefrontal cortex and
basal ganglia.
 <i>Proceedings of the National Academy of Sciences</i>, 2013.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_55"></a>[55]&nbsp;&nbsp;</td><td>
Ray Kurzweil.
 <i>How to Create a Mind: The Secret of Human Thought Revealed</i>.
 Viking Press, New York, NY, 2012.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_56"></a>[56]&nbsp;&nbsp;</td><td>
C.&nbsp;V. Latchoumane, H.&nbsp;V. Ngo, J.&nbsp;Born, and H.&nbsp;S. Shin.
 Thalamic Spindles Promote Memory Formation during Sleep
through Triple Phase-Locking of Cortical, Thalamic, and
Hippocampal Rhythms.
 <i>Neuron</i>, 95(2):424--435, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_57"></a>[57]&nbsp;&nbsp;</td><td>
Omer Levy and Yoav Goldberg.
 Linguistic regularities in sparse and explicit word representations.
 In <i>Proceedings of the Eighteenth Conference on Computational
Natural Language Learning</i>, pages 171--180, Ann Arbor, Michigan, 2014.
Association for Computational Linguistics.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_58"></a>[58]&nbsp;&nbsp;</td><td>
Peter Lu, Sophia Sanchez, Yousef Hindy, Maurice Chiang, and Michael Smith.
 Integrating reinforcement learning agents for error correction in
abstract syntax trees.
 Representative Final Project Archive for Stanford CS379C in Spring
2018, 2018.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_59"></a>[59]&nbsp;&nbsp;</td><td>
Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher.
 Pointer sentinel mixture models.
 <i>CoRR</i>, arXiv:1609.07843, 2016.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_60"></a>[60]&nbsp;&nbsp;</td><td>
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
Antonoglou, Daan Wierstra, and Martin Riedmiller.
 Playing Atari with deep reinforcement learning.
 <i>CoRR</i>, arXiv:1312.5602, 2013.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_61"></a>[61]&nbsp;&nbsp;</td><td>
Martin Monperrus.
 Automatic software repair: A bibliography.
 <i>ACM Computing Surveys</i>, 51(1):17:1--17:24, 2018.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_62"></a>[62]&nbsp;&nbsp;</td><td>
M.&nbsp;Moscovitch, R.&nbsp;Cabeza, G.&nbsp;Winocur, and L.&nbsp;Nadel.
 Episodic memory and beyond: The hippocampus and neocortex in
transformation.
 <i>Annual Review of Psychology</i>, 67:105--134, 2016.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_63"></a>[63]&nbsp;&nbsp;</td><td>
Arun Naira, Praveen Srinivasana, Sam Blackwella, Cagdas Alciceka, Rory Fearona,
Alessandro&nbsp;De Mariaa, Vedavyas Panneershelvama, Mustafa Suleymana, Charles
Beattiea, Stig Petersena, Shane Legga, Volodymyr Mniha, Koray Kavukcuoglua,
and David Silver.
 Massively parallel methods for deep reinforcement learning.
 <i>CoRR</i>, arXiv:1507.04296, 2015.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_64"></a>[64]&nbsp;&nbsp;</td><td>
Dana Nau, Tsz-Chiu Au, Okhtay Ilghami, Ugur Kuter, J.&nbsp;William Murdock, Dan Wu,
and Fusun Yaman.
 SHOP2: An HTN planning system.
 <i>Journal of Artificial Intelligence Research</i>, 20:379--404, 2003.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_65"></a>[65]&nbsp;&nbsp;</td><td>
Arvind Neelakantan, Quoc&nbsp;V. Le, Marti&#x301;n Abadi, Andrew McCallum, and Dario
Amodei.
 Learning a natural language interface with neural programmer.
 In <i>International Conference on Learning Representations</i>, volume
arXiv:1611.08945, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_66"></a>[66]&nbsp;&nbsp;</td><td>
T.&nbsp;Nielsen, C.&nbsp;O'Reilly, M.&nbsp;Carr, G.&nbsp;Dumel, I.&nbsp;Godin, E.&nbsp;Solomonova,
J.&nbsp;Lara-Carrasco, C.&nbsp;Blanchette-Carriere, and T.&nbsp;Paquette.
 Overnight improvements in two REM sleep-sensitive tasks are
associated with both REM and NREM sleep changes, sleep spindle features,
and awakenings for dream recall.
 <i>Neurobiology Learning and Memory</i>, 122:88--97, 2015.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_67"></a>[67]&nbsp;&nbsp;</td><td>
Randall&nbsp;C. O'Reilly.
 Biologically based computational models of high-level cognition.
 <i>Science</i>, 314:91--94, 2006.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_68"></a>[68]&nbsp;&nbsp;</td><td>
Randall&nbsp;C. O'Reilly and Michael&nbsp;J. Frank.
 Making working memory work: A computational model of learning in the
prefrontal cortex and basal ganglia.
 <i>Neural Computation</i>, 18:283--328, 2006.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_69"></a>[69]&nbsp;&nbsp;</td><td>
Randall&nbsp;C. O'Reilly, Thomas&nbsp;E. Hazy, and Seth&nbsp;A. Herd.
 The Leabra cognitive architecture: How to play 20 principles with
nature and win!
 In Susan E.&nbsp;F. Chipman, editor, <i>The Oxford Handbook of Cognitive
Science</i>, Oxford Handbooks, pages 91--115. Oxford University Press, 2016.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_70"></a>[70]&nbsp;&nbsp;</td><td>
Randall&nbsp;C. O’Reilly, Rajan Bhattacharyya, Michael&nbsp;D. Howard, and Nicholas
Ketz.
 Complementary learning systems.
 <i>Cognitive Science</i>, 38(6):1229--1248, 2014.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_71"></a>[71]&nbsp;&nbsp;</td><td>
Randall&nbsp;C. O’Reilly, Alex&nbsp;A. Petrov, Jonathan&nbsp;D. Cohen, Christian&nbsp;J. Lebiere,
Seth&nbsp;A. Herd, and Trent Kriete.
 How limited systematicity emerges: A computational cognitive
neuroscience approach.
 In Paco Calvo and John Symons, editors, <i>The Architecture of
Cognition</i>, pages 191--224. MIT Press, Cambridge, Massachusetts, 2014.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_72"></a>[72]&nbsp;&nbsp;</td><td>
Razvan Pascanu, Yujia Li, Oriol Vinyals, Nicolas Heess, Lars Buesing,
Se&#x301;bastien Racanie&#x300;re, David&nbsp;P. Reichert, Theophane Weber, Daan
Wierstra, and Peter Battaglia.
 Learning model-based planning from scratch.
 <i>CoRR</i>, arXiv:1707.06170, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_73"></a>[73]&nbsp;&nbsp;</td><td>
Wilder Penfield and Edwin Boldrey.
 Somatic motor and sensory representation in the cerebral cortex of
man as studied by electrical stimulation.
 <i>Brain</i>, 60(4):389--443, 1937.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_74"></a>[74]&nbsp;&nbsp;</td><td>
Jeffrey Pennington, Richard Socher, and Christopher&nbsp;D. Manning.
 Glove: Global vectors for word representation.
 In <i>Empirical Methods in Natural Language Processing (EMNLP)</i>,
pages 1532--1543, 2014.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_75"></a>[75]&nbsp;&nbsp;</td><td>
Chris Piech, Jonathan Huang, Andy Nguyen, Mike Phulsuksombati, Mehran Sahami,
and Leonidas Guibas.
 Learning program embeddings to propagate feedback on student code.
 In <i>Proceedings of the 32nd International Conference on
International Conference on Machine Learning - Volume 37</i>, pages 1093--1102,
2015.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_76"></a>[76]&nbsp;&nbsp;</td><td>
Alexander Pritzel, Benigno Uria, Sriram Srinivasan, Adria&#x300;&nbsp;Puigdome&#x300;nech
Badia, Oriol Vinyals, Demis Hassabis, Daan Wierstra, and Charles Blundell.
 Neural episodic control.
 In Doina Precup and Yee&nbsp;Whye Teh, editors, <i>Proceedings of the
34th International Conference on Machine Learning</i>, volume&nbsp;70 of <i>Proceedings of Machine Learning Research</i>, pages 2827--2836, International
Convention Centre, Sydney, Australia, 2017. PMLR.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_77"></a>[77]&nbsp;&nbsp;</td><td>
Alexander Pritzel, Benigno Uria, Sriram Srinivasan, Adria&#x300;&nbsp;Puigdome&#x300;nech
Badia, Oriol Vinyals, Demis Hassabis, Daan Wierstra, and Charles Blundell.
 Neural episodic control.
 <i>CoRR</i>, arXiv:1703.01988, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_78"></a>[78]&nbsp;&nbsp;</td><td>
Neil&nbsp;C. Rabinowitz, Frank Perbet, H.&nbsp;Francis Song, Chiyuan Zhang, S.M.&nbsp;Ali
Eslami, and Matthew Botvinick.
 Machine theory of mind.
 <i>CoRR</i>, arXiv:1802.07740, 2018.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_79"></a>[79]&nbsp;&nbsp;</td><td>
Scott&nbsp;E. Reed and Nando de&nbsp;Freitas.
 Neural programmer-interpreters.
 <i>CoRR</i>, arXiv:1511.06279, 2015.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_80"></a>[80]&nbsp;&nbsp;</td><td>
Charles Rich and Richard&nbsp;C. Waters.
 The programmer's apprentice: A research overview.
 <i>Computer</i>, 21(11):10--25, 1988.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_81"></a>[81]&nbsp;&nbsp;</td><td>
Charlies Rich and Richard&nbsp;C. Waters.
 Automatic programming: myths and prospects.
 <i>IEEE Computer</i>, 21, 1988.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_82"></a>[82]&nbsp;&nbsp;</td><td>
Martin&nbsp;A. Riedmiller, Roland Hafner, Thomas Lampe, Michael Neunert, Jonas
Degrave, Tom&nbsp;Van de&nbsp;Wiele, Volodymyr Mnih, Nicolas Heess, and Jost&nbsp;Tobias
Springenberg.
 Learning by playing - solving sparse reward tasks from scratch.
 <i>CoRR</i>, arXiv:1802.10567, 2018.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_83"></a>[83]&nbsp;&nbsp;</td><td>
D.&nbsp;E. Rumelhart, G.&nbsp;E. Hinton, and J.&nbsp;L. McClelland.
 A general framework for parallel distributed processing.
 In D.&nbsp;E. Rumelhart and J.&nbsp;L. McClelland, editors, <i>Parallel
Distributed Processing, Volume 1 - Explorations in the Microstructure of
Cognition: Foundations</i>, pages 45--76. MIT Press, Cambridge, MA, 1986.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_84"></a>[84]&nbsp;&nbsp;</td><td>
Abigail See, Peter&nbsp;J. Liu, and Christopher&nbsp;D. Manning.
 Get to the point: Summarization with pointer-generator networks.
 In <i>Proceedings of the 56th Annual Meeting of the Association for
Computational Linguistics</i>, volume arXiv:1704.04368, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_85"></a>[85]&nbsp;&nbsp;</td><td>
Richard Shin, Illia Polosukhin, and Dawn Song.
 Towards specification-directed program repair.
 In <i>Submitted to International Conference on Learning
Representations</i>, 2018.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_86"></a>[86]&nbsp;&nbsp;</td><td>
David Silver, Hado van Hasselt, Matteo Hessel, Tom Schaul, Arthur Guez, Tim
Harley, Gabriel Dulac-Arnold, David&nbsp;P. Reichert, Neil&nbsp;C. Rabinowitz,
Andre&#x301; Barreto, and Thomas Degris.
 The predictron: End-to-end learning and planning.
 <i>Proceedings of the 34th International Conference on Machine
Learning</i>, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_87"></a>[87]&nbsp;&nbsp;</td><td>
T.&nbsp;F. Smith and M.&nbsp;S. Waterman.
 Identification of common molecular subsequences.
 <i>Journal of Molecular Biology</i>, 147(1):195--197, 1981.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_88"></a>[88]&nbsp;&nbsp;</td><td>
Pablo Sprechmann, Siddhant&nbsp;M. Jayakumar, Jack&nbsp;W. Rae, Alexander Pritzel,
Adria&nbsp;Puigdomenech Badia, Benigno Uria, Oriol Vinyals, Demis Hassabis, Razvan
Pascanu, and Charles Blundell.
 Memory-based parameter adaptation.
 <i>International Conference on Learning Representations</i>, 2018.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_89"></a>[89]&nbsp;&nbsp;</td><td>
Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus.
 Weakly supervised memory networks.
 <i>CoRR</i>, arXiv:1503.08895, 2015.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_90"></a>[90]&nbsp;&nbsp;</td><td>
Ilya Sutskever and Geoffrey&nbsp;E Hinton.
 Using matrices to model symbolic relationship.
 In D.&nbsp;Koller, D.&nbsp;Schuurmans, Y.&nbsp;Bengio, and L.&nbsp;Bottou, editors, <i>Advances in Neural Information Processing Systems 21</i>, pages 1593--1600.
Curran Associates, Inc., 2009.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_91"></a>[91]&nbsp;&nbsp;</td><td>
Richard&nbsp;S. Sutton, Doina Precup, and Satinder Singh.
 Between MDPs and semi-MDPs: A framework for temporal abstraction
in reinforcement learning.
 <i>Artificial. Intelligence</i>, 112(1-2):181--211, 1999.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_92"></a>[92]&nbsp;&nbsp;</td><td>
Aviv Tamar, Yi&nbsp;Wu, Garrett Thomas, Sergey Levine, and Pieter Abbeel.
 Value iteration networks.
 In <i>Proceedings of the 30th International Conference on Neural
Information Processing Systems</i>. Curran Associates Inc., 2016.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_93"></a>[93]&nbsp;&nbsp;</td><td>
T.&nbsp;J. Teyler and J.&nbsp;W. Rudy.
 The hippocampal indexing theory and episodic memory: updating the
index.
 <i>Hippocampus</i>, 17(12):1158--1169, 2007.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_94"></a>[94]&nbsp;&nbsp;</td><td>
E.&nbsp;Tulving, W.&nbsp;Donaldson, and G.H. Bower.
 <i>Organization of memory</i>.
 Academic Press, 1972.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_95"></a>[95]&nbsp;&nbsp;</td><td>
Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly.
 Pointer networks.
 In C.&nbsp;Cortes, N.&nbsp;D. Lawrence, D.&nbsp;D. Lee, M.&nbsp;Sugiyama, and R.&nbsp;Garnett,
editors, <i>Advances in Neural Information Processing Systems 28</i>, pages
2692--2700. Curran Associates, Inc., 2015.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_96"></a>[96]&nbsp;&nbsp;</td><td>
Oriol Vinyals and Quoc&nbsp;V. Le.
 A neural conversational model.
 In <i>ICML Deep Learning Workshop</i>, 2015.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_97"></a>[97]&nbsp;&nbsp;</td><td>
Shuohang Wand and Jing Jiang.
 Machine comprehension using match-LSTM and answer pointer.
 In <i>International Conference on Learning Representations</i>, volume
arXiv:1608.07905, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_98"></a>[98]&nbsp;&nbsp;</td><td>
Jane&nbsp;X Wang, Zeb Kurth-Nelson, Dharshan Kumaran, Dhruva Tirumala, Hubert Soyer,
Joel&nbsp;Z Leibo, Demis Hassabis, and Matthew Botvinick.
 Prefrontal cortex as a meta-reinforcement learning system.
 <i>Nature Neuroscience</i>, 21:860--868, 2018.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_99"></a>[99]&nbsp;&nbsp;</td><td>
Ke&nbsp;Wang, Rishabh Singh, and Zhendong Su.
 Dynamic neural program embedding for program repair.
 <i>CoRR</i>, arXiv:1711.07163, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_100"></a>[100]&nbsp;&nbsp;</td><td>
Greg Wayne, Chia-Chun Hung, David Amos, Mehdi Mirza, Arun Ahuja, Agnieszka
Grabska-Barwinska, Jack Rae, Piotr Mirowski, Joel&nbsp;Z. Leibo, Adam Santoro,
Mevlana Gemici, Malcolm Reynolds, Tim Harley, Josh Abramson, Shakir Mohamed,
Danilo Rezende, David Saxton, Adam Cain, Chloe Hillier, David Silver, Koray
Kavukcuoglu, Matt Botvinick, Demis Hassabis, and Timothy Lillicrap.
 Unsupervised predictive memory in a goal-directed agent.
 <i>CoRR</i>, arXiv:1803.10760, 2018.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_101"></a>[101]&nbsp;&nbsp;</td><td>
Theophane Weber, Se&#x301;bastien Racanie&#x300;re, David&nbsp;P. Reichert, Lars
Buesing, Arthur Guez, Danilo&nbsp;Jimenez Rezende, Adria&#x300;&nbsp;Puigdome&#x300;nech
Badia, Oriol Vinyals, Nicolas Heess, Yujia Li, Razvan Pascanu, Peter
Battaglia, David Silver, and Daan Wierstra.
 Imagination-augmented agents for deep reinforcement learning.
 <i>CoRR</i>, arXiv:1707.06203, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_102"></a>[102]&nbsp;&nbsp;</td><td>
Jason Weston, Sumit Chopra, and Antoine Bordes.
 Memory networks.
 <i>CoRR</i>, arXiv:1410.3916, 2014.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_103"></a>[103]&nbsp;&nbsp;</td><td>
Catherine Wong.
 Reconstructive memory for abstract selective recall.
 Representative Final Project Archive for Stanford CS379C in Spring
2018, 2018.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_104"></a>[104]&nbsp;&nbsp;</td><td>
Xiaojun Xu, Chang Liu, Qian Feng, Heng Yin, Le&nbsp;Song, and Dawn Song.
 Neural network-based graph embedding for cross-platform binary code
similarity detection.
 <i>CoRR</i>, arXiv:1708.06525, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_105"></a>[105]&nbsp;&nbsp;</td><td>
Pengcheng Yin and Graham Neubig.
 A syntactic neural model for general-purpose code generation.
 In <i>The 55th Annual Meeting of the Association for Computational
Linguistics (ACL)</i>, Vancouver, Canada, 2017.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_106"></a>[106]&nbsp;&nbsp;</td><td>
Matthew&nbsp;D. Zeiler, Dilip Kirshnan, Graham&nbsp;W. Taylor, and Rob Fergus.
 Deconvolutional networks.
 In <i>IEEE International Conference on Computer Vision and
Pattern Recognition</i>, pages 2528--2535, 2010.<p>
</p>
</td></tr>
<tr><td align=right valign=top><a name="node_bib_107"></a>[107]&nbsp;&nbsp;</td><td>
M.D. Zeiler, G.W. Taylor, and R.&nbsp;Fergus.
 Adaptive deconvolutional networks for mid and high level feature
learning.
 In <i>IEEE International Conference on Computer Vision</i>, pages
2018--2025, 2011.<p>
</p>
</table><p>

</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<a name="node_sec_A"></a>
<h1 class=section><a href="#node_toc_node_sec_A">A&nbsp;&nbsp;Human-Like Cognitive Architectures</a></h1>
<p></p>
<p>
Our objective in developing systems that incorporate characteristics of human intelligence is three fold: First, humans provide a compelling solution to the problem of building intelligent systems that we can use as a basic blueprint and then improve upon. Second, the resulting AI systems are likely to be well suited to developing assistants that complement and extend human intelligence while operating in a manner comprehensible to human understanding. Finally, cognitive and systems neuroscience provide clues to engineers interested in exploiting what we know concerning how humans think about and solve problems. In this appendix, we demonstrate one attempt to concretely realize what we've learned from these disciplines in an architecture constructed from off-the-shelf neural networks. </p>
<p>
The programmer's apprentice relies on multiple sources of input, including dialogue in the form of text utterances, visual information from an editor buffer shared by the programmer and apprentice and information from a specially instrumented integrated development environment designed for analyzing, writing and debugging code adapted to interface seamlessly with the apprentice. This input is processed by a collection of neural networks modeled after the primary sensory areas in the primate brain. The output of these networks feeds into a hierarchy of additional networks corresponding to uni-modal secondary and multi-modal association areas that produce increasingly abstract representations as one ascends the hierarchy &#8212; see Figure&nbsp;<a href="#fig_Posterior_Cortex_Semantic_Memory">50</a>.</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
<a name="fig_Posterior_Cortex_Semantic_Memory"></a>
</p>
<a name="node_fig_Temp_33"></a>
<div class=:figure align=center><table width=100%><tr><td align=center><hr>
<p>
</p>
<div align=center><table><tr><td>
 
<img width=550 src="./figures/Posterior_Cortex_Semantic_Memory.png"></td></tr></table></div>

</td></tr>
<tr><td align=left><b>Figure 50:</b>&nbsp;&nbsp;The architecture of the apprentice sensory cortex including the layers corresponding to abstract, multi-modal representations handled by the association areas can be realized as a multi-layer hierarchical neural network model consisting of standard neural network components whose local architecture is primarily determined by the sensory modality involved. This graphic depicts these components as encapsulated in thought bubbles of the sort often employed in cartoons to indicate what some cartoon character is thinking. Analogously, the technical term &quot;thought vector&quot; is used to refer to the activation state of the output layer of such a component.</td></tr>
<tr><td>
<hr>
<p>
</p>
</td></tr></table></div><p></p>
<p>
</p>
<p>
Stanislas Dehaene and his colleagues at the Colle&#x300;ge de France in Paris developed a computational model of consciousness that provides a practical framework for thinking about consciousness that is sufficiently detailed for much of what an engineer might care about in designing digital assistants&nbsp;[<a href="#node_bib_25">25</a>]. Dehaene’s work extends the <i>Global Workspace</i> Theory of Bernard Baars&nbsp;[<a href="#node_bib_3">3</a>]. Dehaene’s version of the theory combined with Yoshua Bengio’s concept of a <i>consciousness prior</i> and deep reinforcement learning&nbsp;[<a href="#node_bib_60">60</a>,&nbsp;<a href="#node_bib_63">63</a>] suggest a model for constructing and maintaining the cognitive states that arise and persist during complex problem solving&nbsp;[<a href="#node_bib_5">5</a>].</p>
<p>
Global Workspace Theory accounts for both conscious and unconscious thought with the primary distinction for our purpose being that the former has been selected for attention and the latter has not been so selected. Sensory data arrives at the periphery of the organism. The data is initially processed in the primary sensory areas located in posterior cortex, propagates forward and is further processed in increasingly-abstract multi-modal association areas. Even as information flows forward toward the front of the brain, the results of abstract computations performed in the association areas are fed back toward the primary sensory cortex. This basic pattern of activity is common in all mammals. </p>
<p>
The human brain has evolved to handle language. In particular, humans have a large frontal cortex that includes machinery responsible for conscious awareness and that depends on an extensive network of specialized neurons called spindle cells that span a large portion of the posterior cortex allowing circuits in the frontal cortex to sense relevant activity throughout this area and then manage this activity by creating and maintaining the persistent state vectors that are necessary when inventing extended naratives or working on complex problems that require juggling many component concepts at once. Figure&nbsp;<a href="#fig_Global_Workspace_Conscious_Attention">51</a> suggests a neural architecture combining the idea of a global workspace with that of an attentional system for identifying relevant input.</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
<a name="fig_Global_Workspace_Conscious_Attention"></a>
</p>
<a name="node_fig_Temp_34"></a>
<div class=:figure align=center><table width=100%><tr><td align=center><hr>
<p>
</p>
<div align=center><table><tr><td>
 
<img width=530 src="./figures/Global_Workspace_Conscious_Attention.png"></td></tr></table></div>

</td></tr>
<tr><td align=left><b>Figure 51:</b>&nbsp;&nbsp;The basic capabilities required to support conscious awareness can be realized in a relatively simple computational architecture that represents the apprentice’s global workspace and incorporates a model of attention that surveys activity throughout somatosensory and motor cortex, identifies the activity relevant to the current focus of attention and then maintains this state of activity so that it can readily be utilized in problem solving.  In the case of the apprentice, new information is ingested into the model at the system interface, including dialog in the form of text, visual information in the form of editor screen images, and a collection of programming-related signals originating from a suite of software development tools. 
Single-modality sensory information feeds into multi-modal association areas to create rich abstract representations. Attentional networks in the prefrontal cortex take as input activations occurring throughout the posterior cortex. These networks are trained by reinforcement learning to identify areas of activity worth attending to and the learned policy selects a set of these areas to attend to and sustain. This attentional process is guided by a prior that prefers low-dimensional thought vectors corresponding to statements about the world that are either true, highly probable or very useful for making decisions. Humans can sustain only a few such activations at a time. The apprentice need not be so constrained.</td></tr>
<tr><td>
<hr>
<p>
</p>
</td></tr></table></div><p></p>
<p>
</p>
<p>
Fundamental to our understanding of human cognition is the essential tradeoff between fast, highly-parallel, context-sensitive, distributed connectionist-style computations and slow, serial, systematic, combinatorial symbolic computations. In developing the programmer's apprentice, symbolic computations of the sort common in conventional computing are realized using extensions that provide a differentiable interface to conventional memory and information processing hardware and software. Such interfaces include the Neural Turing Machine&nbsp;[<a href="#node_bib_39">39</a>] (NTM), Memory Network Model&nbsp;[<a href="#node_bib_102">102</a>,&nbsp;<a href="#node_bib_89">89</a>] and Differentiable Neural Computer&nbsp;[<a href="#node_bib_40">40</a>] (DNC).</p>
<p>
The global workspace summarizes recent experience in terms of sensory input, its integration, abstraction and inferred relevance to the context in which the underlying information was acquired. To exploit the knowledge encapsulated in such experience, the apprentice must identify and make available relevant experience. The apprentice’s experiential knowledge is encoded as tuples in a Neural Turing Machine (NTM) memory that supports associative recall. We’ll ignore the details of the encoding process to focus on how episodic memory is organized, searched and applied to solving problems.</p>
<p>
In the biological analog of an NTM the hippocampus and entorhinal region of the frontal cortex play the role of episodic memory and several subcortical circuits including the basal ganglia comprise the controller&nbsp;[<a href="#node_bib_69">69</a>,&nbsp;<a href="#node_bib_67">67</a>]. The controller employs associative keys in the form of low-dimensional vectors generated from activations highlighted in the global workspace to access related memories that are then actively maintained in the prefrontal cortex and serve to bias processing throughout the brain but particularly in those circuits highlighted in the global workspace. Figure&nbsp;<a href="#fig_Global_Workspace_Episodic_Memory">52</a> provides a sketch of how this is accomplished in the apprentice architecture. </p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
<a name="fig_Global_Workspace_Episodic_Memory"></a>
</p>
<a name="node_fig_Temp_35"></a>
<div class=:figure align=center><table width=100%><tr><td align=center><hr>
<p>
</p>
<div align=center><table><tr><td>
 
<img width=590 src="./figures/Global_Workspace_Episodic_Memory.png"></td></tr></table></div>

</td></tr>
<tr><td align=left><b>Figure 52:</b>&nbsp;&nbsp;You can think of the episodic memory encoded in the hippocampus and entorhinal cortex as RAM and the actively maintained memories in the prefrontal cortex as the contents of registers in a conventional von Neumann architecture. Since the activated memories have different temporal characteristics and functional relationships with the contents of the global workspace, we implement them as two separate NTM memory systems each with its own special-purpose controller. Actively maintained information highlighted in the global workspace is used to generate keys for retrieving relevant memories that augment the highlighted activations. In the DNC paper&nbsp;[<a href="#node_bib_40">40</a>] appearing in <i>Nature</i>, the authors point out that &quot;an associative key that only partially matches the content of a memory location can still be used to attend strongly to that location [allowing] allowing the content of one address [to] effectively encode references to other addresses&quot;. The contents of memory consist of thought vectors that can be composed with other thought vectors to shape the global context for interpretation.</td></tr>
<tr><td>
<hr>
<p>
</p>
</td></tr></table></div><p></p>
<p>
</p>
<p>
Figure&nbsp;<a href="#fig_High_Level_Assistant_Architecture">53</a> combines the components that we've introduced so far in a single neural network architecture. The empty box on the far right includes both the language processing and dialogue management systems as well the networks that interface with FIDE and the other components involved in code synthesis. There are several classes of programming tasks that we might tackle in order to show off the apprentice, including commenting, extending, refactoring and repairing programs. We could focus on functional languages like Scheme or Haskell, strongly typed languages like Pascal and Java or domain specific languages like HTML or SQL. </p>
<p>
However, rather than emphasize any particular programming language or task, in the remainder of this appendix we focus on how one might represent structured programs consisting of one or more procedures in a distributed connectionist framework so as to exploit the advantages of this computational paradigm. We believe the highly-parallel, contextual, connectionist computations that dominate in human information processing will complement the primarily-serial, combinatorial, symbolic computations that characterize conventional information processing and will have a considerable positive impact on the development of practical automatic programming methods.</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
<a name="fig_High_Level_Assistant_Architecture"></a>
</p>
<a name="node_fig_Temp_36"></a>
<div class=:figure align=center><table width=100%><tr><td align=center><hr>
<p>
</p>
<div align=center><table><tr><td>
 
<img width=595 src="./figures/High_Level_Assistant_Architecture.png"></td></tr></table></div>

</td></tr>
<tr><td align=left><b>Figure 53:</b>&nbsp;&nbsp;This slide summarizes the architectural components introduced so far in a single model. Data in the form of text transcriptions of ongoing dialogue, source code and related documentation and output from the integrated development environment are the primary input to the system and are handled by relatively standard neural network models. The Q-network for the attentional RL system is realized as a multi-layer convolutional network. The two DNC controllers are straightforward variations on existing network models with a second controller responsible for maintaining a priority queue encodings of relevant past experience retrieved from episodic memory. The nondescript box labeled &quot;motor cortex&quot; serves as a placeholder for the neural networks responsible for managing dialogue and handling tasks related to programming and code synthesis.</td></tr>
<tr><td>
<hr>
<p>
</p>
</td></tr></table></div><p></p>
<p>
</p>
<p>
The integrated development environment and its associated software engineering tools constitute an extension of the apprentice’s capabilities in much the same way that a piano or violin extends a musician or a prosthetic limb extends someone who has lost an arm or leg. The extension becomes an integral part of the person possessing it and over time their brain creates a topographic map that facilitates interacting with the extension<a name="node_call_footnote_Temp_37"></a><sup><small><a href="#node_footnote_Temp_37">28</a></small></sup>. </p>
<p>
As engineers designing the apprentice, part of our job is to create tools that enable the apprentice to learn its trade and eventually become an expert. Conventional IDE tools simplify the job of software engineers in designing software. The fully instrumented IDE (FIDE) that we engineer for the apprentice will be integrated into the apprentice’s cognitive architecture so that tasks like stepping a debugger or setting breakpoints are as easy for the apprentice as balancing parentheses and checking for spelling errors in a text editor is for us.</p>
<p>
As a first step in simplifying the use of FIDE for coding, the apprentice is designed to manipulate programs as abstract syntax trees (AST) and easily move back and forth between the AST representation and the original source code in collaborating with the programmer. Both the apprentice and the programmer can modify or make references to text appearing in the FIDE window by pointing to items or highlighting regions of the source code. The text and AST versions of the programs represented in the FIDE are automatically synchronized so that the program under development is forced to adhere to certain syntactic invariants. </p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
<a name="fig_Differentiable_Structured_Programs"></a>
</p>
<a name="node_fig_Temp_38"></a>
<div class=:figure align=center><table width=100%><tr><td align=center><hr>
<p>
</p>
<div align=center><table><tr><td>
 
<img width=325 src="./figures/Differentiable_Structured_Programs.png"></td></tr></table></div>

</td></tr>
<tr><td align=left><b>Figure 54:</b>&nbsp;&nbsp;We use pointers to represent programs as abstract syntax trees and partition the NTM memory, as in a conventional computer, into program memory and a LIFO execution (call) stack to support recursion and reentrant procedure invocations, including call frames for return addresses, local variable values and related parameters. The NTM controller manages the program counter and LIFO call stack to simulate the execution of programs stored in program memory. Program statements are represented as embedding vectors and the system learns to evaluate these representations in order to generate intermediate results that are also embeddings. It is a simple matter to execute the corresponding code in the FIDE and incorporate any of the results as features in embeddings.</td></tr>
<tr><td>
<hr>
<p>
</p>
</td></tr></table></div><p></p>
<p>
</p>
<p>
To support this hypothesis, we are developing distributed representations for programs that enable the apprentice to efficiently search for solutions to programming problems by allowing the apprentice to easily move back and forth between the two paradigms, exploiting both conventional approaches to program synthesis and recent work on machine learning and inference in artificial neural networks. Neural Turing Machines coupled with reinforcement learning are capable of learning simple programs. We are interested in representing structured programs expressed in modern programming languages. Our approach is to alter the NTM controller and impose additional structure on the NTM memory designed to support procedural abstraction. </p>
<p>
What could we do with such a representation? It is important to understand why we don’t work with some intermediate representation like bytecodes. By working in the target programming language, we can take advantage of both the abstractions afforded by the language and the expert knowledge of the programmer about how to exploit those abstractions. The apprentice is bootstrapped with several statistical language models: one trained on a natural language corpus and the other on a large code repository. Using these resources and the means of representing and manipulating program embeddings, we intend to train the apprentice to predict the next expression in a partially constructed program by using a variant of imagination-based planning&nbsp;[<a href="#node_bib_72">72</a>]. As another example, we will attempt to leverage NLP methods to generate proposals for substituting one program fragment for another as the basis for code completion. </p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
<a name="fig_Differentiable_Program_Emulation"></a>
</p>
<a name="node_fig_Temp_39"></a>
<div class=:figure align=center><table width=100%><tr><td align=center><hr>
<p>
</p>
<div align=center><table><tr><td>
 
<img width=325 src="./figures/Differentiable_Program_Emulation.png"></td></tr></table></div>

</td></tr>
<tr><td align=left><b>Figure 55:</b>&nbsp;&nbsp;This slide illustrates how we make use of input / output pairs as program invariants to narrow search for the next statement in the evolving target program. At any given moment the call stack contains the trace of a single conditioned path through the developing program. A single path is unlikely to provide sufficient information to account for the constraints implicit in all of the sample input / output pairs and so we intend to use a limited lookahead planning system to sample multiple execution traces in order to inform the prediction of the next program statement. 
These so-called imagination-augmented agents implement a novel architecture for reinforcement learning that balances exploration and exploitation using imperfect models to generate trajectories from some initial state using actions sampled from a rollout policy&nbsp;[<a href="#node_bib_72">72</a>,&nbsp;<a href="#node_bib_101">101</a>,&nbsp;<a href="#node_bib_46">46</a>,&nbsp;<a href="#node_bib_43">43</a>]. These trajectories are then combined and fed to an output policy along with the action proposed by a model-free policy to make better decisions. There are related reinforcement learning architectures that perform Monte Carlo Markov chain search to apply and collect the constraints from multiple input / output pairs.</td></tr>
<tr><td>
<hr>
<p>
</p>
</td></tr></table></div><p></p>
<p>
</p>
<p>
The Differentiable Neural Program (DNP) representation and associated NTM controller for managing the call stack and single-stepping through such programs allow us to exploit the advantages of distributed vector representations to predict the next statement in a program under construction. This model makes it easy to take advantage of supplied natural language descriptions and example input / output pairs plus incorporate semantic information in the form of execution traces generated by utilizing the FIDE to evaluate each statement and encoding information about local variables on the stack. </p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<a name="node_sec_B"></a>
<h1 class=section><a href="#node_toc_node_sec_B">B&nbsp;&nbsp;Bootstrapped Linguistic Competence</a></h1>
<p></p>
<p>
In this appendix, we consider how we might design an end-to-end training protocol for bootstrapping a variant of the programmer's apprentice application. We begin with the analogous stages in early child development. Each of the following four stages is briefly introduced with additional technical details provided in the accompanying footnotes:
</p>
<ul>
<li><p>Basic cognitive bootstrapping and linguistic grounding<a name="node_call_footnote_Temp_40"></a><sup><small><a href="#node_footnote_Temp_40">29</a></small></sup>: </p>
<ul>
<li><p>modeling language: statistical <em>n</em>-gram language model trained on programming corpus;
</p>
<li><p>hierarchical planning: automated tutor generates lessons using curriculum training;
</p>
</ul><p>
</p>
<li><p>Simple interactive behavior for signaling and editing<a name="node_call_footnote_Temp_42"></a><sup><small><a href="#node_footnote_Temp_42">31</a></small></sup>: </p>
<ul>
<li><p>following instruction: learning to carry out simple plans one instruction at a time;
</p>
<li><p>explaining behavior: providing short explanations of behavior, acknowledging failure;
</p>
</ul><p>
</p>
<li><p>Mixed dialogue interleaving instruction and mirroring<a name="node_call_footnote_Temp_43"></a><sup><small><a href="#node_footnote_Temp_43">32</a></small></sup>: </p>
<ul>
<li><p>classifying intention: learning to categorize tasks and summarize intentions to act;
</p>
<li><p>confirming comprehension: conveying practical understanding of specific instructions;
</p>
</ul><p>
</p>
<li><p>Composite behaviors corresponding to simple repairs<a name="node_call_footnote_Temp_44"></a><sup><small><a href="#node_footnote_Temp_44">33</a></small></sup>: </p>
<ul>
<li><p>executing complex plans: generating and executing multi-step plans with contingencies;
</p>
<li><p>recovering from failure: backtracking, recovering, retracting steps on failed branches;
</p>
</ul><p>
</p>
</ul><p></p>
<p>
</p>
<p>
</p>
<p>
</p>
<div class=footnoterule><hr></div><p></p>
<div class=footnote><p><a name="node_footnote_Temp_2"></a><sup><small><a href="#node_call_footnote_Temp_2">1</a></small></sup> The &quot;Sorcerer's Apprentice&quot; is a symphonic poem by the French composer Paul Dukas, written in 1897. Subtitled &quot;Scherzo after a ballad by Goethe&quot;, the piece was based on Johann Wolfgang von Goethe's 1797 poem of the same name. By far the most performed and recorded of Dukas's works, its most notable performance was conducted by Leopold Stokowski in the Walt Disney 1940 animated film &quot;Fantasia&quot; has led to the piece becoming widely known to audiences outside the classical concert hall. <a href="https://en.wikipedia.org/wiki/The_Sorcerer's_Apprentice_(Dukas){SOURCE}"></a></p>
<p><a name="node_footnote_Temp_3"></a><sup><small><a href="#node_call_footnote_Temp_3">2</a></small></sup> Rich and Waters were circumspect about the near-term prospects for automated programming&nbsp;[<a href="#node_bib_81">81</a>]. The abstract of Charlies Rich and Richard Waters original paper&nbsp;[<a href="#node_bib_80">80</a>] on the Programmer's Apprentice project reads:
</p>
<blockquote>
The long-term goal of the Programmer's Apprentice project is to develop a theory of how expert programmers analyze, synthesize, modify, explain, specify, verify, and document programs. The authors present their vision of the Programmer's Apprentice, the principles and techniques underlying it, and their progress toward it. The primary vehicle for this exposition is three scenarios illustrating the use of the Apprentice in three phases of the programming task: implementation, design, and requirements. The first scenario is taken from a completed working prototype. The second and third scenarios are the targets for prototype systems currently under construction.
</blockquote></p>
<p><a name="node_footnote_Temp_6"></a><sup><small><a href="#node_call_footnote_Temp_6">5</a></small></sup> The phrase <a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">Knowledge Representation</a> seems so dated that it must be back in vogue again. It's interesting to think about the evolution of our thinking about representation as chronicled in the names of major technical conferences relating to artificial intelligence. By 1990, the major national and international AI conferences, including the <a href="http://www.aaai.org/Conferences/conferences.php">National Conference on Artificial Intelligence</a> &#8212; I got roped into co-chairing AAAI-91 held in Anaheim, California &#8212; and the <a href="https://ijcai.org/">International Joint Conference on Artificial Intelligence</a> &#8212; once again I succumbed to peer pressure and co-chaired IJCAI-99 which was held in Stockholm, Sweden &#8212; were getting so large and were receiving so many submissions that first satellite and then independent conferences began springing up to cater to special interests including researchers interested in representation.</p>
<p>
For example, Ronald Brachman, Hector Levesque and Raymond Reiter co-chaired the first <a href="http://www.kr.org/index.php">International Conference on Knowledge Representation and Reasoning</a> (KR-89) in 1989. Then Usama Fayyad and Ramasamy Uthurusamy chaired the first <a href="https://www.aaai.org/Press/Proceedings/kdd95.php">International Conference on Knowledge Discovery and Data Mining</a> (KDD-95) in 1995. More recently Yoshua Bengio and Yann LeCun chaired the first <a href="International Conference on Learning Representations">International Conference on Learning Representations</a> (ICLR-13) in 2013. We might extrapolate the trend and imagine Vinod Khosla, Ray Kurzweil, Elon Musk, Peter Thiel and Mark Zuckerberg will co-chair the first <a href="https://www.santafe.edu/research/initiatives/interplanetary-project">Interplanetary Conference on Instantaneous Thought and Infinitely Extensible Memory</a> (ITEM-37) in 2037.</p>
<p><a name="node_footnote_Temp_5"></a><sup><small><a href="#node_call_footnote_Temp_5">4</a></small></sup> The phrases <a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">Knowledge Representation</a>&nbsp;[<a href="#node_bib_12">12</a>] and <a href="https://en.wikipedia.org/wiki/Cognitive_neuroscience">Cognitive Neuroscience</a>&nbsp;[<a href="#node_bib_35">35</a>] refer to important long-standing areas of study, each with their respective academic departments, national and international conferences and large numbers of advocates and adepts. Mentioning them both in the same breath could be orthodoxy or heresy depending on the context and the company you keep, but both disciplines &#8212; it could be argued that each one might be better characterized as a constellation of specialized disciplines<a name="node_call_footnote_Temp_6"></a><sup><small><a href="#node_footnote_Temp_6">5</a></small></sup>
&#8212; have made major contributions to our understanding of intelligence both biological and artificial. Together cognitive neurosciences make up a small but active contingent within the larger population of scientists who consider themselves part of neuroscience including anatomical, behavioral, cellular, cognitive, computational, developmental, genetic, molecular, pharmacological, physiological, psychological and systems neuroscience focusing on neural circuits and their function.</p>
<p><a name="node_footnote_Temp_4"></a><sup><small><a href="#node_call_footnote_Temp_4">3</a></small></sup> This particular section concerns the topic of <a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">knowledge representation</a>&nbsp;[<a href="#node_bib_12">12</a>] as it applies to the programmer's apprentice problem and emphases contributions from the <a href="https://en.wikipedia.org/wiki/Cognitive_neuroscience">cognitive neurosciences</a>&nbsp;[<a href="#node_bib_35">35</a>] as they apply to modeling how information is represented and processed in human-inspired cognitive architectures and connectionist models in particular<a name="node_call_footnote_Temp_5"></a><sup><small><a href="#node_footnote_Temp_5">4</a></small></sup>.</p>
<p><a name="node_footnote_Temp_7"></a><sup><small><a href="#node_call_footnote_Temp_7">6</a></small></sup> The neuroscientist, Moran Cerf, likes to recall an incident that occurred to him when he was young. Cerf enjoyed playing video games but couldn't afford to buy them and so he would go to stores that sold video games and play the demos. He recalls one time in which he started playing a new game and was doing remarkably well after a very short time having reached level III play before being interrupted by a message displayed on the screen that read &quot;Insert coin to play&quot;. He then realized that he hadn't been playing the game at all but rather he simply had been moving the joystick and had been imagining &#8212; indeed he was confident that &#8212; his moves were causing his meteoric rise in level.</p>
<p>
In hindsight it was clear to him that there were many times in which he had moved the joystick in the wrong direction but had remembered it as being the right direction and having the intended effect of improving his score. His subsequent research focuses on how human memory is susceptible to suggestion to the extent that we often remember what we want to and not what actually happened. Time and memory are intertwined. The former we experience as being incongruously mutable &#8212; an hour can seem infinitesimally short and a second interminably long, while the latter seems to us incontrovertibly fixed and yet neuroscience tells us that memories are subject to fantasy and random happenstance. </p>
<p>
If you're interested Moran Cerf's research, check out this YouTube<a href="https://www.youtube.com/watch?v=EVj3sU37gdI"></a>video of Cerf speaking at Talks at Google in which he &quot;describes his lab's work studying the brains of humans using unique tools to eavesdrop on the activity of individual cells of patients undergoing brain surgery while they are awake and behaving. He discusses how the work sheds light on the ways our brain processes information, and reflects on what it tells us about how we create the complex narrative we call 'us'.&quot;</p>
<p><a name="node_footnote_Temp_8"></a><sup><small><a href="#node_call_footnote_Temp_8">7</a></small></sup> The jargon of modern (deep) neural networks is like the argot of a new Freemasonry that has hardly begun to lay the foundations for the restoration of the connectionist temple. Terms like attention, consciousness, imagination, rewards and reinforcement get bandied about as if deeply descriptive of the architectures they are invoked to describe. The odd thing is that often they reveal more than they obfuscate. Even so, the learning curve is steep, and the mountain is constantly shifting.</p>
<p><a name="node_footnote_Temp_9"></a><sup><small><a href="#node_call_footnote_Temp_9">8</a></small></sup> Dehaene&nbsp;<em>et al</em>DehaeneetalPNAS-98 distinguish two main computational spaces within the brain: &quot;The first is a <i>processing network</i>, composed of a set of parallel, distributed and functionally specialized processors or modular sub-systems ranging from primary sensory processors (such as area V1) or unimodal processors (such as area V4), which combine multiple inputs within a given sensory modality, up to heteromodal processors (such as the visuo-tactile neurons in area LIP) that extract highly processed categorical or semantic information. Each processor is subsumed by topologically distinct cortical domains with highly-specific local or medium-range connections that <i>encapsulate</i> information relevant to its function.</p>
<p>
The second computational space is a <i>global workspace</i>, consisting of a distributed set of cortical neurons characterized by their ability to receive from and send back to homologous neurons in other cortical areas horizontal projections through long-range excitatory axons (which may impinge on either excitatory or inhibitory neurons). Our view is that this population of neurons does not belong to a distinct set of <i>cardinal</i> brain areas but, rather, is distributed among brain areas in variable proportions.&quot;</p>
<p><a name="node_footnote_Temp_10"></a><sup><small><a href="#node_call_footnote_Temp_10">9</a></small></sup> Here is the abstract syntax tree for <a href="https://en.wikipedia.org/wiki/Euclidean_algorithm">Euclid's algorithm</a> which is an efficient method for computing the greatest common divisor (GCD) of two numbers:
</p>
<div align=center><table><tr><td>

<img width=433 src="./figures/Euclids_Greatest_Common_Divisor_Method.png"></td></tr></table></div>
</p>
<p><a name="node_footnote_Temp_11"></a><sup><small><a href="#node_call_footnote_Temp_11">10</a></small></sup> <a href="https://en.wikipedia.org/wiki/Coq">Coq</a> is a formal proof management system that &quot;provides a formal language to write mathematical definitions, executable algorithms and theorems together with an environment for semi-interactive development of machine-checked proofs&quot; &#8212; excerpted from Mike Nahas' <a href="https://coq.inria.fr/tutorial-nahas">tutorial</a>. The Coq formal language is also a programming language. It was developed by and named after its inventor, Thierry Coquand, and employed by Georges Gonthier and Benjamin Werner to create a new proof of the <a href="https://en.wikipedia.org/wiki/Four_color_theorem">Four Color Theorem</a> first proved by Kenneth Appel and Wolfgang Haken using a combination of human and computer theorem proving techniques.</p>
<p><a name="node_footnote_Temp_13"></a><sup><small><a href="#node_call_footnote_Temp_13">11</a></small></sup> While the apprentice operates directly on the AST representation of the code, the IDE can be designed to periodically coerce this representation into a syntactically-correct form, display the result as human-readable code, and display meaningful annotations that highlight program fragments relevant to the ongoing collaboration and track the apprentice's attention.</p>
<p><a name="node_footnote_Temp_15"></a><sup><small><a href="#node_call_footnote_Temp_15">12</a></small></sup> From the ETH / SRI website: &quot;We provide a dataset consisting of parsed Parsed ASTs that were used to train and evaluate the DeepSyn tool. The Python programs are collected from GitHub repositories by removing duplicate files, removing project forks (copy of another existing repository), keeping only programs that parse and have at most 30K nodes in the AST and we aim to remove obfuscated files. Furthermore, we only used repositories with permissive and non-viral licenses such as MIT, BSD and Apache. For parsing, we used the Python AST parser included in Python 2.7. We also include the parser as part of our dataset. The dataset is split into two parts &#8212; 100K files used for training and 50K files used for evaluation.&quot;</p>
<p><a name="node_footnote_Temp_16"></a><sup><small><a href="#node_call_footnote_Temp_16">13</a></small></sup> The abstract for Graziano&nbsp;[<a href="#node_bib_41">41</a>]:
</p>
<blockquote>
The purpose of the attention schema theory is to explain how an information-processing device, the brain, arrives at the claim that it possesses a non-physical, subjective awareness, and assigns a high degree of certainty to that extraordinary claim. The theory does not address how the brain might actually possess a non-physical essence. It is not a theory that deals in the non-physical. It is about the computations that cause a machine to make a claim and to assign a high degree of certainty to the claim. The theory is offered as a possible starting point for building artificial consciousness. Given current technology, it should be possible to build a machine that contains a rich internal model of what consciousness is, attributes that property of consciousness to itself and to the people it interacts with, and uses that attribution to make predictions about human behavior. Such a machine would &quot;believe&quot; it is conscious and act like it is conscious, in the same sense that the human machine believes and acts.
</blockquote></p>
<p><a name="node_footnote_Temp_17"></a><sup><small><a href="#node_call_footnote_Temp_17">14</a></small></sup> The abstract for O'Reilly and Frank&nbsp;[<a href="#node_bib_68">68</a>]:
</p>
<blockquote>
The prefrontal cortex has long been thought to subserve both working memory (the holding of information online for processing) and executive functions (deciding how to manipulate working memory and perform processing). Although many computational models of working memory have been developed, the mechanistic basis of executive function remains elusive, often amounting to a homunculus. This article presents an attempt to deconstruct this homunculus through powerful learning mechanisms that allow a computational model of the prefrontal cortex to control both itself and other brain areas in a strategic, task-appropriate manner. These learning mechanisms are based on subcortical structures in the midbrain, basal ganglia, and amygdala, which together form an actor-critic architecture. The critic system learns which prefrontal representations are task relevant and trains the actor, which in turn provides a dynamic gating mechanism for controlling working memory updating. Computationally, the learning mechanism is designed to simultaneously solve the temporal and structural credit assignment problems.
</blockquote></p>
<p><a name="node_footnote_Temp_18"></a><sup><small><a href="#node_call_footnote_Temp_18">15</a></small></sup> The abstract for Sprechmann&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_88">88</a>]:
</p>
<blockquote>
Deep neural networks have excelled on a wide range of problems, from vision to language and game playing. Neural networks very gradually incorporate information into weights as they process data, requiring very low learning rates. If the training distribution shifts, the network is slow to adapt, and when it does adapt, it typically performs badly on the training distribution before the shift. Our method, Memory-based Parameter Adaptation, stores examples in memory and then uses a context-based lookup to directly modify the weights of a neural network. Much higher learning rates can be used for this local adaptation, reneging the need for many iterations over similar data before good predictions can be made. As our method is memory-based, it alleviates several shortcomings of neural networks, such as catastrophic forgetting, fast, stable acquisition of new knowledge, learning with an imbalanced class labels, and fast learning during evaluation. We demonstrate this on a range of supervised tasks: large-scale image classification and language modeling.
</blockquote></p>
<p><a name="node_footnote_Temp_19"></a><sup><small><a href="#node_call_footnote_Temp_19">16</a></small></sup> The abstract for Wang&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_98">98</a>]:
</p>
<blockquote>
Over the past 20 years, neuroscience research on reward-based learning has converged on a canonical model, under which the neurotransmitter dopamine stamps in associations between situations, actions and rewards by modulating the strength of synaptic connections between neurons. However, a growing number of recent findings have placed this standard model under strain. We now draw on recent advances in artificial intelligence to introduce a new theory of reward-based learning. Here, the dopamine system trains another part of the brain, the prefrontal cortex, to operate as its own free-standing learning system. This new perspective accommodates the findings that motivated the standard model, but also deals gracefully with a wider range of observations, providing a fresh foundation for future research.
</blockquote></p>
<p><a name="node_footnote_Temp_20"></a><sup><small><a href="#node_call_footnote_Temp_20">17</a></small></sup> A simple prototype implemented in Python for a dialog management system based on hierarchical planning is available <a href="https://github.com/diacritcal/Dialogical">here</a>. This implementation focuses on the problem of interaction and negotiation during learning and understanding in continuous conversation. The repository also includes documentation in the form of a technical report that is also available on the Stanford course website <a href="https://web.stanford.edu/class/cs379c/class_messages_listing/content/Interaction_Negotation_in_Understanding_Dialog/index.html">here</a>.</p>
<p><a name="node_footnote_Temp_21"></a><sup><small><a href="#node_call_footnote_Temp_21">18</a></small></sup> The abstract for Rabinowitz&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_78">78</a>]:
</p>
<blockquote>
Theory of mind (ToM; Premack and Woodruff, 1978) broadly refers to humans' ability to represent the mental states of others, including their desires, beliefs, and intentions. We propose to train a machine to build such models too. We design a Theory of Mind neural network &#8212; a ToMnet &#8212; which uses meta-learning to build models of the agents it encounters, from observations of their behaviour alone. Through this process, it acquires a strong prior model for agents' behaviour, as well as the ability to bootstrap to richer predictions about agents' characteristics and mental states using only a small number of behavioural observations. We apply the ToMnet to agents behaving in simple gridworld environments, showing that it learns to model random, algorithmic, and deep reinforcement learning agents from varied populations, and that it passes classic ToM tasks such as the &quot;Sally-Anne&quot; test (Wimmer and Perner, 1983; Baron-Cohen et al., 1985) of recognising that others can hold false beliefs about the world. We argue that this system &#8212; which autonomously learns how to model other agents in its world &#8212; is an important step forward for developing multi-agent AI systems, for building intermediating technology for machine-human interaction, and for advancing the progress on interpretable AI.
</blockquote></p>
<p><a name="node_footnote_Temp_22"></a><sup><small><a href="#node_call_footnote_Temp_22">19</a></small></sup> The abstract for Wayne&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_100">100</a>]:
</p>
<blockquote>
Animals execute goal-directed behaviours despite the limited range and scope of their sensors. To cope, they explore environments and store memories maintaining estimates of important information that is not presently available. Recently, progress has been made with artificial intelligence (AI) agents that learn to perform tasks from sensory input, even at a human level, by merging reinforcement learning (RL) algorithms with deep neural networks, and the excitement surrounding these results has led to the pursuit of related ideas as explanations of non-human animal learning. However, we demonstrate that contemporary RL algorithms struggle to solve simple tasks when enough information is concealed from the sensors of the agent, a property called &quot;partial observability&quot;. An obvious requirement for handling partially observed tasks is access to extensive memory, but we show memory is not enough; it is critical that the right information be stored in the right format. We develop a model, the Memory, RL, and Inference Network (MERLIN), in which memory formation is guided by a process of predictive modeling. MERLIN facilitates the solution of tasks in 3D virtual reality environments for which partial observability is severe and memories must be maintained over long durations. Our model demonstrates a single learning agent architecture that can solve canonical behavioural tasks in psychology and neurobiology without strong simplifying assumptions about the dimensionality of sensory input or the duration of experiences.
</blockquote></p>
<p><a name="node_footnote_Temp_23"></a><sup><small><a href="#node_call_footnote_Temp_23">20</a></small></sup> The abstract for Pascanu&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_72">72</a>]:
</p>
<blockquote>
Conventional wisdom holds that model-based planning is a powerful approach to sequential decision-making. It is often very challenging in practice, however, because while a model can be used to evaluate a plan, it does not prescribe how to construct a plan. Here we introduce the &quot;Imagination-based Planner&quot;, the first model-based, sequential decision-making agent that can learn to construct, evaluate, and execute plans. Before any action, it can perform a variable number of imagination steps, which involve proposing an imagined action and evaluating it with its model-based imagination. All imagined actions and outcomes are aggregated, iteratively, into a &quot;plan context&quot; which conditions future real and imagined actions. The agent can even decide how to imagine: testing out alternative imagined actions, chaining sequences of actions together, or building a more complex &quot;imagination tree&quot; by navigating flexibly among the previously imagined states using a learned policy. And our agent can learn to plan economically, jointly optimizing for external rewards and computational costs associated with using its imagination. We show that our architecture can learn to solve a challenging continuous control problem, and also learn elaborate planning strategies in a discrete maze-solving task. Our work opens a new direction toward learning the components of a model-based planning system and how to use them.  
</blockquote></p>
<p><a name="node_footnote_Temp_24"></a><sup><small><a href="#node_call_footnote_Temp_24">21</a></small></sup> The abstract for Das&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_20">20</a>]:
</p>
<blockquote>
We introduce the task of Visual Dialog, which requires an AI agent to hold a meaningful dialog with humans in natural, conversational language about visual content. Specifically, given an image, a dialog history, and a question about the image, the agent has to ground the question in the image, infer its context from history, and answer the question accurately. Visual Dialog is disentangled enough from a specific downstream task so as to serve as a general test of machine intelligence, while being grounded in vision enough to allow objective evaluation of individual responses and benchmark progress. We develop a novel two-person chat data-collection protocol to curate a large-scale Visual Dialog dataset (VisDial). VisDial v0.9 has been released and contains 1 dialog with 10 question-answer pairs on &asymp;120k images from COCO, with a total of &asymp;1.2M dialog question-answer pairs. We introduce a family of neural encoder-decoder models for Visual Dialog with 3 encoders &#8212; Late Fusion, Hierarchical Recurrent Encoder and Memory Network &#8212; and 2 decoders (generative and discriminative), which outperform a number of sophisticated baselines. We propose a retrieval-based evaluation protocol for Visual Dialog where the AI agent is asked to sort a set of candidate answers and evaluated on metrics such as mean-reciprocal-rank of human response. We quantify gap between machine and human performance on the Visual Dialog task via human studies. Our dataset, code, trained models and visual chatbot are available <a href="https://visualdialog.org/">here</a>.
</blockquote></p>
<p><a name="node_footnote_Temp_26"></a><sup><small><a href="#node_call_footnote_Temp_26">22</a></small></sup> For an introduction to the role of sleep in memory, check out the <a href="https://www.youtube.com/watch?v=stXhGMVJuqA">video</a> of the <i>The Mind after Midnight</i> at the World Science Festival. Original Program Date: June 3, 2011. Moderator: Carl Zimmer; Participants: Carlos H. Schenck, Matthew Wilson, Niels Rattenborg. While all three of the participants have interesting things to say, if you only have twenty minutes to spare, watch the segment featuring Matthew Wilson that runs through the middle third of the video from about 25:00 until 45:30 to hear how Wilson characterizes and contrasts the different ways in which rats employ NREM and REM sleep in learning from experience &#8212; allowing both fast replay and rewind during NREM and in imagining circumstances that never occurred but might occur in the future during REM.</p>
<p><a name="node_footnote_Temp_27"></a><sup><small><a href="#node_call_footnote_Temp_27">23</a></small></sup> Specifically, the field of <a href="https://en.wikipedia.org/wiki/Computer_science#Theoretical_computer_science">theoretical computer science</a> includes as subfields <a href="https://en.wikipedia.org/wiki/Computer_science#Data_structures_and_algorithms">data structures and algorithms</a>, <a href="https://en.wikipedia.org/wiki/Computer_science#Information_and_coding_theory">information and coding theory</a> and <a href="https://en.wikipedia.org/wiki/Computer_science#Programming_language_theory">programming language theory</a>. <a href="https://en.wikipedia.org/wiki/Computer_science#Artificial_intelligence">Artificial intelligence</a> and <a href="https://en.wikipedia.org/wiki/Computer_science#Human-computer_interaction">human-computer interaction</a> are considered as subfields of <a href="https://en.wikipedia.org/wiki/Computer_science#Computer_applications">computer applications</a> with computer vision, machine learning, natural language processing, pattern recognition and robotics all considered to be subdisciplines within AI.</p>
<p><a name="node_footnote_Temp_28"></a><sup><small><a href="#node_call_footnote_Temp_28">24</a></small></sup> The abstract for Abolafia&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_1">1</a>]:
</p>
<blockquote>
We consider the task of program synthesis in the presence of a reward function over the output of programs, where the goal is to find programs with maximal rewards. We employ an iterative optimization scheme, where we train an RNN on a dataset of K best programs from a priority queue of the generated programs so far. Then, we synthesize new programs and add them to the priority queue by sampling from the RNN. We benchmark our algorithm, called priority queue training (or PQT), against genetic algorithm and reinforcement learning baselines on a simple but expressive Turing complete programming language called BF. Our experimental results show that our simple PQT algorithm significantly outperforms the baselines. By adding a program length penalty to the reward function, we are able to synthesize short, human readable programs.
</blockquote></p>
<p><a name="node_footnote_Temp_29"></a><sup><small><a href="#node_call_footnote_Temp_29">25</a></small></sup> The abstract for Yin and Neubig&nbsp;[<a href="#node_bib_105">105</a>]:
</p>
<blockquote>
We consider the problem of parsing natural language descriptions into source code written in a general-purpose programming language like Python. Existing data-driven methods treat this problem as a language generation task without considering the underlying syntax of the target programming language. Informed by previous work in semantic parsing, in this paper we propose a novel neural architecture powered by a grammar model to explicitly capture the target syntax as prior knowledge. Experiments find this an effective way to scale up to generation of complex programs from natural language descriptions, achieving state-of-the-art results that well outperform previous code generation and semantic parsing approaches.
</blockquote></p>
<p><a name="node_footnote_Temp_30"></a><sup><small><a href="#node_call_footnote_Temp_30">26</a></small></sup> The abstract for Devlin&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_28">28</a>]:
</p>
<blockquote>
We study the problem of semantic code repair, which can be broadly defined as automatically fixing non-syntactic bugs in source code. The majority of past work in semantic code repair assumed access to unit tests against which candidate repairs could be validated. In contrast, the goal here is to develop a strong statistical model to accurately predict both bug locations and exact fixes without access to information about the intended correct behavior of the program. Achieving such a goal requires a robust contextual repair model, which we train on a large corpus of real-world source code that has been augmented with synthetically injected bugs. Our framework adopts a two-stage approach where first a large set of repair candidates are generated by rule-based processors, and then these candidates are scored by a statistical model using a novel neural network architecture which we refer to as Share, Specialize, and Compete. Specifically, the architecture (1) generates a  shared encoding of the source code using an RNN over the abstract syntax tree, (2) scores each candidate repair using specialized network modules, and (3) then normalizes these scores together so they can compete against one another in comparable probability space. We evaluate our model on a real-world test set gathered from GitHub containing four common categories of bugs. Our model is able to predict the exact correct repair 41% of the time with a single guess, compared to 13% accuracy for an attentional sequence-to-sequence model.
</blockquote></p>
<p><a name="node_footnote_Temp_31"></a><sup><small><a href="#node_call_footnote_Temp_31">27</a></small></sup> The abstract for Chen&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_18">18</a>]:
</p>
<blockquote>
Program translation is an important tool to migrate legacy code in one language into an ecosystem built in a different language. In this work, we are the first to consider employing deep neural networks toward tackling this problem. We observe that program translation is a modular procedure, in which a sub-tree of the source tree is translated into the corresponding target sub-tree at each step. To capture this intuition, we design a tree-to-tree neural network as an encoder-decoder architecture to translate a source tree into a target one. Meanwhile, we develop an attention mechanism for the tree-to-tree model, so that when the decoder expands one non-terminal in the target tree, the attention mechanism locates the corresponding sub-tree in the source tree to guide the expansion of the decoder. We evaluate the program translation capability of our tree-to-tree model against several state-of-the-art approaches. Compared against other neural translation models, we observe that our approach is consistently better than the baselines with a margin of up to 15 points. Further, our approach can improve the previous state-of-the-art program translation approaches by a margin of 20 points on the translation of real-world projects.
</blockquote></p>
<p><a name="node_footnote_Temp_37"></a><sup><small><a href="#node_call_footnote_Temp_37">28</a></small></sup> In the mammalian brain, information pertaining to sensing and motor control is topographically mapped to reflect the intrinsic structure of that information required for interpretation. This was early recognized in the work of Hubel and Wiesel&nbsp;[<a href="#node_bib_51">51</a>,&nbsp;<a href="#node_bib_50">50</a>] on the striate cortex of the cat and macaque monkey and in the work of Wilder Penfield&nbsp;[<a href="#node_bib_73">73</a>] developing the idea of a cortical homunculus in the primary motor and somatosensory areas of the brain located between the parietal and frontal lobes of the primate cortex. Such maps have become associated with the theory of embodied cognition.</p>
<p><a name="node_footnote_Temp_41"></a><sup><small><a href="#node_call_footnote_Temp_41">30</a></small></sup> <a name="hierarchical_task_network_planner"></a>
  Following&nbsp;[<a href="#node_bib_24">24</a>,&nbsp;<a href="#node_bib_11">11</a>], we employ hierarchical planning technology to implement several key components in the underlying bootstrapping and dialog management system. Each such component consists of a hierarchical task network (HTN) representing a collection of hierarchically organized plan schemas designed to run in a lightweight Python implementation of the HTN planner developed by Dana Nau&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_64">64</a>]:
</p>
<blockquote>
Hierarchical task network (HTN) planning is an approach to automated planning in which the dependency among actions can be given in the form of hierarchically structured networks. Planning problems are specified in the hierarchical task network approach by providing a set of tasks, which can be:
<ol>
<li><p><i>primitive tasks</i>, that roughly correspond to the actions of <a href="https://en.wikipedia.org/wiki/STRIPS">STRIPS</a>,
</p>
<li><p><i>compound tasks</i>, that can be seen as composed of a set of simpler tasks, and
</p>
<li><p><i>objective tasks</i>, that roughly correspond to the goals of STRIPS, but are more general.
</p>
</ol><p></p>
<p>
A solution to an HTN problem is then an executable sequence of primitive tasks that can be obtained from the initial task network by decomposing compound tasks into their set of simpler tasks, and by inserting ordering constraints. <a href="https://en.wikipedia.org/wiki/Hierarchical_task_network">SOURCE</a>
</p>
</blockquote></p>
<p><a name="node_footnote_Temp_40"></a><sup><small><a href="#node_call_footnote_Temp_40">29</a></small></sup> <a name="Bootstrap_Development_A_grounding"></a>
Bootstrapping the programmer's apprentice: Basic cognitive bootstrapping and linguistic grounding
</p>
<p>
The programmer's assistant agent is designed to distinguish between three voices: the voice of the programmer, the voice of the assistant's automated tutor and its own voice. We could have provided an audio track to distinguish these voices, but since there only these three and the overall system can determine when any one of them is speaking, the system simply adds a few bits to each utterance as a proxy for an audio signature allowing the assistant to make such distinctions for itself. When required, we use the same signature to indicate which of the three speakers is responsible for changes to the shared input and output associated with the fully instrumented IDE henceforth abbreviated as FIDE &#8212; pronounced &quot;/fee/'-/day/&quot;, from the Latin meaning: (i) trust, (ii) credit, (iii) fidelity, (iv) honesty. It will also prove useful to further distinguish the voice of the assistant as being in one of two modes: <i>private</i>, engaging in so-called <a href="https://en.wikipedia.org/wiki/Intrapersonal_communication">inner speech</a> that is not voiced aloud, and <i>public</i>, meaning spoken out loud for the explicit purpose of communicating with the programmer. We borrow the basic framework for modeling other agents and simple theory-of-mind from Rabinowitz&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_78">78</a>].</p>
<p>
The bootstrap statistical language model consists of an <em>n</em>-gram embedding trained on large general-text language corpus augmented with programming and software-engineering related text drawn from online forums and transcripts of pair-programming dialog. For the time being, we will not pursue the option of trying to acquire a large enough dialog corpus to train an encoder-decoder LSTM/GRU dialog manager / conversational model&nbsp;[<a href="#node_bib_96">96</a>]. In the initial prototype, natural language generation (NLG) output for the automated tutor and assistant will be handled using hierarchical planning technology leveraging ideas developed in the CMU <a href="http://www.cs.cmu.edu/~dbohus/ravenclaw-olympus/index-dan.html">RavenClaw</a> dialogue management system&nbsp;[<a href="#node_bib_11">11</a>]<a name="node_call_footnote_Temp_41"></a><sup><small><a href="#node_footnote_Temp_41">30</a></small></sup>,
but we have plans to explore hybrid natural language generation by combining hard-coded Python dialog agents corresponding to hierarchical task networks and differentiable dialogic encoder-decoder thought-cloud generators using a variant of pointer-generator networks as described by See&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_84">84</a>].<p>
Both the tutor and assistant NLG subsystems will rely on a base-level collection of plans &#8212; hierarchical task network (<a href="#hierarchical_task_network_planner">HTN</a>) &#8212; that we employ in several contexts plus a set of specialized plans &#8212; an HTN subnetwork &#8212; specific to each subsystem. At any given moment in time, a meta control system&nbsp;[<a href="#node_bib_46">46</a>] in concert with a reinforcement-learning-trained policy determines the curricular goal constraining the tutor's choice of specific lesson is implemented using a variant of the scheduled auxiliary control paradigm described by Riedmiller&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_82">82</a>]. Having selected a subset of lessons relevant to the current curricular goal, the meta-controller cedes control to the tutor which selects a specific lesson and a suitable plan to oversee interaction with the agent over the course of the lesson.</p>
<p>
Most lessons will require a combination of spoken dialogue and interactive signaling that may include both the agent and the tutor pointing, highlighting, performing edits and controlling the FIDE by executing code and using developer tools like the debugger to change state, set break points and single step the interpreter, but we're getting ahead of ourselves. The curriculum for mastering the basic referential modes is divided into three levels of mastery in keeping with Terrence Deacon's description&nbsp;[<a href="#node_bib_21">21</a>] and Charles Sanders Peirce's (semiotic) <a href="https://en.wikipedia.org/wiki/Semiotic_theory_of_Charles_Sanders_Peirce">theory of signs</a>. The tutor will start at the most basic level, continually evaluating performance to determine when it is time to graduate to the next level or when it is appropriate to revert to an earlier level to provide additional training in order to master the less demanding modes of reference.</p>
<p>
</p>
<p><a name="node_footnote_Temp_42"></a><sup><small><a href="#node_call_footnote_Temp_42">31</a></small></sup> <a name="Bootstrap_Development_B_signaling"></a>
Bootstrapping the programmer's apprentice: Simple interactive behavior for signaling and editing:
</p>
<p>
In the <a href="#Bootstrap_Development_A_grounding">first stage</a> of bootstrapping, the assistant's automated tutor engages in an analog of the sort of simple signaling and reinforcement that a mother might engage in with her baby in order to encourage the infant to begin taking notice of its environment and participating in the simplest forms of communication. The basic exchange goes something like: the mother draws the baby's attention to something and the baby acknowledges by making some sound or movement. This early step requires that the baby can direct its gaze and attend to changes in its visual field.</p>
<p>
In the case of the assistant, the relevant changes would correspond to changes in FIDE or the shared browser window, pointing would be accomplished by altering the contents of FIDE buffers or modifying HTML. Since the assistant has an innate capability to parse language into sequences of words, the tutor can preface each lesson with short verbal lesson summary, e.g., &quot;the variable '<tt>foo</tt>'&quot;, &quot;the underlined variable&quot;, &quot;the highlighted assignment statement&quot;, &quot;the expression highlighted in blue&quot;. The implicit curriculum followed by the tutor would systematically graduate to more complicated language for specifying referents, e.g., &quot;the <i>body</i> of the '<tt>for</tt>' loop&quot;, &quot;the '<tt>else</tt>' <i>clause</i> in the '<tt>conditional</tt> statement&quot;, &quot;the <i>scope</i> of the variable '<tt>counter</tt>'&quot;, &quot;the expression on the <i>right-hand side</i> of the first assignment statement&quot;.</p>
<p>
The goal of the bootstrap tutor is to eventually graduate to simple substitution and repair activities requiring a combination of basic attention, signaling, requesting feedback and simple edits, e.g., &quot;highlight the scope of the variable shown in red&quot;, &quot;change the name of the function to be &quot;<tt>Increment_Counter</tt>&quot;, &quot;insert a &quot;<tt>for</tt>&quot; loop with an iterator over the items in the &quot;<tt>bucket</tt>&quot; list&quot;, &quot;delete the next two expressions&quot;, with the length and complexity of the specification gradually increasing until the apprentice is capable of handling code changes that involve multiple goals and dozens of intermediate steps, e.g., &quot;delete the variable &quot;<tt>Interrupt_Flag</tt>&quot; from the parameter list of the function declaration and eliminate all of the expressions that refer to the variable within the scope of the function definition&quot;.</p>
<p>
Note the importance of an attentional system that can notice changes in the integrated development environment and shared browser window, the ability to use recency to help resolve ambiguities, and emphasize basic signals that require noticing changes in the IDE and acknowledging that these changes were made as a means of signaling expectations relevant to the ongoing conversation between the programmer and the apprentice. These are certainly subtleties that will have to be introduced gradually into the curricular repertoire as the apprentice gains experience. We are depending on employing a variant of Riedmiller&nbsp;<em>et al</em> that will enable us to employ the FIDE to gamify the process by evaluating progress at different levels using a combination of general extrinsic reward and policy-specific intrinsic motivations to guide action selection&nbsp;[<a href="#node_bib_82">82</a>].</p>
<p>
<a name="natural_intracortical_lingua_franca"></a>
Randall O'Reilly mentioned in his class presentation the idea that natural language might play an important role in human brains as an intra-cortical lingua franca. Given that one of the primary roles language serves is to serialize thought thereby facilitating serial computation with all of its advantages in terms of logical precision and combinatorial expression, projecting a distributed connectionist representation through some sort of auto encoder bottleneck might gain some advantage in combining aspects of symbolic and connectionist architectures. This also relates to O'Reilly’s discussion of the hippocampal system and in particular the processing performed by the dentate gyrus and hippocampal areas CA1 in CA2 in generating a sparse representation that enables rapid binding of arbitrary informational states and facilitates encoding and retrieving of episodic memory in the entorhinal cortex.</p>
<p>
</p>
<p><a name="node_footnote_Temp_43"></a><sup><small><a href="#node_call_footnote_Temp_43">32</a></small></sup> <a name="Bootstrap_Development_C_mirroring"></a>
Bootstrapping the programmer's apprentice: Mixed dialogue interleaving instruction and mirroring:
</p>
<p>
</p>
<p>
</p>
<p>

</p>
<p>
</p>
<p>
Every utterance, whether generated by the programmer or the apprentice's tutor or generated by the apprentice either intended for the programmer or <i>sotto voce</i> for its internal record, has potential future value and hence it makes sense to record that utterance along with any context that might help to realize that potential at a later point in time. Endel Tulving coined the phrase <a href="https://en.wikipedia.org/wiki/Episodic_memory">episodic memory</a> to refer to this sort of memory. We'll forgo discussion of other types of memory for the time being and focus on what the apprentice will need to remember in order take advantage of its past experience. </p>
<p>
Here is the simplest, stripped-to-its-most-basic-elements scenario outlined in the class notes: (a) the apprentice performs a sequence of steps that effect a repair on a code fragment, (b) this experience is recorded in a sequence of tuples of the form (<em>s</em><sub><em>t</em></sub>,<span style="margin-left: .27778em">&zwnj;</span><em>a</em><sub><em>t</em></sub>,<span style="margin-left: .27778em">&zwnj;</span><em>r</em><sub><em>t</em></sub>,<span style="margin-left: .27778em">&zwnj;</span><em>s</em><sub><em>t</em>+1</sub>) and consolidated in episodic memory, (c) at a subsequent time, days or weeks later, the apprentice recognizes a similar situation and realizes an opportunity to exercise what was learned in the earlier episode, and (d) a suitably adapted repair is applied in the present circumstances and incorporated into a more general policy so that it can be applied in wider range circumstances.</p>
<p>
The succinct notation doesn't reveal any hint of the complexity and subtlety of the question. What were the (prior) circumstances &#8212; <em>s</em><sub><em>t</em></sub>? What was thought, said and done to plan, prepare and take action &#8212; <em>a</em><sub><em>t</em></sub>? What were the (posterior) consequences &#8212; <em>r</em><sub><em>t</em></sub> and <em>s</em><sub><em>t</em>+1</sub>? We can't simply record the entire neural state vector. We could, however, plausibly record the information temporarily stored in working memory since this is the only information that could have played any substantive role &#8212; for better or worse &#8212; in guiding executive function. </p>
<p>
We can't store everything and then carefully pick through the pile looking for what might have made a difference, but we can do something almost as useful. We can propagate the reward gradient back through the value- / <span style="font-family:cursive">Q</span>-function and then further back through the activated circuits in working memory that were used to select <em>a</em><sub><em>i</em></sub> and adjust their weights accordingly. The objective in this case being to optimize the <span style="font-family:cursive">Q</span>-function by predicting the state variables that it needs in order to make an accurate prediction of the value of applying action <em>a</em><sub><em>t</em></sub> in <em>s</em><sub><em>t</em></sub> as described in Wayne&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_100">100</a>].</p>
<p>
Often the problem can be described as a simple Markov process and the state represented as a vector comprising of a finite number of state variables, <em>s</em><sub><em>t</em></sub>  = &lang;
<span style="color:black">&alpha;</span><sub>0</sub>,&thinsp;
<span style="color:black">&alpha;</span><sub>1</sub>,&thinsp;
<span style="color:black">&alpha;</span><sub>2</sub>,&thinsp;
<span style="color:black">&alpha;</span><sub>3</sub>,&thinsp;
<span style="color:black">&alpha;</span><sub>4</sub>,&thinsp;
<span style="color:black">&alpha;</span><sub>5</sub>,&thinsp;
<span style="color:black">&alpha;</span><sub>6</sub>,&thinsp;
<span style="color:black">&alpha;</span><sub>7</sub>
&rang;
, with the implicit assumption that the process is <i>fully observable</i>. More generally, the Markov property still holds, but the state is only <i>partially observable</i> resulting in a much harder class of decision problem known as a <a href="https://en.wikipedia.org/wiki/Partially_observable_Markov_decision_process">POMDP</a>. In some cases, we can finesse the complexity if we can ensure that we can observe the <i>relevant</i> state variables in any given state, e.g., in one set of states it is enough to know one subset of the state variables, {&lang;
<span style="color:black">&alpha;</span><sub>0</sub>,&thinsp;
<span style="color:red">&alpha;</span><sub>1</sub>,&thinsp;
<span style="color:black">&alpha;</span><sub>2</sub>,&thinsp;
<span style="color:red">&alpha;</span><sub>3</sub>,&thinsp;
<span style="color:black">&alpha;</span><sub>4</sub>,&thinsp;
<span style="color:black">&alpha;</span><sub>5</sub>,&thinsp;
<span style="color:black">&alpha;</span><sub>6</sub>,&thinsp;
<span style="color:red">&alpha;</span><sub>7</sub>
&rang;
}, while in another set of states a different subset of state variables suffices, {&lang;
<span style="color:black">&alpha;</span><sub>0</sub>,&thinsp;
<span style="color:black">&alpha;</span><sub>1</sub>,&thinsp;
<span style="color:black">&alpha;</span><sub>2</sub>,&thinsp;
<span style="color:black">&alpha;</span><sub>3</sub>,&thinsp;
<span style="color:red">&alpha;</span><sub>4</sub>,&thinsp;
<span style="color:black">&alpha;</span><sub>5</sub>,&thinsp;
<span style="color:red">&alpha;</span><sub>6</sub>,&thinsp;
<span style="color:black">&alpha;</span><sub>7</sub>
&rang;
}. If you can learn which state variables are required and arrange to observe them, the problem reduces to the fully observed case. </p>
<p>
There's a catch however. The state vector includes state variables that correspond to the observations of external processes that we have little or no direct control over as well as the apprehension of internal processes including the activation of subnetworks. We may need to plan for and carry out the requisite observations to acquire the external process state and perform the requisite computations to produce and then access the resulting internal state information. We also have the ability to perform two fundamentally different types of computation each of which has different strengths and weaknesses that conveniently complement the other.</p>
<p>
The mammalian brain is optimized to efficiently perform many computations in parallel; however, for the most part it is not particularly effective dealing with the inconsistencies that arise among those largely independent computations. Rather than relying on estimating and conditioning action selection on internally maintained state variables, most animals rely on environmental cues &#8212; callsed <a href="https://en.wikipedia.org/wiki/Affordance">affordances</a>&nbsp;[<a href="#node_bib_37">37</a>] &#8212; to restrict the space of possible options and simplify action selection. However, complex skills like programming require complex serial computations in order to reconcile and make sense of the contradictory suggestions originating from our mostly parallel computational substrate. </p>
<p>
Conventional reinforcement learning may work for some types of routine programming like writing simple text-processing scripts, but it is not likely to suffice for programs that involve more complex logical, mathematical and algorithmic thinking. The programmer's apprentice project is intended as a playground in which to explore ideas derived from biological systems that might help us chip away at these more difficult problems. For example, the primate brain compensates for the limitations of its largely parallel processing approach to solving problems by using specialized networks in the frontal cortex, thalamus, striatum, and basal ganglia to serialize the computations necessary to perform complex thinking. </p>
<p>
At the very least, it seems reasonable to suggest that we need cognitive machinery that is at least as powerful as the programs we aspire the apprentice to generate&nbsp;[<a href="#node_bib_34">34</a>]. We need the neural equivalent of the [<a href="https://en.wikipedia.org/wiki/Control_unit"><tt>CONTROL UNIT</tt></a>] responsible for maintaining a [<a href="https://en.wikipedia.org/wiki/Program_counter"><tt>PROGRAM COUNTER</tt></a>] and the analog of loading instructions and operands into <tt>REGISTERS</tt> in the [<a href="https://en.wikipedia.org/wiki/Arithmetic_logic_unit"><tt>ARITHMETIC AND LOGIC UNIT</tt></a>] and subsequently writing the resulting computed products into other registers or <tt>RANDOM ACCESS MEMORY</tt>. These <i>particular</i> features of the von Neumann architecture are not essential &#8212; what is required is a lingistic foundation that supports a complete story of computation and that is grounded in the detailed &#8212; almost visceral &#8212; experience of carrying out computations.</p>
<p>
A single <span style="font-family:cursive">Q</span> (value) function encoding a single action-selection policy with fixed finite-discrete or continuous state and action spaces isn't likely to suffice. Supporting compiled subroutines doesn't significantly change the picture. The addition of a meta controller for orchestrating a finite collection of separate, special-purpose policies adds complexity without appreciably adding competence. And simply adding language for describing procedures, composing production rules, and compiling subroutines as a Sapir-Whorf-induced infusion of ontological enhancement is &#8212; by itself &#8212; only a distraction. We need an approach that exploits a deeper understanding of the role of language in the modern age &#8212; a method of using a subset of natural language to describe programs in terms of narratives where executing such a program is tantamount to telling the story. Think about how human cognitive systems encode and serialize remembered stories, about programs as stories drawing on life experience by exploiting the serial nature of episodic memory, and about thought clouds that represent a superposition of eigenstates such that collapsing the wave function yields coherent narrative that serves as a program trace.</p>
<p>
</p>
<p><a name="node_footnote_Temp_44"></a><sup><small><a href="#node_call_footnote_Temp_44">33</a></small></sup> <a name="Bootstrap_Development_D_combining"></a>
Bootstrapping the programmer's apprentice: Composite behaviors corresponding to simple repairs:
</p>
<p>
A <i>software design pattern</i> &quot;is a general, reusable solution to a commonly occurring problem within a given context in software design. It is not a finished design that can be transformed directly into source or machine code. It is a description or template for how to solve a problem that can be used in many different situations. Design patterns are formalized best practices that the programmer can use to solve common problems when designing an application or system&quot; &#8212; <a href="https://en.wikipedia.org/wiki/Software_design_pattern">SOURCE</a>. They are typically characterized as belonging to one of three categories: 
<a href="https://en.wikipedia.org/wiki/Software_design_pattern#Creational_patterns">creational</a>,
<a href="https://en.wikipedia.org/wiki/Software_design_pattern#Creational_patterns">structural</a>, or
<a href="https://en.wikipedia.org/wiki/Software_design_pattern#Behavioral_patterns">behavioral</a>.</p>
<p>
I would like to believe that such patterns provide clear prescriptions for how to tackle challenging programming problems, but I know better. Studying such patterns and analyzing examples of their application to practical problems is an excellent exercise for both computer science students learning to program, and practicing software engineers wanting to improve their skills. That said, these design patterns require considerable effort to master and are well beyond what one might hope to accomplish in bootstrapping basic linguistic and programming skills. Indeed, mastery depends on already knowing &#8212; at the very least &#8212; the rudiments of these skills. </p>
<p>
</p>
<p>
I'm willing to concede that mental software is not always expressed in language. For the programmer's apprentice, I'm thinking of encoding what is essentially static and syntactic knowledge about programs and programming using four different representations, and what is essentially dynamic and semantic knowledge in a family of structured representations that encode program execution traces of one sort or another. The four static / syntactic representations are summarized as follows:
</p>
<ul>
<li><p>(i) distributed (connectionist) representations of natural language as points in high-dimensional embedding spaces &#8212; thought clouds;
</p>
<li><p>(ii) natural language transcripts of dialogical utterances / interlocutionary acts encoded as lexical token streams &#8212; word sequences;
</p>
<li><p>(iii) programs in the target programming language represented as structured objects corresponding to augmented <i>abstract syntax trees</i> (ASTs)&#8212; the augmentations correspond to edges representing procedure calls, iteration and recursion resulting in directed acyclic graphs;
</p>
<li><p>(iv) hierarchical plans corresponding to subnetworks of <i>hierarchical task networks</i> (HTNs) or, if you like, the implied representation of hierarchical plans encoded in value iteration networks&nbsp;[<a href="#node_bib_92">92</a>] and goal-based policies&nbsp;[<a href="#node_bib_42">42</a>]. I'm also thinking about encoding HTNs as policies using a variation on the idea of <i>options</i>&nbsp;[<a href="#node_bib_91">91</a>] as described in Riedmiller&nbsp;<em>et al</em>&nbsp;[<a href="#node_bib_82">82</a>]; 
</p>
</ul><p></p>
<p>
The first entry (i) is somewhat misleading in that any one of the remaining three (ii-iv) can be represented as a point / thought cloud using an appropriate embedding method. Thought clouds are the Swiss Army knife of distributed codes. They represent a (constrained) superposition of possibilities allowing us to convert large corpora of serialized structures into point clouds that enable massively parallel search, and subsequently allow us to collapse the wave function, as it were, to read off solutions by re-serializing the distributed encoding of constraints that result from conducting such parallel searches.</p>
<p>
I propose to develop encoders and decoders to translate between (serial) representations (ii-iv) where only a subset of conversions are possible or desirable given the expressivity of the underlying representation language. I imagine autoencoders with an <a href="https://en.wikipedia.org/wiki/Information_bottleneck_method">information bottleneck</a> that take embeddings of natural language descriptions as input and produces an equivalent HTN representation, combining a mixture of (executable) interlocutory and code synthesis tasks. The interlocutory tasks generate explanations and produce comments and specifications. The code-synthesis tasks serve to generate, repair, debug and test code represented in the FIDE.</p>
<p>
Separately encoded embeddings will tend to evolve independently, frustrating attempts to combine them into composite representations that allow powerful means of abstraction. The hope is that we can use natural language as a <a href="https://en.wikipedia.org/wiki/Lingua_franca">lingua franca</a> &#8212; a &quot;bridge&quot; language &#8212; to coerce agreement among disparate representations by forcing them to cohere along shared, possibly refactored dimensions in much the same way that <i>trade languages</i> serve as an expeditious means of exchanging information between scientists and engineers working in different disciplines or scholars who do not share a native language or dialect.</p>
<p>
</p>
<p>
</p>
</div>
<div class=smallskip></div>
<p style="margin-top: 0pt; margin-bottom: 0pt">
<div align=right class=navigation></div>
</p>
<p></p>
</div>
</body>
</html>
