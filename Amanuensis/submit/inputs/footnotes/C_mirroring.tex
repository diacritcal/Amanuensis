%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% FOOTNOTE
{\bf{Bootstrapping the programmer's apprentice: Mixed dialogue interleaving instruction and mirroring:}}\\
%%% FOOTNOTE
%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Every utterance, whether generated by the programmer or the apprentice's tutor or generated by the apprentice either intended for the programmer or {\it{sotto voce}} for its internal record, has potential future value and hence it makes sense to record that utterance along with any context that might help to realize that potential at a later point in time. Endel Tulving coined the phrase {\it{episodic memory}} to refer to this sort of memory. We'll forgo discussion of other types of memory for the time being and focus on what the apprentice will need to remember in order take advantage of its past experience. 

Here is the simplest, stripped-to-its-most-basic-elements scenario outlined in the class notes: (a) the apprentice performs a sequence of steps that effect a repair on a code fragment, (b) this experience is recorded in a sequence of tuples of the form $(s_{t}, a_{t}, r_{t}, s_{t+1})$ and consolidated in episodic memory, (c) at a subsequent time, days or weeks later, the apprentice recognizes a similar situation and realizes an opportunity to exercise what was learned in the earlier episode, and (d) a suitably adapted repair is applied in the present circumstances and incorporated into a more general policy so that it can be applied in wider range circumstances.

The succinct notation doesn't reveal any hint of the complexity and subtlety of the question. What were the (prior) circumstances \emdash{} $s_{t}$? What was thought, said and done to plan, prepare and take action \emdash{} $a_{t}$? What were the (posterior) consequences \emdash{} $r_{t}$ and $s_{t+1}$? We can't simply record the entire neural state vector. We could, however, plausibly record the information temporarily stored in working memory since this is the only information that could have played any substantive role \emdash{} for better or worse \emdash{} in guiding executive function. 

We can't store everything and then carefully pick through the pile looking for what might have made a difference, but we can do something almost as useful. We can propagate the reward gradient back through the value- / $Q$-function and then further back through the activated circuits in working memory that were used to select $a_{i}$ and adjust their weights accordingly. The objective in this case being to optimize the $Q$-function by predicting the state variables that it needs in order to make an accurate prediction of the value of applying action $a_{t}$ in $s_{t}$ as described in Wayne~\etal{}~\cite{WayneetalCoRR-18}.

Often the problem can be described as a simple Markov process and the state represented as a vector comprising of a finite number of state variables, $s_t = \langle{} \sigma{}_0, \sigma{}_1, \sigma{}_2, \sigma{}_3, \sigma{}_4, \sigma{}_5, \sigma{}_6, \sigma{}_7, \rangle{}$, with the implicit assumption that the process is {\it{fully observable}}. More generally, the Markov property still holds, but the state is only {\it{partially observable}} resulting in a much harder class of decision problem known as a {\urlh{https://en.wikipedia.org/wiki/Partially_observable_Markov_decision_process}{POMDP}}. In some cases, we can finesse the complexity if we can ensure that we can observe the {\it{relevant}} state variables in any given state, e.g., in one set of states it is enough to know one subset of the state variables, $\langle{} \sigma{}_0, \color{red}\sigma{}_1\color{black}, \sigma{}_2, \color{red}\sigma{}_3\color{black}, \sigma{}_4, \sigma{}_5, \sigma{}_6, \color{red}\sigma{}_7\color{black} \rangle{}$, while in another set of states a different subset of state variables suffices, $\langle{} \sigma{}_0, \sigma{}_1, \sigma{}_2, \sigma{}_3, \color{red}\sigma{}_4\color{black}, \sigma{}_5, \color{red}\sigma{}_6\color{black}, \sigma{}_7 \rangle{}$. If you can learn which state variables are required and arrange to observe them, the problem reduces to the fully observed case. 

There's a catch however. The state vector includes state variables that correspond to the observations of external processes that we have little or no direct control over as well as the apprehension of internal processes including the activation of subnetworks. We may need to plan for and carry out the requisite observations to acquire the external process state and perform the requisite computations to produce and then access the resulting internal state information. We also have the ability to perform two fundamentally different types of computation each of which has different strengths and weaknesses that conveniently complement the other.

The mammalian brain is optimized to efficiently perform many computations in parallel; however, for the most part it is not particularly effective dealing with the inconsistencies that arise among those largely independent computations. Rather than relying on estimating and conditioning action selection on internally maintained state variables, most animals rely on environmental cues \emdash{} callsed {\urlh{https://en.wikipedia.org/wiki/Affordance}{affordances}}~\cite{GibsonAFFORDANCES-79} \emdash{} to restrict the space of possible options and simplify action selection. However, complex skills like programming require complex serial computations in order to reconcile and make sense of the contradictory suggestions originating from our mostly parallel computational substrate. 

Conventional reinforcement learning may work for some types of routine programming like writing simple text-processing scripts, but it is not likely to suffice for programs that involve more complex logical, mathematical and algorithmic thinking. The programmer's apprentice project is intended as a playground in which to explore ideas derived from biological systems that might help us chip away at these more difficult problems. For example, the primate brain compensates for the limitations of its largely parallel processing approach to solving problems by using specialized networks in the frontal cortex, thalamus, striatum, and basal ganglia to serialize the computations necessary to perform complex thinking. 

At the very least, it seems reasonable to suggest that we need cognitive machinery that is at least as powerful as the programs we aspire the apprentice to generate~\cite{GallistelandKing2009computational}. We need the neural equivalent of the {{\tt{CONTROL UNIT}}} responsible for maintaining a {\tt{PROGRAM COUNTER}} and the analog of loading instructions and operands into {\tt{REGISTERS}} in the {\tt{ARITHMETIC AND LOGIC UNIT}} and subsequently writing the resulting computed products into other registers or {\tt{RANDOM ACCESS MEMORY}}. These {\it{particular}} features of the von Neumann architecture are not essential \emdash{} what is required is a lingistic foundation that supports a complete story of computation and that is grounded in the detailed \emdash{} almost visceral \emdash{} experience of carrying out computations.

A single $Q$ (value) function encoding a single action-selection policy with fixed finite-discrete or continuous state and action spaces isn't likely to suffice. Supporting compiled subroutines doesn't significantly change the picture. The addition of a meta controller for orchestrating a finite collection of separate, special-purpose policies adds complexity without appreciably adding competence. And simply adding language for describing procedures, composing production rules, and compiling subroutines as a Sapir-Whorf-induced infusion of ontological enhancement is \emdash{} by itself \emdash{} only a distraction. We need an approach that exploits a deeper understanding of the role of language in the modern age \emdash{} a method of using a subset of natural language to describe programs in terms of narratives where executing such a program is tantamount to telling the story. Think about how human cognitive systems encode and serialize remembered stories, about programs as stories drawing on life experience by exploiting the serial nature of episodic memory, and about thought clouds that represent a superposition of eigenstates such that collapsing the wave function yields coherent narrative that serves as a program trace.\\

%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
